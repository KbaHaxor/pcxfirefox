# HG changeset patch
# User xunxun1982@gmail.com
# Date 1438678016 -28800
#      Tue Aug 04 16:46:56 2015 +0800
# Branch MOBILE400b10_2015080313_RELBRANCH
# Node ID f3705b7a4bba8f375ed4cce5f26e6467bfd25caf
# Parent  59e0ca4dbf354d358ffca3b98e39047cf61e1212
tete009

diff --git a/browser/branding/aurora/configure.sh b/browser/branding/aurora/configure.sh
--- a/browser/branding/aurora/configure.sh
+++ b/browser/branding/aurora/configure.sh
@@ -1,7 +1,8 @@
 # This Source Code Form is subject to the terms of the Mozilla Public
 # License, v. 2.0. If a copy of the MPL was not distributed with this
 # file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 MOZ_APP_DISPLAYNAME=FirefoxDeveloperEdition
 MOZ_APP_REMOTINGNAME=firefox-dev
 MOZ_DEV_EDITION=1
+MOZ_UA_BUILDID=20100101
diff --git a/browser/branding/nightly/configure.sh b/browser/branding/nightly/configure.sh
--- a/browser/branding/nightly/configure.sh
+++ b/browser/branding/nightly/configure.sh
@@ -1,5 +1,6 @@
 # This Source Code Form is subject to the terms of the Mozilla Public
 # License, v. 2.0. If a copy of the MPL was not distributed with this
 # file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 MOZ_APP_DISPLAYNAME=Nightly
+MOZ_UA_BUILDID=20100101
diff --git a/configure.in b/configure.in
--- a/configure.in
+++ b/configure.in
@@ -2238,21 +2238,16 @@ ia64*-hpux*)
         WIN32_CONSOLE_EXE_LDFLAGS=-SUBSYSTEM:CONSOLE,$WIN32_SUBSYSTEM_VERSION
         WIN32_GUI_EXE_LDFLAGS=-SUBSYSTEM:WINDOWS,$WIN32_SUBSYSTEM_VERSION
         DSO_LDOPTS=-SUBSYSTEM:WINDOWS,$WIN32_SUBSYSTEM_VERSION
         _USE_CPP_INCLUDE_FLAG=1
         _DEFINES_CFLAGS='-FI $(DEPTH)/dist/include/mozilla-config.h -DMOZILLA_CLIENT'
         _DEFINES_CXXFLAGS='-FI $(DEPTH)/dist/include/mozilla-config.h -DMOZILLA_CLIENT'
         CFLAGS="$CFLAGS -W3 -Gy"
         CXXFLAGS="$CXXFLAGS -W3 -Gy"
-        if test "$CPU_ARCH" = "x86"; then
-            dnl VS2012+ defaults to -arch:SSE2.
-            CFLAGS="$CFLAGS -arch:IA32"
-            CXXFLAGS="$CXXFLAGS -arch:IA32"
-        fi
         dnl VS2013+ requires -FS when parallel building by make -jN.
         dnl If nothing, compiler sometimes causes C1041 error.
         CFLAGS="$CFLAGS -FS"
         CXXFLAGS="$CXXFLAGS -FS"
         # khuey says we can safely ignore MSVC warning C4251
         # MSVC warning C4244 (implicit type conversion may lose data) warns
         # and requires workarounds for perfectly valid code.  Also, GCC/clang
         # don't warn about it by default. So for consistency/sanity, we turn
@@ -2290,26 +2285,26 @@ ia64*-hpux*)
         # autoconf insists on passing $LDFLAGS to the compiler.
         if test -z "$CLANG_CL"; then
             LDFLAGS="$LDFLAGS -LARGEADDRESSAWARE -NXCOMPAT"
             if test -z "$DEVELOPER_OPTIONS"; then
                 LDFLAGS="$LDFLAGS -RELEASE"
             fi
         fi
         dnl For profile-guided optimization
-        PROFILE_GEN_CFLAGS="-GL"
-        PROFILE_GEN_LDFLAGS="-LTCG:PGINSTRUMENT"
+        PROFILE_GEN_CFLAGS="-GL -DMSVC_PGO_ENABLED"
+        PROFILE_GEN_LDFLAGS="-LTCG:PGINSTRUMENT -PogoSafeMode"
         dnl XXX: PGO builds can fail with warnings treated as errors,
         dnl specifically "no profile data available" appears to be
         dnl treated as an error sometimes. This might be a consequence
         dnl of using WARNINGS_AS_ERRORS in some modules, combined
         dnl with the linker doing most of the work in the whole-program
         dnl optimization/PGO case. I think it's probably a compiler bug,
         dnl but we work around it here.
-        PROFILE_USE_CFLAGS="-GL -wd4624 -wd4952"
+        PROFILE_USE_CFLAGS="-GL -wd4624 -wd4952 -DMSVC_PGO_ENABLED"
         dnl XXX: should be -LTCG:PGOPTIMIZE, but that fails on libxul.
         dnl Probably also a compiler bug, but what can you do?
         PROFILE_USE_LDFLAGS="-LTCG:PGUPDATE"
         LDFLAGS="$LDFLAGS -DYNAMICBASE"
         if test "$_CC_MAJOR_VERSION" = "18" -a "$_CC_BUILD_VERSION" = "31101"; then
             dnl Use MaxILKSize as a workaround for LNK1248 in VS2013update4
             dnl See https://connect.microsoft.com/VisualStudio/feedback/details/1044914/fatal-error-lnk1248
             LDFLAGS="$LDFLAGS -MaxILKSize:0x7FF00000"
diff --git a/dom/base/Element.h b/dom/base/Element.h
--- a/dom/base/Element.h
+++ b/dom/base/Element.h
@@ -346,16 +346,28 @@ public:
   // false
   inline bool HasDirAuto() const {
     return (!HasFixedDir() &&
             (HasValidDir() || IsHTMLElement(nsGkAtoms::bdi)));
   }
 
   Directionality GetComputedDirectionality() const;
 
+  void PrefetchAttrsAndChildren()
+  {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)&mAttrsAndChildren, _MM_HINT_NTA);
+#endif
+  }
+
+  void PrefetchAttrAndChildArrayImpl()
+  {
+    mAttrsAndChildren.PrefetchImpl();
+  }
+
 protected:
   /**
    * Method to get the _intrinsic_ content state of this element.  This is the
    * state that is independent of the element's presentation.  To get the full
    * content state, use State().  See mozilla/EventStates.h for
    * the possible bits that could be set here.
    */
   virtual EventStates IntrinsicState() const;
diff --git a/dom/base/nsAttrAndChildArray.h b/dom/base/nsAttrAndChildArray.h
--- a/dom/base/nsAttrAndChildArray.h
+++ b/dom/base/nsAttrAndChildArray.h
@@ -7,16 +7,20 @@
 /*
  * Storage of the children and attributes of a DOM node; storage for
  * the two is unified to minimize footprint.
  */
 
 #ifndef nsAttrAndChildArray_h___
 #define nsAttrAndChildArray_h___
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include "mozilla/Attributes.h"
 #include "mozilla/MemoryReporting.h"
 
 #include "nscore.h"
 #include "nsAttrName.h"
 #include "nsAttrValue.h"
 #include "nsCaseTreatment.h"
 
@@ -124,16 +128,23 @@ public:
   }
 
   size_t SizeOfExcludingThis(mozilla::MallocSizeOf aMallocSizeOf) const;
   bool HasMappedAttrs() const
   {
     return MappedAttrCount();
   }
 
+  void PrefetchImpl()
+  {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)mImpl, _MM_HINT_NTA);
+#endif
+  }
+
 private:
   nsAttrAndChildArray(const nsAttrAndChildArray& aOther) = delete;
   nsAttrAndChildArray& operator=(const nsAttrAndChildArray& aOther) = delete;
 
   void Clear();
 
   uint32_t NonMappedAttrCount() const;
   uint32_t MappedAttrCount() const;
diff --git a/dom/canvas/CanvasRenderingContext2D.cpp b/dom/canvas/CanvasRenderingContext2D.cpp
--- a/dom/canvas/CanvasRenderingContext2D.cpp
+++ b/dom/canvas/CanvasRenderingContext2D.cpp
@@ -4953,63 +4953,17 @@ CanvasRenderingContext2D::GetImageDataAr
   }
 
   // NOTE! dst is the same as src, and this relies on reading
   // from src and advancing that ptr before writing to dst.
   // NOTE! I'm not sure that it is, I think this comment might have been
   // inherited from Thebes canvas and is no longer true
   uint8_t* dst = data + dstWriteRect.y * (aWidth * 4) + dstWriteRect.x * 4;
 
-  if (mOpaque) {
-    for (int32_t j = 0; j < dstWriteRect.height; ++j) {
-      for (int32_t i = 0; i < dstWriteRect.width; ++i) {
-        // XXX Is there some useful swizzle MMX we can use here?
-#if MOZ_LITTLE_ENDIAN
-        uint8_t b = *src++;
-        uint8_t g = *src++;
-        uint8_t r = *src++;
-        src++;
-#else
-        src++;
-        uint8_t r = *src++;
-        uint8_t g = *src++;
-        uint8_t b = *src++;
-#endif
-        *dst++ = r;
-        *dst++ = g;
-        *dst++ = b;
-        *dst++ = 255;
-      }
-      src += srcStride - (dstWriteRect.width * 4);
-      dst += (aWidth * 4) - (dstWriteRect.width * 4);
-    }
-  } else
-  for (int32_t j = 0; j < dstWriteRect.height; ++j) {
-    for (int32_t i = 0; i < dstWriteRect.width; ++i) {
-      // XXX Is there some useful swizzle MMX we can use here?
-#if MOZ_LITTLE_ENDIAN
-      uint8_t b = *src++;
-      uint8_t g = *src++;
-      uint8_t r = *src++;
-      uint8_t a = *src++;
-#else
-      uint8_t a = *src++;
-      uint8_t r = *src++;
-      uint8_t g = *src++;
-      uint8_t b = *src++;
-#endif
-      // Convert to non-premultiplied color
-      *dst++ = gfxUtils::sUnpremultiplyTable[a * 256 + r];
-      *dst++ = gfxUtils::sUnpremultiplyTable[a * 256 + g];
-      *dst++ = gfxUtils::sUnpremultiplyTable[a * 256 + b];
-      *dst++ = a;
-    }
-    src += srcStride - (dstWriteRect.width * 4);
-    dst += (aWidth * 4) - (dstWriteRect.width * 4);
-  }
+  GetImageData_component(src, dst, dstWriteRect.width, dstWriteRect.height, srcStride, aWidth * 4);
 
   *aRetval = darray;
   return NS_OK;
 }
 
 void
 CanvasRenderingContext2D::EnsureErrorTarget()
 {
@@ -5142,37 +5096,17 @@ CanvasRenderingContext2D::PutImageData_e
                                                           false);
   if (!imgsurf || imgsurf->CairoStatus()) {
     return NS_ERROR_FAILURE;
   }
 
   uint8_t *src = aArray->Data();
   uint8_t *dst = imgsurf->Data();
 
-  for (uint32_t j = 0; j < h; j++) {
-    for (uint32_t i = 0; i < w; i++) {
-      uint8_t r = *src++;
-      uint8_t g = *src++;
-      uint8_t b = *src++;
-      uint8_t a = *src++;
-
-      // Convert to premultiplied color (losslessly if the input came from getImageData)
-#if MOZ_LITTLE_ENDIAN
-      *dst++ = gfxUtils::sPremultiplyTable[a * 256 + b];
-      *dst++ = gfxUtils::sPremultiplyTable[a * 256 + g];
-      *dst++ = gfxUtils::sPremultiplyTable[a * 256 + r];
-      *dst++ = a;
-#else
-      *dst++ = a;
-      *dst++ = gfxUtils::sPremultiplyTable[a * 256 + r];
-      *dst++ = gfxUtils::sPremultiplyTable[a * 256 + g];
-      *dst++ = gfxUtils::sPremultiplyTable[a * 256 + b];
-#endif
-    }
-  }
+  PutImageData_component(src, dst, w, h, w * 4, w * 4);
 
   EnsureTarget();
   if (!IsTargetValid()) {
     return NS_ERROR_FAILURE;
   }
 
   RefPtr<SourceSurface> sourceSurface =
     mTarget->CreateSourceSurfaceFromData(imgsurf->Data(), IntSize(w, h), imgsurf->Stride(), SurfaceFormat::B8G8R8A8);
diff --git a/dom/canvas/CanvasUtils.cpp b/dom/canvas/CanvasUtils.cpp
--- a/dom/canvas/CanvasUtils.cpp
+++ b/dom/canvas/CanvasUtils.cpp
@@ -1,13 +1,21 @@
 /* -*- Mode: C++; tab-width: 20; indent-tabs-mode: nil; c-basic-offset: 4 -*- */
 /* This Source Code Form is subject to the terms of the Mozilla Public
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+#include <omp.h>
+#endif
+
+#include <tmmintrin.h>
+#include "mozilla/SSE.h"
+#include "gfxUtils.h"
+
 #include <stdlib.h>
 #include <stdarg.h>
 
 #include "prprf.h"
 
 #include "nsIServiceManager.h"
 
 #include "nsIConsoleService.h"
@@ -74,10 +82,260 @@ CoerceDouble(JS::Value v, double* d)
     } else if (v.isUndefined()) {
         *d = 0.0;
     } else {
         return false;
     }
     return true;
 }
 
+void
+GetImageData_component(uint8_t* _src, uint8_t* _dst,
+                       int32_t width, int32_t height,
+                       uint32_t srcStride, uint32_t dstStride)
+{
+    uint8_t *srcFirst = _src;
+    uint8_t *dstFirst = _dst;
+
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+    int omp_thread_counts = omp_get_max_threads();
+
+#pragma omp parallel for schedule(guided) default(none) \
+shared(srcFirst, dstFirst, width, height, srcStride, dstStride, gfxUtils::sUnpremultiplyTable) \
+if (omp_thread_counts >= 2 && \
+    height >= (int32_t)omp_thread_counts && \
+    width * height >= 4096)
+#endif // defined(TT_MEMUTIL) && defined(_MSC_VER)
+    for (int32_t j = 0; j < height; ++j) {
+        uint8_t *src = srcFirst + (srcStride * j);
+        uint8_t *dst = dstFirst + (dstStride * j);
+
+        for (int32_t i = 0; i < width; ++i) {
+            // XXX Is there some useful swizzle MMX we can use here?
+#ifdef IS_LITTLE_ENDIAN
+            uint8_t b = *src++;
+            uint8_t g = *src++;
+            uint8_t r = *src++;
+            uint8_t a = *src++;
+#else
+            uint8_t a = *src++;
+            uint8_t r = *src++;
+            uint8_t g = *src++;
+            uint8_t b = *src++;
+#endif
+            // Convert to non-premultiplied color
+            *dst++ = gfxUtils::sUnpremultiplyTable[a * 256 + r];
+            *dst++ = gfxUtils::sUnpremultiplyTable[a * 256 + g];
+            *dst++ = gfxUtils::sUnpremultiplyTable[a * 256 + b];
+            *dst++ = a;
+        }
+    }
+}
+
+void
+PutImageData_component(uint8_t* _src, uint8_t* _dst,
+                       int32_t width, int32_t height,
+                       uint32_t srcStride, uint32_t dstStride)
+{
+    uint8_t *srcFirst = _src;
+    uint8_t *dstFirst = _dst;
+
+    if (mozilla::supports_ssse3()) {
+        static const __m128i msk_alpha = _mm_set1_epi32(0xFF000000);
+        static const __m128i sfl_alphaLo = _mm_set_epi8(0x80, 7, 0x80, 7, 0x80, 7, 0x80, 7, 0x80, 3, 0x80, 3, 0x80, 3, 0x80, 3);
+        static const __m128i sfl_alphaHi = _mm_set_epi8(0x80, 15, 0x80, 15, 0x80, 15, 0x80, 15, 0x80, 11, 0x80, 11, 0x80, 11, 0x80, 11);
+        static const __m128i word_add = _mm_set1_epi16(0x00FF);
+        static const __m128i word_mul = _mm_set_epi16(0, 257, 257, 257, 0, 257, 257, 257);
+        static const __m128i sfl_bgra = _mm_set_epi8(15, 12, 13, 14, 11, 8, 9, 10, 7, 4, 5, 6, 3, 0, 1, 2);
+
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+        int omp_thread_counts = omp_get_max_threads();
+
+#pragma omp parallel for schedule(guided) default(none) \
+shared(srcFirst, dstFirst, width, height, srcStride, dstStride, gfxUtils::sPremultiplyTable) \
+if (omp_thread_counts >= 2 && \
+    height >= (int32_t)omp_thread_counts && \
+    width * height >= 12000)
+#endif // defined(TT_MEMUTIL) && defined(_MSC_VER)
+        for (int j = 0; j < height; j++) {
+            uint8_t *src = srcFirst + (srcStride * j);
+            uint8_t *dst = dstFirst + (dstStride * j);
+            int32_t i = width;
+
+            while (i >= 1 && ((unsigned)dst & 15)) {
+                uint8_t r = *src++;
+                uint8_t g = *src++;
+                uint8_t b = *src++;
+                uint8_t a = *src++;
+
+                // Convert to premultiplied color (losslessly if the input came from getImageData)
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + b];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + g];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + r];
+                *dst++ = a;
+                i -= 1;
+            }
+
+            const int srcMissalignedBytes = ((unsigned)src & 15);
+
+            if (srcMissalignedBytes == 0) {
+                while (i >= 4) {
+                    __m128i xmb = _mm_load_si128((__m128i*)src);
+                    __m128i xmwLo = _mm_unpacklo_epi8(xmb, _mm_setzero_si128());
+                    __m128i xmwHi = _mm_unpackhi_epi8(xmb, _mm_setzero_si128());
+
+                    __m128i xmwAlpha = _mm_and_si128(xmb, msk_alpha);
+                    __m128i xmwAlphaLo = _mm_shuffle_epi8(xmb, sfl_alphaLo);
+                    __m128i xmwAlphaHi = _mm_shuffle_epi8(xmb, sfl_alphaHi);
+
+                    xmwLo = _mm_mullo_epi16(xmwLo, xmwAlphaLo);
+                    xmwLo = _mm_adds_epu16(xmwLo, word_add);
+                    xmwLo = _mm_mulhi_epu16(xmwLo, word_mul);
+
+                    xmwHi = _mm_mullo_epi16(xmwHi, xmwAlphaHi);
+                    xmwHi = _mm_adds_epu16(xmwHi, word_add);
+                    xmwHi = _mm_mulhi_epu16(xmwHi, word_mul);
+
+                    __m128i xmRes = _mm_packus_epi16(xmwLo, xmwHi);
+                    xmRes = _mm_or_si128(xmRes, xmwAlpha);
+                    xmRes = _mm_shuffle_epi8(xmRes, sfl_bgra);
+                    _mm_store_si128((__m128i*)dst, xmRes);
+
+                    src += 16;
+                    dst += 16;
+                    i -= 4;
+                }
+            } else {
+                __m128i xmLoadPre = _mm_load_si128((__m128i*)(src - srcMissalignedBytes));
+
+                while (i >= 4) {
+                    __m128i xmLoadNext = _mm_load_si128((__m128i*)(src - srcMissalignedBytes + 16));
+                    __m128i xmb;
+
+                    switch (srcMissalignedBytes) {
+                    case 1:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 1);
+                        break;
+                    case 2:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 2);
+                        break;
+                    case 3:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 3);
+                        break;
+                    case 4:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 4);
+                        break;
+                    case 5:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 5);
+                        break;
+                    case 6:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 6);
+                        break;
+                    case 7:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 7);
+                        break;
+                    case 8:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 8);
+                        break;
+                    case 9:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 9);
+                        break;
+                    case 10:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 10);
+                        break;
+                    case 11:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 11);
+                        break;
+                    case 12:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 12);
+                        break;
+                    case 13:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 13);
+                        break;
+                    case 14:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 14);
+                        break;
+                    case 15:
+                        xmb = _mm_alignr_epi8(xmLoadNext, xmLoadPre, 15);
+                        break;
+                    }
+                    xmLoadPre = xmLoadNext;
+
+                    __m128i xmwLo = _mm_unpacklo_epi8(xmb, _mm_setzero_si128());
+                    __m128i xmwHi = _mm_unpackhi_epi8(xmb, _mm_setzero_si128());
+
+                    __m128i xmwAlpha = _mm_and_si128(xmb, msk_alpha);
+                    __m128i xmwAlphaLo = _mm_shuffle_epi8(xmb, sfl_alphaLo);
+                    __m128i xmwAlphaHi = _mm_shuffle_epi8(xmb, sfl_alphaHi);
+
+                    xmwLo = _mm_mullo_epi16(xmwLo, xmwAlphaLo);
+                    xmwLo = _mm_adds_epu16(xmwLo, word_add);
+                    xmwLo = _mm_mulhi_epu16(xmwLo, word_mul);
+
+                    xmwHi = _mm_mullo_epi16(xmwHi, xmwAlphaHi);
+                    xmwHi = _mm_adds_epu16(xmwHi, word_add);
+                    xmwHi = _mm_mulhi_epu16(xmwHi, word_mul);
+
+                    __m128i xmRes = _mm_packus_epi16(xmwLo, xmwHi);
+                    xmRes = _mm_or_si128(xmRes, xmwAlpha);
+                    xmRes = _mm_shuffle_epi8(xmRes, sfl_bgra);
+                    _mm_store_si128((__m128i*)dst, xmRes);
+
+                    src += 16;
+                    dst += 16;
+                    i -= 4;
+                }
+            }
+
+            while (i >= 1) {
+                uint8_t r = *src++;
+                uint8_t g = *src++;
+                uint8_t b = *src++;
+                uint8_t a = *src++;
+
+                // Convert to premultiplied color (losslessly if the input came from getImageData)
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + b];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + g];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + r];
+                *dst++ = a;
+                i -= 1;
+            }
+        }
+    } else {
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+        int omp_thread_counts = omp_get_max_threads();
+
+#pragma omp parallel for schedule(guided) default(none) \
+shared(srcFirst, dstFirst, width, height, srcStride, dstStride, gfxUtils::sPremultiplyTable) \
+if (omp_thread_counts >= 2 && \
+    height >= (int32_t)omp_thread_counts && \
+    width * height >= 4096)
+#endif // defined(TT_MEMUTIL) && defined(_MSC_VER)
+        for (int64_t j = 0; j < height; j++) {
+            uint8_t *src = srcFirst + (srcStride * j);
+            uint8_t *dst = dstFirst + (dstStride * j);
+
+            for (int32_t i = 0; i < width; i++) {
+                // XXX Is there some useful swizzle MMX we can use here?
+                uint8_t r = *src++;
+                uint8_t g = *src++;
+                uint8_t b = *src++;
+                uint8_t a = *src++;
+
+                // Convert to premultiplied color (losslessly if the input came from getImageData)
+#ifdef IS_LITTLE_ENDIAN
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + b];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + g];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + r];
+                *dst++ = a;
+#else
+                *dst++ = a;
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + r];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + g];
+                *dst++ = gfxUtils::sPremultiplyTable[a * 256 + b];
+#endif
+            }
+        }
+    }
+}
+
 } // namespace CanvasUtils
 } // namespace mozilla
diff --git a/dom/canvas/CanvasUtils.h b/dom/canvas/CanvasUtils.h
--- a/dom/canvas/CanvasUtils.h
+++ b/dom/canvas/CanvasUtils.h
@@ -17,16 +17,24 @@ namespace mozilla {
 
 namespace dom {
 class HTMLCanvasElement;
 }
 
 namespace CanvasUtils {
 
 
+void GetImageData_component(uint8_t* _src, uint8_t* _dst,
+                            int32_t width, int32_t height,
+                            uint32_t srcStride, uint32_t dstStride);
+
+void PutImageData_component(uint8_t* _src, uint8_t* _dst,
+                            int32_t width, int32_t height,
+                            uint32_t srcStride, uint32_t dstStride);
+
 // Check that the rectangle [x,y,w,h] is a subrectangle of [0,0,realWidth,realHeight]
 
 inline bool CheckSaneSubrectSize(int32_t x, int32_t y, int32_t w, int32_t h,
                             int32_t realWidth, int32_t realHeight) {
     CheckedInt32 checked_xmost  = CheckedInt32(x) + w;
     CheckedInt32 checked_ymost  = CheckedInt32(y) + h;
 
     return w >= 0 && h >= 0 && x >= 0 && y >= 0 &&
diff --git a/dom/canvas/moz.build b/dom/canvas/moz.build
--- a/dom/canvas/moz.build
+++ b/dom/canvas/moz.build
@@ -35,22 +35,23 @@ EXPORTS.mozilla.dom += [
 
 # http://support.microsoft.com/kb/143208
 DEFINES['NOMINMAX'] = True
 
 # Canvas 2D and common sources
 UNIFIED_SOURCES += [
     'CanvasImageCache.cpp',
     'CanvasRenderingContext2D.cpp',
-    'CanvasUtils.cpp',
     'DocumentRendererChild.cpp',
     'DocumentRendererParent.cpp',
     'ImageData.cpp',
 ]
 
+SOURCES += ['CanvasUtils.cpp']
+
 # WebGL Sources
 UNIFIED_SOURCES += [
     'MurmurHash3.cpp',
     'WebGL1Context.cpp',
     'WebGL1ContextBuffers.cpp',
     'WebGL1ContextUniforms.cpp',
     'WebGL2Context.cpp',
     'WebGL2ContextBuffers.cpp',
@@ -146,8 +147,15 @@ LOCAL_INCLUDES += [
     '/js/xpconnect/src',
     '/layout/generic',
     '/layout/style',
     '/layout/xul',
 ]
 
 CXXFLAGS += CONFIG['MOZ_CAIRO_CFLAGS']
 CXXFLAGS += CONFIG['TK_CFLAGS']
+
+if CONFIG['_MSC_VER']:
+    if '-DTT_MEMUTIL' in CONFIG['MOZ_OPTIMIZE_FLAGS']:
+        SOURCES['CanvasUtils.cpp'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
diff --git a/dom/plugins/base/nsPluginNativeWindowWin.cpp b/dom/plugins/base/nsPluginNativeWindowWin.cpp
--- a/dom/plugins/base/nsPluginNativeWindowWin.cpp
+++ b/dom/plugins/base/nsPluginNativeWindowWin.cpp
@@ -31,17 +31,28 @@ using namespace mozilla;
 
 #define nsMajorVersion(v)       (((int32_t)(v) >> 16) & 0xffff)
 #define nsMinorVersion(v)       ((int32_t)(v) & 0xffff)
 #define versionOK(suppliedV, requiredV)                   \
   (nsMajorVersion(suppliedV) == nsMajorVersion(requiredV) \
    && nsMinorVersion(suppliedV) >= nsMinorVersion(requiredV))
 
 
-#define NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION TEXT("MozillaPluginWindowPropertyAssociation")
+class CAtom_MozillaPluginWindowPropertyAssociation {
+public:
+  CAtom_MozillaPluginWindowPropertyAssociation() {
+    atom = ::GlobalAddAtomW(L"MozillaPluginWindowPropertyAssociation");
+  }
+  ~CAtom_MozillaPluginWindowPropertyAssociation() {
+    ::GlobalDeleteAtom(atom);
+  }
+  ATOM atom;
+};
+static CAtom_MozillaPluginWindowPropertyAssociation gaMpwpa;
+#define NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION ((LPCWSTR)(DWORD)gaMpwpa.atom)
 #define NS_PLUGIN_CUSTOM_MSG_ID TEXT("MozFlashUserRelay")
 #define WM_USER_FLASH WM_USER+1
 static UINT sWM_FLASHBOUNCEMSG = 0;
 
 typedef nsTWeakRef<class nsPluginNativeWindowWin> PluginWindowWeakRef;
 
 /**
  *  PLEvent handling code
@@ -187,17 +198,17 @@ static LRESULT CALLBACK PluginWndProc(HW
  * are currently not in use when running with e10s. (Utility calls like CallSetWindow
  * are still in use in the content process.) We would like to keep things this away,
  * essentially making all the hacks here obsolete. Some of the mitigation work here has
  * already been supplanted by code in PluginInstanceChild. The rest we eventually want
  * to rip out.
  */
 static LRESULT CALLBACK PluginWndProcInternal(HWND hWnd, UINT msg, WPARAM wParam, LPARAM lParam)
 {
-  nsPluginNativeWindowWin * win = (nsPluginNativeWindowWin *)::GetProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
+  nsPluginNativeWindowWin * win = (nsPluginNativeWindowWin *)::GetPropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
   if (!win)
     return TRUE;
 
   // The DispatchEvent(NS_PLUGIN_ACTIVATE) below can trigger a reentrant focus
   // event which might destroy us.  Hold a strong ref on the plugin instance
   // to prevent that, bug 374229.
   nsRefPtr<nsNPAPIPluginInstance> inst;
   win->GetPluginInstance(inst);
@@ -389,17 +400,17 @@ static User32SetWindowLongA sUser32SetWi
 static User32SetWindowLongW sUser32SetWindowLongWHookStub = nullptr;
 #endif
 static inline bool
 SetWindowLongHookCheck(HWND hWnd,
                        int nIndex,
                        LONG_PTR newLong)
 {
   nsPluginNativeWindowWin * win =
-    (nsPluginNativeWindowWin *)GetProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
+    (nsPluginNativeWindowWin *)GetPropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
   if (!win || (win && win->mPluginType != nsPluginHost::eSpecialType_Flash) ||
       (nIndex == GWLP_WNDPROC &&
        newLong == reinterpret_cast<LONG_PTR>(PluginWndProc)))
     return true;
   return false;
 }
 
 #ifdef _WIN64
@@ -417,17 +428,17 @@ SetWindowLongAHook(HWND hWnd,
   if (SetWindowLongHookCheck(hWnd, nIndex, newLong))
       return sUser32SetWindowLongAHookStub(hWnd, nIndex, newLong);
 
   // Set flash's new subclass to get the result.
   LONG_PTR proc = sUser32SetWindowLongAHookStub(hWnd, nIndex, newLong);
 
   // We already checked this in SetWindowLongHookCheck
   nsPluginNativeWindowWin * win =
-    (nsPluginNativeWindowWin *)GetProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
+    (nsPluginNativeWindowWin *)GetPropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
 
   // Hook our subclass back up, just like we do on setwindow.
   win->SetPrevWindowProc(
     reinterpret_cast<WNDPROC>(sUser32SetWindowLongWHookStub(hWnd, nIndex,
       reinterpret_cast<LONG_PTR>(PluginWndProc))));
   return proc;
 }
 
@@ -446,17 +457,17 @@ SetWindowLongWHook(HWND hWnd,
   if (SetWindowLongHookCheck(hWnd, nIndex, newLong))
       return sUser32SetWindowLongWHookStub(hWnd, nIndex, newLong);
 
   // Set flash's new subclass to get the result.
   LONG_PTR proc = sUser32SetWindowLongWHookStub(hWnd, nIndex, newLong);
 
   // We already checked this in SetWindowLongHookCheck
   nsPluginNativeWindowWin * win =
-    (nsPluginNativeWindowWin *)GetProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
+    (nsPluginNativeWindowWin *)GetPropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
 
   // Hook our subclass back up, just like we do on setwindow.
   win->SetPrevWindowProc(
     reinterpret_cast<WNDPROC>(sUser32SetWindowLongWHookStub(hWnd, nIndex,
       reinterpret_cast<LONG_PTR>(PluginWndProc))));
   return proc;
 }
 
@@ -691,31 +702,31 @@ nsresult nsPluginNativeWindowWin::Subcla
   else
     style |= WS_CLIPCHILDREN;
   SetWindowLongPtr(hWnd, GWL_STYLE, style);
 
   mPluginWinProc = (WNDPROC)SetWindowLongPtr(hWnd, GWLP_WNDPROC, (LONG_PTR)PluginWndProc);
   if (!mPluginWinProc)
     return NS_ERROR_FAILURE;
 
-  DebugOnly<nsPluginNativeWindowWin *> win = (nsPluginNativeWindowWin *)::GetProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
+  DebugOnly<nsPluginNativeWindowWin *> win = (nsPluginNativeWindowWin *)::GetPropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
   NS_ASSERTION(!win || (win == this), "plugin window already has property and this is not us");
 
-  if (!::SetProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION, (HANDLE)this))
+  if (!::SetPropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION, (HANDLE)this))
     return NS_ERROR_FAILURE;
 
   return NS_OK;
 }
 
 nsresult nsPluginNativeWindowWin::UndoSubclassAndAssociateWindow()
 {
   // remove window property
   HWND hWnd = (HWND)window;
   if (IsWindow(hWnd))
-    ::RemoveProp(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
+    ::RemovePropW(hWnd, NS_PLUGIN_WINDOW_PROPERTY_ASSOCIATION);
 
   // restore the original win proc
   // but only do this if this were us last time
   if (mPluginWinProc) {
     WNDPROC currentWndProc = (WNDPROC)::GetWindowLongPtr(hWnd, GWLP_WNDPROC);
     if (currentWndProc == PluginWndProc)
       SetWindowLongPtr(hWnd, GWLP_WNDPROC, (LONG_PTR)mPluginWinProc);
     mPluginWinProc = nullptr;
diff --git a/gfx/2d/2D.h b/gfx/2d/2D.h
--- a/gfx/2d/2D.h
+++ b/gfx/2d/2D.h
@@ -21,16 +21,20 @@
 
 // This RefPtr class isn't ideal for usage in Azure, as it doesn't allow T**
 // outparams using the &-operator. But it will have to do as there's no easy
 // solution.
 #include "mozilla/RefPtr.h"
 
 #include "mozilla/DebugOnly.h"
 
+#include "mozilla/SSE.h"
+
+#include <string.h>
+
 #ifdef MOZ_ENABLE_FREETYPE
 #include <string>
 #endif
 
 struct _cairo_surface;
 typedef _cairo_surface cairo_surface_t;
 
 struct _cairo_scaled_font;
@@ -987,18 +991,22 @@ public:
    * its own performance impact though, and ideally callers would be smart
    * enough not to require it.  At a future date this method may stop this
    * doing transform buffering so, if you're a consumer, please try to be smart
    * about calling this method as little as possible.  For example, instead of
    * concatenating a translation onto the current transform then calling
    * FillRect, try to integrate the translation into FillRect's aRect
    * argument's x/y offset.
    */
-  virtual void SetTransform(const Matrix &aTransform)
-    { mTransform = aTransform; mTransformDirty = true; }
+  virtual void SetTransform(const Matrix &aTransform) {
+    if (memcmp(&mTransform, &aTransform, sizeof(Matrix)) != 0) {
+      mTransform = aTransform;
+      mTransformDirty = true;
+    }
+  }
 
   inline void ConcatTransform(const Matrix &aTransform)
     { SetTransform(aTransform * Matrix(GetTransform())); }
 
   SurfaceFormat GetFormat() const { return mFormat; }
 
   /** Tries to get a native surface for a DrawTarget, this may fail if the
    * draw target cannot convert to this surface type.
@@ -1080,17 +1088,17 @@ struct TileSet
 {
   Tile* mTiles;
   size_t mTileCount;
 };
 
 class GFX2D_API Factory
 {
 public:
-  static bool HasSSE2();
+  static bool HasSSE2() { return supports_sse2(); }
 
   /** Make sure that the given dimensions don't overflow a 32-bit signed int
    * using 4 bytes per pixel; optionally, make sure that either dimension
    * doesn't exceed the given limit.
    */
   static bool CheckSurfaceSize(const IntSize &sz, int32_t limit = 0);
 
   /** Make sure the given dimension satisfies the CheckSurfaceSize and is
diff --git a/gfx/2d/BaseRect.h b/gfx/2d/BaseRect.h
--- a/gfx/2d/BaseRect.h
+++ b/gfx/2d/BaseRect.h
@@ -5,16 +5,19 @@
 
 #ifndef MOZILLA_GFX_BASERECT_H_
 #define MOZILLA_GFX_BASERECT_H_
 
 #include <algorithm>
 #include <cmath>
 #include <ostream>
 
+#include <stddef.h>
+#include <emmintrin.h>
+
 #include "mozilla/Assertions.h"
 #include "mozilla/FloatingPoint.h"
 #include "mozilla/TypeTraits.h"
 #include "Types.h"
 
 namespace mozilla {
 namespace gfx {
 
@@ -50,16 +53,55 @@ struct BaseRect {
   BaseRect(const Point& aOrigin, const SizeT &aSize) :
       x(aOrigin.x), y(aOrigin.y), width(aSize.width), height(aSize.height)
   {
   }
   BaseRect(T aX, T aY, T aWidth, T aHeight) :
       x(aX), y(aY), width(aWidth), height(aHeight)
   {
   }
+  BaseRect(const __m128i& a128i)
+  {
+    _mm_storeu_si128((__m128i *)&x, a128i);
+  }
+
+  bool IsInt32x4() const {
+    return _is_int32<T>::value &&
+           offsetof(Sub, x) == offsetof(Sub, y) - 4 &&
+           offsetof(Sub, x) == offsetof(Sub, width) - 8 &&
+           offsetof(Sub, x) == offsetof(Sub, height) - 12;
+  }
+  template <typename T>
+  struct _is_int32 {
+    enum { value = false };
+  };
+  template <>
+  struct _is_int32<long> {
+    enum { value = (sizeof(long) == 4) };
+  };
+  template <>
+  struct _is_int32<long const> {
+    enum { value = (sizeof(long) == 4) };
+  };
+  template <>
+  struct _is_int32<int> {
+    enum { value = (sizeof(int) == 4) };
+  };
+  template <>
+  struct _is_int32<int const> {
+    enum { value = (sizeof(int) == 4) };
+  };
+  template <>
+  struct _is_int32<long long> {
+    enum { value = (sizeof(long long) == 4) };
+  };
+  template <>
+  struct _is_int32<long long const> {
+    enum { value = (sizeof(long long) == 4) };
+  };
 
   // Emptiness. An empty rect is one that has no area, i.e. its height or width
   // is <= 0
   bool IsEmpty() const { return height <= 0 || width <= 0; }
   void SetEmpty() { width = height = 0; }
 
   // "Finite" means not inf and not NaN
   bool IsFinite() const
diff --git a/gfx/2d/Blur.cpp b/gfx/2d/Blur.cpp
--- a/gfx/2d/Blur.cpp
+++ b/gfx/2d/Blur.cpp
@@ -7,16 +7,17 @@
 #include "Blur.h"
 
 #include <algorithm>
 #include <math.h>
 #include <string.h>
 
 #include "mozilla/CheckedInt.h"
 #include "mozilla/Constants.h"
+#include "nsAutoPtr.h"
 
 #include "2D.h"
 #include "DataSurfaceHelpers.h"
 #include "Tools.h"
 
 #ifdef BUILD_ARM_NEON
 #include "mozilla/arm.h"
 #endif
@@ -34,35 +35,43 @@ namespace gfx {
  * @param aLeftLobe The number of pixels to blend on the left.
  * @param aRightLobe The number of pixels to blend on the right.
  * @param aWidth The number of columns in the buffers.
  * @param aRows The number of rows in the buffers.
  * @param aSkipRect An area to skip blurring in.
  * XXX shouldn't we pass stride in separately here?
  */
 static void
-BoxBlurHorizontal(unsigned char* aInput,
-                  unsigned char* aOutput,
+BoxBlurHorizontal(unsigned char* TT_RESTRICTED_PTR aInput,
+                  unsigned char* TT_RESTRICTED_PTR aOutput,
                   int32_t aLeftLobe,
                   int32_t aRightLobe,
                   int32_t aWidth,
                   int32_t aRows,
-                  const IntRect& aSkipRect)
+                  const IntRect& aSkipRect,
+                  int32_t* TT_RESTRICTED_PTR aLasts,
+                  int32_t* TT_RESTRICTED_PTR aNexts)
 {
     MOZ_ASSERT(aWidth > 0);
 
     int32_t boxSize = aLeftLobe + aRightLobe + 1;
     bool skipRectCoversWholeRow = 0 >= aSkipRect.x &&
                                   aWidth <= aSkipRect.XMost();
     if (boxSize == 1) {
         memcpy(aOutput, aInput, aWidth*aRows);
         return;
     }
     uint32_t reciprocal = uint32_t((uint64_t(1) << 32) / boxSize);
 
+    for (int32_t x = 0; x < aWidth; x++) {
+        int32_t tmp = x - aLeftLobe;
+        aLasts[x] = max(tmp, 0);
+        aNexts[x] = min(tmp + boxSize, aWidth - 1);
+    }
+
     for (int32_t y = 0; y < aRows; y++) {
         // Check whether the skip rect intersects this row. If the skip
         // rect covers the whole surface in this row, we can avoid
         // this row entirely (and any others along the skip rect).
         bool inSkipRectY = y >= aSkipRect.y &&
                            y < aSkipRect.YMost();
         if (inSkipRectY && skipRectCoversWholeRow) {
             y = aSkipRect.YMost() - 1;
@@ -94,53 +103,58 @@ BoxBlurHorizontal(unsigned char* aInput,
                     int32_t pos = x + i - aLeftLobe;
                     // See assertion above; if aWidth is zero, then we would have no
                     // valid position to clamp to.
                     pos = max(pos, 0);
                     pos = min(pos, aWidth - 1);
                     alphaSum += aInput[aWidth * y + pos];
                 }
             }
-            int32_t tmp = x - aLeftLobe;
-            int32_t last = max(tmp, 0);
-            int32_t next = min(tmp + boxSize, aWidth - 1);
 
             aOutput[aWidth * y + x] = (uint64_t(alphaSum) * reciprocal) >> 32;
 
-            alphaSum += aInput[aWidth * y + next] -
-                        aInput[aWidth * y + last];
+            alphaSum += aInput[aWidth * y + aNexts[x]] -
+                        aInput[aWidth * y + aLasts[x]];
         }
     }
 }
 
 /**
  * Identical to BoxBlurHorizontal, except it blurs top and bottom instead of
  * left and right.
  * XXX shouldn't we pass stride in separately here?
  */
 static void
-BoxBlurVertical(unsigned char* aInput,
-                unsigned char* aOutput,
+BoxBlurVertical(unsigned char* TT_RESTRICTED_PTR aInput,
+                unsigned char* TT_RESTRICTED_PTR aOutput,
                 int32_t aTopLobe,
                 int32_t aBottomLobe,
                 int32_t aWidth,
                 int32_t aRows,
-                const IntRect& aSkipRect)
+                const IntRect& aSkipRect,
+                int32_t* TT_RESTRICTED_PTR aLasts,
+                int32_t* TT_RESTRICTED_PTR aNexts)
 {
     MOZ_ASSERT(aRows > 0);
 
     int32_t boxSize = aTopLobe + aBottomLobe + 1;
     bool skipRectCoversWholeColumn = 0 >= aSkipRect.y &&
                                      aRows <= aSkipRect.YMost();
     if (boxSize == 1) {
         memcpy(aOutput, aInput, aWidth*aRows);
         return;
     }
     uint32_t reciprocal = uint32_t((uint64_t(1) << 32) / boxSize);
 
+    for (int32_t y = 0; y < aRows; y++) {
+        int32_t tmp = y - aTopLobe;
+        aLasts[y] = max(tmp, 0);
+        aNexts[y] = min(tmp + boxSize, aRows - 1);
+    }
+
     for (int32_t x = 0; x < aWidth; x++) {
         bool inSkipRectX = x >= aSkipRect.x &&
                            x < aSkipRect.XMost();
         if (inSkipRectX && skipRectCoversWholeColumn) {
             x = aSkipRect.XMost() - 1;
             continue;
         }
 
@@ -165,24 +179,21 @@ BoxBlurVertical(unsigned char* aInput,
                     int32_t pos = y + i - aTopLobe;
                     // See assertion above; if aRows is zero, then we would have no
                     // valid position to clamp to.
                     pos = max(pos, 0);
                     pos = min(pos, aRows - 1);
                     alphaSum += aInput[aWidth * pos + x];
                 }
             }
-            int32_t tmp = y - aTopLobe;
-            int32_t last = max(tmp, 0);
-            int32_t next = min(tmp + boxSize, aRows - 1);
 
             aOutput[aWidth * y + x] = (uint64_t(alphaSum) * reciprocal) >> 32;
 
-            alphaSum += aInput[aWidth * next + x] -
-                        aInput[aWidth * last + x];
+            alphaSum += aInput[aWidth * aNexts[y] + x] -
+                        aInput[aWidth * aLasts[y] + x];
         }
     }
 }
 
 static void ComputeLobes(int32_t aRadius, int32_t aLobes[3][2])
 {
     int32_t major, minor, final;
 
@@ -504,31 +515,41 @@ AlphaBoxBlur::Blur(uint8_t* aData)
       size_t szB = stride * size.height;
       uint8_t* tmpData = new (std::nothrow) uint8_t[szB];
       if (!tmpData) {
         return;
       }
 
       memset(tmpData, 0, szB);
 
+      size_t szLastsNexts = 0;
+      if (mBlurRadius.width > 0) {
+        szLastsNexts = stride;
+      }
+      if (mBlurRadius.height > 0) {
+        szLastsNexts = max<size_t>(szLastsNexts, GetSize().height);
+      }
+      nsAutoArrayPtr<int32_t> tmpLasts(new int32_t[szLastsNexts]);
+      nsAutoArrayPtr<int32_t> tmpNexts(new int32_t[szLastsNexts]);
+
       uint8_t* a = aData;
       uint8_t* b = tmpData;
       if (mBlurRadius.width > 0) {
-        BoxBlurHorizontal(a, b, horizontalLobes[0][0], horizontalLobes[0][1], stride, GetSize().height, mSkipRect);
-        BoxBlurHorizontal(b, a, horizontalLobes[1][0], horizontalLobes[1][1], stride, GetSize().height, mSkipRect);
-        BoxBlurHorizontal(a, b, horizontalLobes[2][0], horizontalLobes[2][1], stride, GetSize().height, mSkipRect);
+        BoxBlurHorizontal(a, b, horizontalLobes[0][0], horizontalLobes[0][1], stride, GetSize().height, mSkipRect, tmpLasts, tmpNexts);
+        BoxBlurHorizontal(b, a, horizontalLobes[1][0], horizontalLobes[1][1], stride, GetSize().height, mSkipRect, tmpLasts, tmpNexts);
+        BoxBlurHorizontal(a, b, horizontalLobes[2][0], horizontalLobes[2][1], stride, GetSize().height, mSkipRect, tmpLasts, tmpNexts);
       } else {
         a = tmpData;
         b = aData;
       }
       // The result is in 'b' here.
       if (mBlurRadius.height > 0) {
-        BoxBlurVertical(b, a, verticalLobes[0][0], verticalLobes[0][1], stride, GetSize().height, mSkipRect);
-        BoxBlurVertical(a, b, verticalLobes[1][0], verticalLobes[1][1], stride, GetSize().height, mSkipRect);
-        BoxBlurVertical(b, a, verticalLobes[2][0], verticalLobes[2][1], stride, GetSize().height, mSkipRect);
+        BoxBlurVertical(b, a, verticalLobes[0][0], verticalLobes[0][1], stride, GetSize().height, mSkipRect, tmpLasts, tmpNexts);
+        BoxBlurVertical(a, b, verticalLobes[1][0], verticalLobes[1][1], stride, GetSize().height, mSkipRect, tmpLasts, tmpNexts);
+        BoxBlurVertical(b, a, verticalLobes[2][0], verticalLobes[2][1], stride, GetSize().height, mSkipRect, tmpLasts, tmpNexts);
       } else {
         a = b;
       }
       // The result is in 'a' here.
       if (a == tmpData) {
         memcpy(aData, tmpData, szB);
       }
       delete [] tmpData;
diff --git a/gfx/2d/DrawTargetD2D.cpp b/gfx/2d/DrawTargetD2D.cpp
--- a/gfx/2d/DrawTargetD2D.cpp
+++ b/gfx/2d/DrawTargetD2D.cpp
@@ -18,16 +18,18 @@
 #include <algorithm>
 #include "mozilla/Constants.h"
 #include "FilterNodeSoftware.h"
 
 #include "FilterNodeD2D1.h"
 #include "ExtendInputEffectD2D1.h"
 
 #include <dwrite.h>
+#include <tmmintrin.h>
+#include "mozilla/SSE.h"
 
 // decltype is not usable for overloaded functions.
 typedef HRESULT (WINAPI*D2D1CreateFactoryFunc)(
     D2D1_FACTORY_TYPE factoryType,
     REFIID iid,
     CONST D2D1_FACTORY_OPTIONS *pFactoryOptions,
     void **factory
 );
@@ -2437,29 +2439,92 @@ DrawTargetD2D::CreateBrushForPattern(con
     }
     return bmBrush.forget();
   }
 
   gfxWarning() << "Invalid pattern type detected.";
   return nullptr;
 }
 
+static const float f_zero = 0;
+static const float f_one = 1.0f;
+static const __m128 xm_4095_rcp_mul = _mm_set_ss(1.0f / 4095);
+static const __m128 xm_255x4 = _mm_set1_ps(255.0f);
+static const __m128i sfl_pack4 = _mm_set_epi8(0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 0x80, 12, 0, 4, 8);
+
 TemporaryRef<ID3D10Texture2D>
 DrawTargetD2D::CreateGradientTexture(const GradientStopsD2D *aStops)
 {
   CD3D10_TEXTURE2D_DESC desc(DXGI_FORMAT_B8G8R8A8_UNORM, 4096, 1, 1, 1);
 
   std::vector<D2D1_GRADIENT_STOP> rawStops;
   rawStops.resize(aStops->mStopCollection->GetGradientStopCount());
   aStops->mStopCollection->GetGradientStops(&rawStops.front(), rawStops.size());
 
-  std::vector<unsigned char> textureData;
-  textureData.resize(4096 * 4);
-  unsigned char *texData = &textureData.front();
-
+  unsigned char *textureData = new unsigned char [4096 * 4];
+  unsigned char *texData = textureData;
+
+if (mozilla::supports_sse2())
+{
+  bool has_ssse3 = mozilla::supports_ssse3();
+  __m128 prevColorPos = _mm_load_ss(&f_zero);
+  __m128 nextColorPos = _mm_load_ss(&f_one);
+  __m128 prevColor = _mm_loadu_ps((float*)&rawStops[0].color);
+  __m128 nextColor = prevColor;
+
+  if (rawStops.size() >= 2) {
+    nextColor = _mm_loadu_ps((float*)&rawStops[1].color);
+    nextColorPos = _mm_load_ss(&rawStops[1].position);
+  }
+
+  uint32_t stopPosition = 2;
+  __m128 interp_rcp_mul = _mm_div_ss(_mm_load_ss(&f_one), _mm_sub_ss(nextColorPos, prevColorPos));
+
+  // Not the most optimized way but this will do for now.
+  for (int i = 0; i < 4096; i++) {
+    // The 4095 seems a little counter intuitive, but we want the gradient
+    // color at offset 0 at the first pixel, and at offset 1.0f at the last
+    // pixel.
+    __m128 pos;
+    pos = _mm_cvtsi32_ss(pos, i);
+    pos = _mm_mul_ss(pos, xm_4095_rcp_mul);
+
+    if (_mm_comigt_ss(pos, nextColorPos)) {
+      prevColor = nextColor;
+      prevColorPos = nextColorPos;
+      if (rawStops.size() > stopPosition) {
+        nextColor = _mm_loadu_ps((float*)&rawStops[stopPosition].color);
+        nextColorPos = _mm_load_ss(&rawStops[stopPosition++].position);
+      } else {
+        nextColorPos = _mm_load_ss(&f_one);
+      }
+      interp_rcp_mul = _mm_div_ss(_mm_load_ss(&f_one), _mm_sub_ss(nextColorPos, prevColorPos));
+    }
+
+    __m128 interp = _mm_mul_ss(_mm_sub_ss(pos, prevColorPos), interp_rcp_mul);
+    interp = _mm_shuffle_ps(interp, interp, _MM_SHUFFLE(0, 0, 0, 0));
+
+    __m128 newColor = _mm_add_ps(_mm_mul_ps(_mm_sub_ps(nextColor, prevColor), interp), prevColor);
+    newColor = _mm_mul_ps(newColor, xm_255x4);
+
+    if (has_ssse3) {
+      __m128i xmResult = _mm_cvttps_epi32(newColor);
+      xmResult = _mm_shuffle_epi8(xmResult, sfl_pack4);
+      *((uint32_t*)&texData[i * 4]) = _mm_cvtsi128_si32(xmResult);
+    } else {
+      newColor = _mm_shuffle_ps(newColor, newColor, _MM_SHUFFLE(3, 0, 1, 2));
+      __m128i xmResult = _mm_cvttps_epi32(newColor);
+      xmResult = _mm_packs_epi32(xmResult, _mm_setzero_si128());
+      xmResult = _mm_packus_epi16(xmResult, _mm_setzero_si128());
+      *((uint32_t*)&texData[i * 4]) = _mm_cvtsi128_si32(xmResult);
+    }
+  }
+}
+else
+{
   float prevColorPos = 0;
   float nextColorPos = 1.0f;
   D2D1_COLOR_F prevColor = rawStops[0].color;
   D2D1_COLOR_F nextColor = prevColor;
 
   if (rawStops.size() >= 2) {
     nextColor = rawStops[1].color;
     nextColorPos = rawStops[1].position;
@@ -2498,24 +2563,27 @@ DrawTargetD2D::CreateGradientTexture(con
                     prevColor.b + (nextColor.b - prevColor.b) * interp,
                     prevColor.a + (nextColor.a - prevColor.a) * interp);
 
     texData[i * 4] = (char)(255.0f * newColor.b);
     texData[i * 4 + 1] = (char)(255.0f * newColor.g);
     texData[i * 4 + 2] = (char)(255.0f * newColor.r);
     texData[i * 4 + 3] = (char)(255.0f * newColor.a);
   }
+}
 
   D3D10_SUBRESOURCE_DATA data;
-  data.pSysMem = &textureData.front();
+  data.pSysMem = textureData;
   data.SysMemPitch = 4096 * 4;
 
   RefPtr<ID3D10Texture2D> tex;
   mDevice->CreateTexture2D(&desc, &data, byRef(tex));
 
+  delete [] textureData;
+
   return tex.forget();
 }
 
 TemporaryRef<ID3D10Texture2D>
 DrawTargetD2D::CreateTextureForAnalysis(IDWriteGlyphRunAnalysis *aAnalysis, const IntRect &aBounds)
 {
   HRESULT hr;
 
diff --git a/gfx/2d/Factory.cpp b/gfx/2d/Factory.cpp
--- a/gfx/2d/Factory.cpp
+++ b/gfx/2d/Factory.cpp
@@ -181,40 +181,16 @@ void PreferenceAccess::SetAccess(Prefere
 #ifdef WIN32
 ID3D10Device1 *Factory::mD3D10Device;
 ID3D11Device *Factory::mD3D11Device;
 ID2D1Device *Factory::mD2D1Device;
 #endif
 
 DrawEventRecorder *Factory::mRecorder;
 
-bool
-Factory::HasSSE2()
-{
-#if defined(__SSE2__) || defined(_M_X64) || \
-    (defined(_M_IX86_FP) && _M_IX86_FP >= 2)
-  // gcc with -msse2 (default on OSX and x86-64)
-  // cl.exe with -arch:SSE2 (default on x64 compiler)
-  return true;
-#elif defined(HAVE_CPU_DETECTION)
-  static enum {
-    UNINITIALIZED,
-    NO_SSE2,
-    HAS_SSE2
-  } sDetectionState = UNINITIALIZED;
-
-  if (sDetectionState == UNINITIALIZED) {
-    sDetectionState = HasCPUIDBit(1u, edx, (1u<<26)) ? HAS_SSE2 : NO_SSE2;
-  }
-  return sDetectionState == HAS_SSE2;
-#else
-  return false;
-#endif
-}
-
 // If the size is "reasonable", we want gfxCriticalError to assert, so
 // this is the option set up for it.
 inline int LoggerOptionsBasedOnSize(const IntSize& aSize)
 {
   return CriticalLog::DefaultOptions(Factory::ReasonableSurfaceSize(aSize));
 }
 
 bool
diff --git a/gfx/angle/src/libEGL/Surface.cpp b/gfx/angle/src/libEGL/Surface.cpp
--- a/gfx/angle/src/libEGL/Surface.cpp
+++ b/gfx/angle/src/libEGL/Surface.cpp
@@ -3,16 +3,17 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 //
 
 // Surface.cpp: Implements the egl::Surface class, representing a drawing surface
 // such as the client area of a window, including any back buffers.
 // Implements EGLSurface and related functionality. [EGL 1.4] section 2.2 page 3.
 
+#include <algorithm>
 #include <tchar.h>
 
 #include <algorithm>
 
 #include "libEGL/Surface.h"
 
 #include "common/debug.h"
 #include "libGLESv2/Texture.h"
diff --git a/gfx/cairo/cairo/src/cairo-d2d-private.h b/gfx/cairo/cairo/src/cairo-d2d-private.h
--- a/gfx/cairo/cairo/src/cairo-d2d-private.h
+++ b/gfx/cairo/cairo/src/cairo-d2d-private.h
@@ -37,16 +37,17 @@
 #define CAIRO_D2D_PRIVATE_H
 
 #ifdef CAIRO_HAS_D2D_SURFACE
 
 #include <windows.h>
 #include <d2d1.h>
 #include <d3d10.h>
 #include <dxgi.h>
+#include <list>
 
 #include "cairoint.h"
 #include "cairo-surface-clipper-private.h"
 
 #include "cairo-win32-refptr.h"
 #include "cairo-d2d-private-fx.h"
 #include "cairo-win32.h"
 #include "cairo-list-private.h"
@@ -68,16 +69,28 @@ struct _cairo_d2d_device
     RefPtr<ID3D10RasterizerState> mRasterizerState;
     RefPtr<ID3D10BlendState> mBlendStates[MAX_OPERATORS];
     /** Texture used for manual glyph rendering */
     RefPtr<ID3D10Texture2D> mTextTexture;
     RefPtr<ID3D10ShaderResourceView> mTextTextureView;
     int mVRAMUsage;
 };
 
+typedef struct
+{
+    RefPtr<ID2D1RadialGradientBrush> radialGradientBrush;
+    RefPtr<ID2D1GradientStopCollection> radialGradientStopCollection;
+} radial_gradient;
+
+typedef struct
+{
+    RefPtr<ID2D1LinearGradientBrush> linearGradientBrush;
+    RefPtr<ID2D1GradientStopCollection> linearGradientStopCollection;
+} linear_gradient;
+
 const unsigned int TEXT_TEXTURE_WIDTH = 2048;
 const unsigned int TEXT_TEXTURE_HEIGHT = 512;
 typedef struct _cairo_d2d_device cairo_d2d_device_t;
 
 struct _cairo_d2d_surface {
     _cairo_d2d_surface() : d2d_clip(NULL), clipping(false), isDrawing(false),
             textRenderingState(TEXT_RENDERING_UNINITIALIZED)
     {
@@ -125,16 +138,22 @@ struct _cairo_d2d_surface {
      */
     RefPtr<ID2D1Layer> helperLayer;
     /** If this layer currently is clipping, used to prevent excessive push/pops */
     bool clipping;
     /** Brush used for bitmaps */
     RefPtr<ID2D1BitmapBrush> bitmapBrush;
     /** Brush used for solid colors */
     RefPtr<ID2D1SolidColorBrush> solidColorBrush;
+
+    /** Brush used for radial gradients */
+    std::list<radial_gradient> mRadialGradientCache;
+    /** Brush used for linear gradients */
+    std::list<linear_gradient> mLinearGradientCache;
+
     /** Indicates if our render target is currently in drawing mode */
     bool isDrawing;
     /** Indicates if text rendering is initialized */
     enum TextRenderingState {
         TEXT_RENDERING_UNINITIALIZED,
         TEXT_RENDERING_NO_CLEARTYPE,
         TEXT_RENDERING_NORMAL,
         TEXT_RENDERING_GDI_CLASSIC
diff --git a/gfx/cairo/cairo/src/cairo-d2d-surface.cpp b/gfx/cairo/cairo/src/cairo-d2d-surface.cpp
--- a/gfx/cairo/cairo/src/cairo-d2d-surface.cpp
+++ b/gfx/cairo/cairo/src/cairo-d2d-surface.cpp
@@ -1536,29 +1536,64 @@ static RefPtr<ID2D1Brush>
 	    stops[i].color = _cairo_d2d_color_from_cairo_color_stop(stop->color);
 	}
 	stops[i].position = 1.0f;
 	stops[i].color = D2D1::ColorF(0, 0);
     } else {
 	return NULL;
     }
 
-    RefPtr<ID2D1GradientStopCollection> stopCollection;
-    d2dsurf->rt->CreateGradientStopCollection(stops, num_stops, &stopCollection);
-    RefPtr<ID2D1RadialGradientBrush> brush;
-
-    d2dsurf->rt->CreateRadialGradientBrush(D2D1::RadialGradientBrushProperties(center,
-									       origin,
-									       outer_radius,
-									       outer_radius),
-					   brushProps,
-					   stopCollection,
-					   &brush);
+    std::list<radial_gradient>::iterator iterRadialGradient = d2dsurf->mRadialGradientCache.end();
+
+    if (d2dsurf->mRadialGradientCache.size() > 0) {
+        for (std::list<radial_gradient>::iterator iter = d2dsurf->mRadialGradientCache.begin();
+             iter != d2dsurf->mRadialGradientCache.end(); iter++) {
+            UINT32 nCount = (*iter).radialGradientStopCollection->GetGradientStopCount();
+
+            if (nCount == num_stops &&
+                nCount > 0) {
+                D2D1_GRADIENT_STOP *gradientStopsOld = new D2D1_GRADIENT_STOP[nCount];
+
+                (*iter).radialGradientStopCollection->GetGradientStops(gradientStopsOld, nCount);
+                bool stopCollectionEqual = (memcmp(gradientStopsOld, stops, sizeof(D2D1_GRADIENT_STOP) * nCount) == 0);
+                delete [] gradientStopsOld;
+                if (stopCollectionEqual) {
+                    iterRadialGradient = iter;
+                    break;
+                }
+            }
+        }
+    }
+
+    if (iterRadialGradient != d2dsurf->mRadialGradientCache.end()) {
+        (*iterRadialGradient).radialGradientBrush->SetOpacity(brushProps.opacity);
+        (*iterRadialGradient).radialGradientBrush->SetTransform(&brushProps.transform);
+        (*iterRadialGradient).radialGradientBrush->SetCenter(center);
+        (*iterRadialGradient).radialGradientBrush->SetGradientOriginOffset(origin);
+        (*iterRadialGradient).radialGradientBrush->SetRadiusX(outer_radius);
+        (*iterRadialGradient).radialGradientBrush->SetRadiusY(outer_radius);
+    } else {
+        radial_gradient rg;
+
+        d2dsurf->rt->CreateGradientStopCollection(stops, num_stops, &rg.radialGradientStopCollection);
+        d2dsurf->rt->CreateRadialGradientBrush(D2D1::RadialGradientBrushProperties(center,
+            origin,
+            outer_radius,
+            outer_radius),
+            brushProps,
+            rg.radialGradientStopCollection,
+            &rg.radialGradientBrush);
+
+        iterRadialGradient = d2dsurf->mRadialGradientCache.insert(d2dsurf->mRadialGradientCache.begin(), rg);
+        if (d2dsurf->mRadialGradientCache.size() > 50) {
+            d2dsurf->mRadialGradientCache.pop_back();
+        }
+    }
     delete [] stops;
-    return brush;
+    return (*iterRadialGradient).radialGradientBrush;
 }
 
 static RefPtr<ID2D1Brush>
 _cairo_d2d_create_linear_gradient_brush(cairo_d2d_surface_t *d2dsurf,
 					cairo_path_fixed_t *fill_path,
 					cairo_linear_pattern_t *source_pattern)
 {
     if (source_pattern->p1.x == source_pattern->p2.x &&
@@ -1713,26 +1748,60 @@ static RefPtr<ID2D1Brush>
 	for (unsigned int i = 1; i < source_pattern->base.n_stops + 1; i++) {
 	    cairo_gradient_stop_t *stop = &source_pattern->base.stops[i - 1];
 	    stops[i].position = (FLOAT)stop->offset;
 	    stops[i].color = _cairo_d2d_color_from_cairo_color_stop(stop->color);
 	}
 	stops[source_pattern->base.n_stops + 1].position = 1.0f;
 	stops[source_pattern->base.n_stops + 1].color = D2D1::ColorF(0, 0);
     }
-    RefPtr<ID2D1GradientStopCollection> stopCollection;
-    d2dsurf->rt->CreateGradientStopCollection(stops, num_stops, &stopCollection);
-    RefPtr<ID2D1LinearGradientBrush> brush;
-    d2dsurf->rt->CreateLinearGradientBrush(D2D1::LinearGradientBrushProperties(D2D1::Point2F((FLOAT)p1.x, (FLOAT)p1.y),
-									       D2D1::Point2F((FLOAT)p2.x, (FLOAT)p2.y)),
-					   brushProps,
-					   stopCollection,
-					   &brush);
+
+    std::list<linear_gradient>::iterator iterLinearGradient = d2dsurf->mLinearGradientCache.end();
+
+    if (d2dsurf->mLinearGradientCache.size() > 0) {
+        for (std::list<linear_gradient>::iterator iter = d2dsurf->mLinearGradientCache.begin();
+             iter != d2dsurf->mLinearGradientCache.end(); iter++) {
+            UINT32 nCount = (*iter).linearGradientStopCollection->GetGradientStopCount();
+
+            if (nCount == num_stops &&
+                nCount > 0) {
+                D2D1_GRADIENT_STOP *gradientStopsOld = new D2D1_GRADIENT_STOP[nCount];
+
+                (*iter).linearGradientStopCollection->GetGradientStops(gradientStopsOld, nCount);
+                bool stopCollectionEqual = (memcmp(gradientStopsOld, stops, sizeof(D2D1_GRADIENT_STOP) * nCount) == 0);
+                delete [] gradientStopsOld;
+                if (stopCollectionEqual) {
+                    iterLinearGradient = iter;
+                    break;
+                }
+            }
+        }
+    }
+
+    if (iterLinearGradient != d2dsurf->mLinearGradientCache.end()) {
+        (*iterLinearGradient).linearGradientBrush->SetOpacity(brushProps.opacity);
+        (*iterLinearGradient).linearGradientBrush->SetTransform(&brushProps.transform);
+        (*iterLinearGradient).linearGradientBrush->SetStartPoint(D2D1::Point2F((FLOAT)p1.x, (FLOAT)p1.y));
+        (*iterLinearGradient).linearGradientBrush->SetEndPoint(D2D1::Point2F((FLOAT)p2.x, (FLOAT)p2.y));
+    } else {
+        linear_gradient lg;
+
+        d2dsurf->rt->CreateGradientStopCollection(stops, num_stops, &lg.linearGradientStopCollection);
+        d2dsurf->rt->CreateLinearGradientBrush(D2D1::LinearGradientBrushProperties(D2D1::Point2F((FLOAT)p1.x, (FLOAT)p1.y), D2D1::Point2F((FLOAT)p2.x, (FLOAT)p2.y)),
+            brushProps,
+            lg.linearGradientStopCollection,
+            &lg.linearGradientBrush);
+
+        iterLinearGradient = d2dsurf->mLinearGradientCache.insert(d2dsurf->mLinearGradientCache.begin(), lg);
+        if (d2dsurf->mLinearGradientCache.size() > 100) {
+            d2dsurf->mLinearGradientCache.pop_back();
+        }
+    }
     delete [] stops;
-    return brush;
+    return (*iterLinearGradient).linearGradientBrush;
 }
 
 /**
  * This creates an ID2D1Brush that will fill with the correct pattern.
  * This function passes a -strong- reference to the caller, the brush
  * needs to be released, even if it is not unique.
  *
  * \param d2dsurf Surface to create a brush for
diff --git a/gfx/cairo/libpixman/src/moz.build b/gfx/cairo/libpixman/src/moz.build
--- a/gfx/cairo/libpixman/src/moz.build
+++ b/gfx/cairo/libpixman/src/moz.build
@@ -146,8 +146,27 @@ if CONFIG['GNU_CC']:
         '-Wno-missing-field-initializers',
     ]
     if CONFIG['CLANG_CXX']:
         CFLAGS += [
             '-Wno-incompatible-pointer-types',
             '-Wno-tautological-compare',
             '-Wno-tautological-constant-out-of-range-compare',
         ]
+
+if CONFIG['_MSC_VER']:
+    if '-DTT_MEMUTIL' in CONFIG['MOZ_OPTIMIZE_FLAGS']:
+        SOURCES['pixman-implementation.c'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
+        SOURCES['pixman-general.c'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
+        SOURCES['pixman-trap.c'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
+        SOURCES['pixman-sse2.c'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
diff --git a/gfx/cairo/libpixman/src/pixman-edge.c b/gfx/cairo/libpixman/src/pixman-edge.c
--- a/gfx/cairo/libpixman/src/pixman-edge.c
+++ b/gfx/cairo/libpixman/src/pixman-edge.c
@@ -161,16 +161,18 @@ rasterize_edges_8 (pixman_image_t *image
 {
     pixman_fixed_t y = t;
     uint32_t  *line;
     int fill_start = -1, fill_end = -1;
     int fill_size = 0;
     uint32_t *buf = (image)->bits.bits;
     int stride = (image)->bits.rowstride;
     int width = (image)->bits.width;
+    pixman_fixed_t rx_old = 0;
+    int rxs_old = 0, rxi_old = 0;
 
     line = buf + pixman_fixed_to_int (y) * stride;
 
     for (;;)
     {
         uint8_t *ap = (uint8_t *) line;
         pixman_fixed_t lx, rx;
         int lxi, rxi;
@@ -192,22 +194,39 @@ rasterize_edges_8 (pixman_image_t *image
 	}
 
         /* Skip empty (or backwards) sections */
         if (rx > lx)
         {
             int lxs, rxs;
 
             /* Find pixel bounds for span. */
-            lxi = pixman_fixed_to_int (lx);
-            rxi = pixman_fixed_to_int (rx);
+            /* Sample coverage for edge pixels */
+            if (lx == 0)
+            {
+                lxi = 0;
+                lxs = 0;
+            }
+            else
+            {
+                lxi = pixman_fixed_to_int (lx);
+                lxs = RENDER_SAMPLES_X (lx, 8);
+            }
 
-            /* Sample coverage for edge pixels */
-            lxs = RENDER_SAMPLES_X (lx, 8);
-            rxs = RENDER_SAMPLES_X (rx, 8);
+            if (rx == rx_old)
+            {
+                rxi = rxi_old;
+                rxs = rxs_old;
+            }
+            else
+            {
+                rxi_old = rxi = pixman_fixed_to_int (rx);
+                rxs_old = rxs = RENDER_SAMPLES_X (rx, 8);
+                rx_old = rx;
+            }
 
             /* Add coverage across row */
             if (lxi == rxi)
             {
                 WRITE (image, ap + lxi,
 		       clip255 (READ (image, ap + lxi) + rxs - lxs));
 	    }
             else
diff --git a/gfx/cairo/libpixman/src/pixman-implementation.c b/gfx/cairo/libpixman/src/pixman-implementation.c
--- a/gfx/cairo/libpixman/src/pixman-implementation.c
+++ b/gfx/cairo/libpixman/src/pixman-implementation.c
@@ -22,16 +22,24 @@
  */
 
 #ifdef HAVE_CONFIG_H
 #include <config.h>
 #endif
 #include <stdlib.h>
 #include "pixman-private.h"
 
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+#include <omp.h>
+#endif
+
+#ifdef _MSC_VER
+#include <windows.h>
+#endif
+
 pixman_implementation_t *
 _pixman_implementation_create (pixman_implementation_t *fallback,
 			       const pixman_fast_path_t *fast_paths)
 {
     pixman_implementation_t *imp;
 
     assert (fast_paths);
 
@@ -371,21 +379,194 @@ pixman_bool_t
 	    env += len;
 	}
 	while (*env++);
     }
 
     return FALSE;
 }
 
+#ifdef _MSC_VER
+
+#ifdef TT_MEMUTIL
+uint32_t dwNonTemporalDataSizeMin = NON_TEMPORAL_STORES_NOT_SUPPORTED;
+uint32_t dwNonTemporalMemcpySizeMin = NON_TEMPORAL_STORES_NOT_SUPPORTED;
+#endif
+typedef BOOL (WINAPI *LPFN_GLPI)(PSYSTEM_LOGICAL_PROCESSOR_INFORMATION, PDWORD);
+
+int Initialize_TT()
+{
+#ifdef TT_MEMUTIL
+    int omp_thread_counts = 0;
+    DWORD pam, sam;
+
+    long env_omp_num_threads = 0;
+    wchar_t *lpwz_env = _wgetenv(L"OMP_NUM_THREADS");
+    if (lpwz_env)
+    {
+      env_omp_num_threads = _wtol(lpwz_env);
+    }
+
+    omp_set_dynamic(0);
+    omp_set_num_threads(1);
+
+    if (GetProcessAffinityMask(GetCurrentProcess(), &pam, &sam))
+    {
+        LPFN_GLPI glpi =
+            (LPFN_GLPI)GetProcAddress(GetModuleHandle("kernel32.dll"),
+            "GetLogicalProcessorInformation");
+        DWORD returnLength = 0;
+        int *pThreadBindIndex = NULL;
+
+        if (NULL != glpi &&
+            !glpi(NULL, &returnLength) &&
+            GetLastError() == ERROR_INSUFFICIENT_BUFFER)
+        {
+            PSYSTEM_LOGICAL_PROCESSOR_INFORMATION buffer =
+                (PSYSTEM_LOGICAL_PROCESSOR_INFORMATION)malloc(returnLength);
+
+            if (glpi(buffer, &returnLength))
+            {
+                DWORD byteOffset;
+                PSYSTEM_LOGICAL_PROCESSOR_INFORMATION ptr;
+                int i;
+                size_t threadBindIndexSize;
+
+                byteOffset = 0;
+                ptr = buffer;
+                while (byteOffset < returnLength)
+                {
+                    if (RelationProcessorCore == ptr->Relationship)
+                    {
+                        omp_thread_counts++;
+                    }
+                    byteOffset += sizeof(SYSTEM_LOGICAL_PROCESSOR_INFORMATION);
+                    ptr++;
+                }
+
+                threadBindIndexSize = sizeof(int) * omp_thread_counts;
+                pThreadBindIndex = (int *)malloc(threadBindIndexSize);
+                memset(pThreadBindIndex, 0xFF, threadBindIndexSize);
+
+                i = 0;
+                byteOffset = 0;
+                ptr = buffer;
+                while (byteOffset < returnLength)
+                {
+                    if (RelationProcessorCore == ptr->Relationship)
+                    {
+                        if (i < omp_thread_counts)
+                        {
+                            int b;
+
+                            for (b = 0; b <= 31; b++)
+                            {
+                                if ((pam & ptr->ProcessorMask) & (1 << b))
+                                {
+                                    pThreadBindIndex[i++] = b;
+                                    break;
+                                }
+                            }
+                        }
+                        else
+                        {
+                            break;
+                        }
+                    }
+                    byteOffset += sizeof(SYSTEM_LOGICAL_PROCESSOR_INFORMATION);
+                    ptr++;
+                }
+            }
+            free(buffer);
+        }
+
+        if (NULL == pThreadBindIndex)
+        {
+            int b;
+            int i;
+            size_t threadBindIndexSize;
+
+            for (b = 0; b <= 31; b++)
+            {
+                if (pam & (1 << b)) omp_thread_counts++;
+            }
+
+            threadBindIndexSize = sizeof(int) * omp_thread_counts;
+            pThreadBindIndex = (int *)malloc(threadBindIndexSize);
+            memset(pThreadBindIndex, 0xFF, threadBindIndexSize);
+
+            for (i = 0; i < omp_thread_counts; i++)
+            {
+                pThreadBindIndex[i] = i;
+            }
+        }
+
+        if (NULL != pThreadBindIndex)
+        {
+            if (omp_thread_counts >= 1)
+            {
+                OSVERSIONINFO osvi = { sizeof(OSVERSIONINFO) };
+                BOOL bIsWindows7orLater = FALSE;
+
+                omp_set_dynamic(0);
+                if (0 != env_omp_num_threads)
+                {
+                    omp_thread_counts = env_omp_num_threads;
+                }
+                omp_set_num_threads(omp_thread_counts);
+                omp_thread_counts = omp_get_max_threads();
+
+                GetVersionEx(&osvi);
+                bIsWindows7orLater =
+                    (VER_PLATFORM_WIN32_NT == osvi.dwPlatformId) &&
+                    ((6 == osvi.dwMajorVersion && osvi.dwMinorVersion >= 1) || (osvi.dwMajorVersion >= 7));
+                if (!bIsWindows7orLater)
+                {
+#pragma omp parallel
+                    {
+                        SetThreadIdealProcessor(GetCurrentThread(),
+                            pThreadBindIndex[omp_get_thread_num()]);
+                    }
+                }
+            }
+            free(pThreadBindIndex);
+        }
+    }
+#endif /* TT_MEMUTIL */
+
+#ifdef TT_MEMUTIL
+    dwNonTemporalMemcpySizeMin = dwNonTemporalDataSizeMin = GetNonTemporalDataSizeMin_tt();
+    if (dwNonTemporalMemcpySizeMin != NON_TEMPORAL_STORES_NOT_SUPPORTED)
+    {
+        dwNonTemporalMemcpySizeMin = dwNonTemporalDataSizeMin / 2;
+    }
+#endif
+
+    return 0;
+}
+
+#endif /* _MSC_VER */
+
 pixman_implementation_t *
 _pixman_choose_implementation (void)
 {
     pixman_implementation_t *imp;
 
+#ifdef _MSC_VER
+    {
+        static pixman_bool_t initialized = FALSE;
+
+        if (!initialized)
+        {
+            Initialize_TT();
+            initialized = TRUE;
+        }
+    }
+#endif
+
     imp = _pixman_implementation_create_general();
 
     if (!_pixman_disabled ("fast"))
 	imp = _pixman_implementation_create_fast_path (imp);
 
     imp = _pixman_x86_get_implementations (imp);
     imp = _pixman_arm_get_implementations (imp);
     imp = _pixman_ppc_get_implementations (imp);
diff --git a/gfx/cairo/libpixman/src/pixman-private.h b/gfx/cairo/libpixman/src/pixman-private.h
--- a/gfx/cairo/libpixman/src/pixman-private.h
+++ b/gfx/cairo/libpixman/src/pixman-private.h
@@ -1179,9 +1179,16 @@ void pixman_timer_register (pixman_timer
 
 #define TIMER_BEGIN(tname)
 #define TIMER_END(tname)
 
 #endif /* PIXMAN_TIMERS */
 
 #endif /* __ASSEMBLER__ */
 
+#ifdef TT_MEMUTIL
+extern pixman_bool_t nt_initialized;
+extern uint32_t dwNonTemporalDataSizeMin;
+extern uint32_t dwNonTemporalMemcpySizeMin;
+void InitializeNonTemporalData();
+#endif /* TT_MEMUTIL */
+
 #endif /* PIXMAN_PRIVATE_H */
diff --git a/gfx/cairo/libpixman/src/pixman-sse2.c b/gfx/cairo/libpixman/src/pixman-sse2.c
--- a/gfx/cairo/libpixman/src/pixman-sse2.c
+++ b/gfx/cairo/libpixman/src/pixman-sse2.c
@@ -375,16 +375,23 @@ load_128_unaligned (const __m128i* src)
  */
 static force_inline void
 save_128_write_combining (__m128i* dst,
                           __m128i  data)
 {
     _mm_stream_si128 (dst, data);
 }
 
+/* save 1 pixels using Write Combining memory */
+static force_inline void
+save_32_write_combining (int* dst, int data)
+{
+    _mm_stream_si32 (dst, data);
+}
+
 /* save 4 pixels on a 16-byte boundary aligned address */
 static force_inline void
 save_128_aligned (__m128i* dst,
                   __m128i  data)
 {
     _mm_store_si128 (dst, data);
 }
 
@@ -4677,16 +4684,20 @@ sse2_composite_add_n_8_8888 (pixman_impl
 		      unpack_32_1x128 (*dst)));
 	    }
 	    dst++;
 	    w--;
 	}
     }
 }
 
+#ifdef TT_MEMUTIL
+extern uint32_t dwNonTemporalMemcpySizeMin;
+#endif
+
 static pixman_bool_t
 sse2_blt (pixman_implementation_t *imp,
           uint32_t *               src_bits,
           uint32_t *               dst_bits,
           int                      src_stride,
           int                      dst_stride,
           int                      src_bpp,
           int                      dst_bpp,
@@ -4695,16 +4706,19 @@ sse2_blt (pixman_implementation_t *imp,
           int                      dest_x,
           int                      dest_y,
           int                      width,
           int                      height)
 {
     uint8_t *   src_bytes;
     uint8_t *   dst_bytes;
     int byte_width;
+#ifdef TT_MEMUTIL
+    pixman_bool_t use_nontemporal_copy;
+#endif
 
     if (src_bpp != dst_bpp)
 	return FALSE;
 
     if (src_bpp == 16)
     {
 	src_stride = src_stride * (int) sizeof (uint32_t) / 2;
 	dst_stride = dst_stride * (int) sizeof (uint32_t) / 2;
@@ -4724,16 +4738,20 @@ sse2_blt (pixman_implementation_t *imp,
 	src_stride *= 4;
 	dst_stride *= 4;
     }
     else
     {
 	return FALSE;
     }
 
+#ifdef TT_MEMUTIL
+    use_nontemporal_copy = ((uint32_t)(byte_width * height) > dwNonTemporalMemcpySizeMin);
+#endif
+
     while (height--)
     {
 	int w;
 	uint8_t *s = src_bytes;
 	uint8_t *d = dst_bytes;
 	src_bytes += src_stride;
 	dst_bytes += dst_stride;
 	w = byte_width;
@@ -4741,34 +4759,88 @@ sse2_blt (pixman_implementation_t *imp,
 	while (w >= 2 && ((uintptr_t)d & 3))
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
 
+#ifdef TT_MEMUTIL
+if (use_nontemporal_copy)
+{
 	while (w >= 4 && ((uintptr_t)d & 15))
 	{
-	    *(uint32_t *)d = *(uint32_t *)s;
+	    save_32_write_combining ((int*)d, *(int*)s);
 
 	    w -= 4;
 	    s += 4;
 	    d += 4;
 	}
 
 	while (w >= 64)
 	{
 	    __m128i xmm0, xmm1, xmm2, xmm3;
 
+	    _mm_prefetch((char const *)s + (200*64/34+192), _MM_HINT_NTA);
+
 	    xmm0 = load_128_unaligned ((__m128i*)(s));
 	    xmm1 = load_128_unaligned ((__m128i*)(s + 16));
 	    xmm2 = load_128_unaligned ((__m128i*)(s + 32));
 	    xmm3 = load_128_unaligned ((__m128i*)(s + 48));
 
+	    save_128_write_combining ((__m128i*)(d),    xmm0);
+	    save_128_write_combining ((__m128i*)(d + 16), xmm1);
+	    save_128_write_combining ((__m128i*)(d + 32), xmm2);
+	    save_128_write_combining ((__m128i*)(d + 48), xmm3);
+
+	    s += 64;
+	    d += 64;
+	    w -= 64;
+	}
+
+	while (w >= 16)
+	{
+	    save_128_write_combining ((__m128i*)d, load_128_unaligned ((__m128i*)s) );
+
+	    w -= 16;
+	    d += 16;
+	    s += 16;
+	}
+
+	while (w >= 4)
+	{
+	    save_32_write_combining ((int*)d, *(int*)s);
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+}
+else
+#endif
+{
+	while (w >= 4 && ((uintptr_t)d & 15))
+	{
+	    *(uint32_t *)d = *(uint32_t *)s;
+
+	    w -= 4;
+	    s += 4;
+	    d += 4;
+	}
+
+	while (w >= 64)
+	{
+	    __m128i xmm0, xmm1, xmm2, xmm3;
+
+	    xmm0 = load_128_unaligned ((__m128i*)(s));
+	    xmm1 = load_128_unaligned ((__m128i*)(s + 16));
+	    xmm2 = load_128_unaligned ((__m128i*)(s + 32));
+	    xmm3 = load_128_unaligned ((__m128i*)(s + 48));
+
 	    save_128_aligned ((__m128i*)(d),    xmm0);
 	    save_128_aligned ((__m128i*)(d + 16), xmm1);
 	    save_128_aligned ((__m128i*)(d + 32), xmm2);
 	    save_128_aligned ((__m128i*)(d + 48), xmm3);
 
 	    s += 64;
 	    d += 64;
 	    w -= 64;
@@ -4786,26 +4858,34 @@ sse2_blt (pixman_implementation_t *imp,
 	while (w >= 4)
 	{
 	    *(uint32_t *)d = *(uint32_t *)s;
 
 	    w -= 4;
 	    s += 4;
 	    d += 4;
 	}
+}
 
 	if (w >= 2)
 	{
 	    *(uint16_t *)d = *(uint16_t *)s;
 	    w -= 2;
 	    s += 2;
 	    d += 2;
 	}
     }
 
+#ifdef TT_MEMUTIL
+    if (use_nontemporal_copy)
+    {
+        _mm_sfence();
+    }
+#endif
+
     return TRUE;
 }
 
 static void
 sse2_composite_copy_area (pixman_implementation_t *imp,
                           pixman_composite_info_t *info)
 {
     PIXMAN_COMPOSITE_ARGS (info);
diff --git a/gfx/cairo/libpixman/src/pixman-trap.c b/gfx/cairo/libpixman/src/pixman-trap.c
--- a/gfx/cairo/libpixman/src/pixman-trap.c
+++ b/gfx/cairo/libpixman/src/pixman-trap.c
@@ -20,75 +20,123 @@
  * TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
  * PERFORMANCE OF THIS SOFTWARE.
  */
 
 #ifdef HAVE_CONFIG_H
 #include <config.h>
 #endif
 
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+#include <omp.h>
+#endif
+#include <limits.h>
+
 #include <stdio.h>
 #include <stdlib.h>
 #include "pixman-private.h"
 
 /*
  * Compute the smallest value greater than or equal to y which is on a
  * grid row.
  */
 
 PIXMAN_EXPORT pixman_fixed_t
 pixman_sample_ceil_y (pixman_fixed_t y, int n)
 {
     pixman_fixed_t f = pixman_fixed_frac (y);
     pixman_fixed_t i = pixman_fixed_floor (y);
 
+if (8 == n)
+{
+    f = DIV (f - Y_FRAC_FIRST (8) + (STEP_Y_SMALL (8) - pixman_fixed_e), STEP_Y_SMALL (8)) * STEP_Y_SMALL (8) +
+	Y_FRAC_FIRST (8);
+    
+    if (f > Y_FRAC_LAST (8))
+    {
+	if (pixman_fixed_to_int (i) == 0x7fff)
+	{
+	    f = 0xffff; /* saturate */
+	}
+	else
+	{
+	    f = Y_FRAC_FIRST (8);
+	    i += pixman_fixed_1;
+	}
+    }
+}
+else
+{
     f = DIV (f - Y_FRAC_FIRST (n) + (STEP_Y_SMALL (n) - pixman_fixed_e), STEP_Y_SMALL (n)) * STEP_Y_SMALL (n) +
 	Y_FRAC_FIRST (n);
     
     if (f > Y_FRAC_LAST (n))
     {
 	if (pixman_fixed_to_int (i) == 0x7fff)
 	{
 	    f = 0xffff; /* saturate */
 	}
 	else
 	{
 	    f = Y_FRAC_FIRST (n);
 	    i += pixman_fixed_1;
 	}
     }
+}
     return (i | f);
 }
 
 /*
  * Compute the largest value strictly less than y which is on a
  * grid row.
  */
 PIXMAN_EXPORT pixman_fixed_t
 pixman_sample_floor_y (pixman_fixed_t y,
                        int            n)
 {
     pixman_fixed_t f = pixman_fixed_frac (y);
     pixman_fixed_t i = pixman_fixed_floor (y);
 
+if (8 == n)
+{
+    f = DIV (f - pixman_fixed_e - Y_FRAC_FIRST (8), STEP_Y_SMALL (8)) * STEP_Y_SMALL (8) +
+	Y_FRAC_FIRST (8);
+
+    if (f < Y_FRAC_FIRST (8))
+    {
+	if (pixman_fixed_to_int (i) == 0x8000)
+	{
+	    f = 0; /* saturate */
+	}
+	else
+	{
+	    f = Y_FRAC_LAST (8);
+	    i -= pixman_fixed_1;
+	}
+    }
+}
+else
+{
     f = DIV (f - pixman_fixed_e - Y_FRAC_FIRST (n), STEP_Y_SMALL (n)) * STEP_Y_SMALL (n) +
 	Y_FRAC_FIRST (n);
 
     if (f < Y_FRAC_FIRST (n))
     {
 	if (pixman_fixed_to_int (i) == 0x8000)
 	{
 	    f = 0; /* saturate */
 	}
 	else
 	{
 	    f = Y_FRAC_LAST (n);
 	    i -= pixman_fixed_1;
 	}
     }
+}
+
     return (i | f);
 }
 
 /*
  * Step an edge by any amount (including negative values)
  */
 PIXMAN_EXPORT void
 pixman_edge_step (pixman_edge_t *e,
@@ -181,21 +229,32 @@ pixman_edge_init (pixman_edge_t *e,
 	else
 	{
 	    e->signdx = -1;
 	    e->stepx = -(-dx / dy);
 	    e->dx = -dx % dy;
 	    e->e = 0;
 	}
 
+if (8 == n)
+{
+	_pixman_edge_multi_init (e, STEP_Y_SMALL (8),
+				 &e->stepx_small, &e->dx_small);
+
+	_pixman_edge_multi_init (e, STEP_Y_BIG (8),
+				 &e->stepx_big, &e->dx_big);
+}
+else
+{
 	_pixman_edge_multi_init (e, STEP_Y_SMALL (n),
 				 &e->stepx_small, &e->dx_small);
 
 	_pixman_edge_multi_init (e, STEP_Y_BIG (n),
 				 &e->stepx_big, &e->dx_big);
+}
     }
     pixman_edge_step (e, y_start - y_top);
 }
 
 /*
  * Initialize one edge structure given a line, starting y value
  * and a pixel offset for the line
  */
@@ -322,25 +381,47 @@ pixman_add_trapezoids (pixman_image_t * 
                        const pixman_trapezoid_t *traps)
 {
     int i;
 
 #if 0
     dump_image (image, "before");
 #endif
 
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+int omp_thread_counts = omp_get_max_threads();
+if (omp_thread_counts >= 2 &&
+    ntraps >= omp_thread_counts &&
+    ntraps >= 160)
+{
+#pragma omp parallel for schedule(guided) default(none) \
+shared(ntraps, traps, image, x_off, y_off)
+    for (i = 0; i < ntraps; ++i)
+    {
+	const pixman_trapezoid_t *trap = &(traps[i]);
+
+	if (pixman_trapezoid_valid (trap))
+	{
+		pixman_rasterize_trapezoid (image, trap, x_off, y_off);
+	}
+    }
+}
+else
+#endif
+{
     for (i = 0; i < ntraps; ++i)
     {
 	const pixman_trapezoid_t *trap = &(traps[i]);
 
 	if (!pixman_trapezoid_valid (trap))
 	    continue;
 
 	pixman_rasterize_trapezoid (image, trap, x_off, y_off);
     }
+}
 
 #if 0
     dump_image (image, "after");
 #endif
 }
 
 PIXMAN_EXPORT void
 pixman_rasterize_trapezoid (pixman_image_t *          image,
diff --git a/gfx/qcms/moz.build b/gfx/qcms/moz.build
--- a/gfx/qcms/moz.build
+++ b/gfx/qcms/moz.build
@@ -56,8 +56,15 @@ if use_sse2:
             # with -m64 and without optimization.
             SOURCES['transform-sse2.c'].flags += ['-xO4']
         else:
             SOURCES['transform-sse2.c'].flags += ['-xarch=sse2']
 
 if use_altivec:
     SOURCES += ['transform-altivec.c']
     SOURCES['transform-altivec.c'].flags += ['-maltivec']
+
+if CONFIG['_MSC_VER']:
+    if '-DTT_MEMUTIL' in CONFIG['MOZ_OPTIMIZE_FLAGS']:
+        SOURCES['transform-sse2.c'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
diff --git a/gfx/qcms/transform-sse2.c b/gfx/qcms/transform-sse2.c
--- a/gfx/qcms/transform-sse2.c
+++ b/gfx/qcms/transform-sse2.c
@@ -1,8 +1,12 @@
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+#include <omp.h>
+#endif
+
 #include <emmintrin.h>
 
 #include "qcmsint.h"
 
 /* pre-shuffled: just load these into XMM reg instead of load-scalar/shufps sequence */
 #define FLOATSCALE  (float)(PRECACHE_OUTPUT_SIZE)
 #define CLAMPMAXVAL ( ((float) (PRECACHE_OUTPUT_SIZE - 1)) / PRECACHE_OUTPUT_SIZE )
 static const ALIGN float floatScaleX4[4] =
@@ -10,27 +14,18 @@ static const ALIGN float floatScaleX4[4]
 static const ALIGN float clampMaxValueX4[4] =
     { CLAMPMAXVAL, CLAMPMAXVAL, CLAMPMAXVAL, CLAMPMAXVAL};
 
 void qcms_transform_data_rgb_out_lut_sse2(qcms_transform *transform,
                                           unsigned char *src,
                                           unsigned char *dest,
                                           size_t length)
 {
-    unsigned int i;
+    int i;
     float (*mat)[4] = transform->matrix;
-    char input_back[32];
-    /* Ensure we have a buffer that's 16 byte aligned regardless of the original
-     * stack alignment. We can't use __attribute__((aligned(16))) or __declspec(align(32))
-     * because they don't work on stack variables. gcc 4.4 does do the right thing
-     * on x86 but that's too new for us right now. For more info: gcc bug #16660 */
-    float const * input = (float*)(((uintptr_t)&input_back[16]) & ~0xf);
-    /* share input and output locations to save having to keep the
-     * locations in separate registers */
-    uint32_t const * output = (uint32_t*)input;
 
     /* deref *transform now to avoid it in loop */
     const float *igtbl_r = transform->input_gamma_table_r;
     const float *igtbl_g = transform->input_gamma_table_g;
     const float *igtbl_b = transform->input_gamma_table_b;
 
     /* deref *transform now to avoid it in loop */
     const uint8_t *otdata_r = &transform->output_table_r->data[0];
@@ -42,88 +37,65 @@ void qcms_transform_data_rgb_out_lut_sse
     const __m128 mat1  = _mm_load_ps(mat[1]);
     const __m128 mat2  = _mm_load_ps(mat[2]);
 
     /* these values don't change, either */
     const __m128 max   = _mm_load_ps(clampMaxValueX4);
     const __m128 min   = _mm_setzero_ps();
     const __m128 scale = _mm_load_ps(floatScaleX4);
 
-    /* working variables */
-    __m128 vec_r, vec_g, vec_b, result;
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+    int omp_thread_counts;
+#endif
 
     /* CYA */
     if (!length)
         return;
 
-    /* one pixel is handled outside of the loop */
-    length--;
-
-    /* setup for transforming 1st pixel */
-    vec_r = _mm_load_ss(&igtbl_r[src[0]]);
-    vec_g = _mm_load_ss(&igtbl_g[src[1]]);
-    vec_b = _mm_load_ss(&igtbl_b[src[2]]);
-    src += 3;
-
-    /* transform all but final pixel */
-
+#if defined(TT_MEMUTIL) && defined(_MSC_VER)
+    omp_thread_counts = omp_get_max_threads();
+#pragma omp parallel for schedule(static) default(none) num_threads(2) \
+shared(length, igtbl_r, igtbl_g, igtbl_b, src, dest, otdata_r, otdata_g, otdata_b) \
+if (omp_thread_counts >= 2 && \
+    length >= (int32_t)omp_thread_counts && \
+    length >= 700)
+#endif // defined(TT_MEMUTIL) && defined(_MSC_VER)
     for (i=0; i<length; i++)
     {
+        __m128 vec_r, vec_g, vec_b;
+        __m128i result;
+
+        /* load */
+        vec_r = _mm_load_ss(&igtbl_r[src[i * 3 + 0]]);
+        vec_g = _mm_load_ss(&igtbl_g[src[i * 3 + 1]]);
+        vec_b = _mm_load_ss(&igtbl_b[src[i * 3 + 2]]);
+
         /* position values from gamma tables */
         vec_r = _mm_shuffle_ps(vec_r, vec_r, 0);
         vec_g = _mm_shuffle_ps(vec_g, vec_g, 0);
         vec_b = _mm_shuffle_ps(vec_b, vec_b, 0);
 
         /* gamma * matrix */
         vec_r = _mm_mul_ps(vec_r, mat0);
         vec_g = _mm_mul_ps(vec_g, mat1);
         vec_b = _mm_mul_ps(vec_b, mat2);
 
         /* crunch, crunch, crunch */
         vec_r  = _mm_add_ps(vec_r, _mm_add_ps(vec_g, vec_b));
         vec_r  = _mm_max_ps(min, vec_r);
         vec_r  = _mm_min_ps(max, vec_r);
-        result = _mm_mul_ps(vec_r, scale);
-
-        /* store calc'd output tables indices */
-        _mm_store_si128((__m128i*)output, _mm_cvtps_epi32(result));
-
-        /* load for next loop while store completes */
-        vec_r = _mm_load_ss(&igtbl_r[src[0]]);
-        vec_g = _mm_load_ss(&igtbl_g[src[1]]);
-        vec_b = _mm_load_ss(&igtbl_b[src[2]]);
-        src += 3;
+        result = _mm_cvtps_epi32(_mm_mul_ps(vec_r, scale));
 
         /* use calc'd indices to output RGB values */
-        dest[OUTPUT_R_INDEX] = otdata_r[output[0]];
-        dest[OUTPUT_G_INDEX] = otdata_g[output[1]];
-        dest[OUTPUT_B_INDEX] = otdata_b[output[2]];
-        dest += RGB_OUTPUT_COMPONENTS;
+        dest[i * RGB_OUTPUT_COMPONENTS + OUTPUT_R_INDEX] = otdata_r[_mm_cvtsi128_si32(result)];
+        result = _mm_srli_si128(result, 4);
+        dest[i * RGB_OUTPUT_COMPONENTS + OUTPUT_G_INDEX] = otdata_g[_mm_cvtsi128_si32(result)];
+        result = _mm_srli_si128(result, 4);
+        dest[i * RGB_OUTPUT_COMPONENTS + OUTPUT_B_INDEX] = otdata_b[_mm_cvtsi128_si32(result)];
     }
-
-    /* handle final (maybe only) pixel */
-
-    vec_r = _mm_shuffle_ps(vec_r, vec_r, 0);
-    vec_g = _mm_shuffle_ps(vec_g, vec_g, 0);
-    vec_b = _mm_shuffle_ps(vec_b, vec_b, 0);
-
-    vec_r = _mm_mul_ps(vec_r, mat0);
-    vec_g = _mm_mul_ps(vec_g, mat1);
-    vec_b = _mm_mul_ps(vec_b, mat2);
-
-    vec_r  = _mm_add_ps(vec_r, _mm_add_ps(vec_g, vec_b));
-    vec_r  = _mm_max_ps(min, vec_r);
-    vec_r  = _mm_min_ps(max, vec_r);
-    result = _mm_mul_ps(vec_r, scale);
-
-    _mm_store_si128((__m128i*)output, _mm_cvtps_epi32(result));
-
-    dest[OUTPUT_R_INDEX] = otdata_r[output[0]];
-    dest[OUTPUT_G_INDEX] = otdata_g[output[1]];
-    dest[OUTPUT_B_INDEX] = otdata_b[output[2]];
 }
 
 void qcms_transform_data_rgba_out_lut_sse2(qcms_transform *transform,
                                            unsigned char *src,
                                            unsigned char *dest,
                                            size_t length)
 {
     unsigned int i;
diff --git a/gfx/src/nsRegion.cpp b/gfx/src/nsRegion.cpp
--- a/gfx/src/nsRegion.cpp
+++ b/gfx/src/nsRegion.cpp
@@ -4,16 +4,20 @@
 
 
 #include "nsRegion.h"
 #include "nsPrintfCString.h"
 #include "nsTArray.h"
 #include "gfx3DMatrix.h"
 #include "gfxUtils.h"
 
+#if !defined(NS_COORD_IS_FLOAT) && defined(_MSC_VER) && defined(_M_IX86)
+#include <intrin.h>
+#endif
+
 bool nsRegion::Contains(const nsRegion& aRgn) const
 {
   // XXX this could be made faster
   nsRegionRectIterator iter(aRgn);
   while (const nsRect* r = iter.Next()) {
     if (!Contains (*r)) {
       return false;
     }
@@ -553,17 +557,21 @@ void nsRegion::SimplifyInward (uint32_t 
 }
 
 uint64_t nsRegion::Area () const
 {
   uint64_t area = 0;
   nsRegionRectIterator iter(*this);
   const nsRect* r;
   while ((r = iter.Next()) != nullptr) {
+#if !defined(NS_COORD_IS_FLOAT) && defined(_MSC_VER) && defined(_M_IX86)
+    area += __emul(r->width, r->height);
+#else
     area += uint64_t(r->width)*r->height;
+#endif
   }
   return area;
 }
 
 nsRegion& nsRegion::ScaleRoundOut (float aXScale, float aYScale)
 {
   if (mozilla::gfx::FuzzyEqual(aXScale, 1.0f) &&
       mozilla::gfx::FuzzyEqual(aYScale, 1.0f)) {
diff --git a/image/src/imgLoader.cpp b/image/src/imgLoader.cpp
--- a/image/src/imgLoader.cpp
+++ b/image/src/imgLoader.cpp
@@ -1601,25 +1601,27 @@ imgLoader::CheckCacheLimits(imgCacheTabl
   // Remove entries from the cache until we're back at our desired max size.
   while (queue.GetSize() > sCacheMaxSize) {
     // Remove the first entry in the queue.
     nsRefPtr<imgCacheEntry> entry(queue.Pop());
 
     NS_ASSERTION(entry, "imgLoader::CheckCacheLimits -- NULL entry pointer");
 
 #if defined(PR_LOGGING)
-    nsRefPtr<imgRequest> req(entry->GetRequest());
-    if (req) {
-      nsRefPtr<ImageURL> uri;
-      req->GetURI(getter_AddRefs(uri));
-      nsAutoCString spec;
-      uri->GetSpec(spec);
-      LOG_STATIC_FUNC_WITH_PARAM(GetImgLog(),
-                                 "imgLoader::CheckCacheLimits",
-                                 "entry", spec.get());
+    if (entry) {
+      nsRefPtr<imgRequest> req(entry->GetRequest());
+      if (req) {
+        nsRefPtr<ImageURL> uri;
+        req->GetURI(getter_AddRefs(uri));
+        nsAutoCString spec;
+        uri->GetSpec(spec);
+        LOG_STATIC_FUNC_WITH_PARAM(GetImgLog(),
+                                   "imgLoader::CheckCacheLimits",
+                                   "entry", spec.get());
+      }
     }
 #endif
 
     if (entry) {
       RemoveFromCache(entry);
     }
   }
 }
diff --git a/js/src/configure.in b/js/src/configure.in
--- a/js/src/configure.in
+++ b/js/src/configure.in
@@ -1769,21 +1769,16 @@ ia64*-hpux*)
         WIN32_CONSOLE_EXE_LDFLAGS=-SUBSYSTEM:CONSOLE,$WIN32_SUBSYSTEM_VERSION
         WIN32_GUI_EXE_LDFLAGS=-SUBSYSTEM:WINDOWS,$WIN32_SUBSYSTEM_VERSION
         DSO_LDOPTS=-SUBSYSTEM:WINDOWS,$WIN32_SUBSYSTEM_VERSION
         _USE_CPP_INCLUDE_FLAG=1
         _DEFINES_CFLAGS='-FI $(DEPTH)/js/src/js-confdefs.h -DMOZILLA_CLIENT'
         _DEFINES_CXXFLAGS='-FI $(DEPTH)/js/src/js-confdefs.h -DMOZILLA_CLIENT'
         CFLAGS="$CFLAGS -W3 -Gy"
         CXXFLAGS="$CXXFLAGS -W3 -Gy"
-        if test "$CPU_ARCH" = "x86"; then
-            dnl VS2012+ defaults to -arch:SSE2.
-            CFLAGS="$CFLAGS -arch:IA32"
-            CXXFLAGS="$CXXFLAGS -arch:IA32"
-        fi
         dnl VS2013+ requires -FS when parallel building by make -jN.
         dnl If nothing, compiler sometimes causes C1041 error.
         CFLAGS="$CFLAGS -FS"
         CXXFLAGS="$CXXFLAGS -FS"
         # khuey says we can safely ignore MSVC warning C4251
         # MSVC warning C4244 (implicit type conversion may lose data) warns
         # and requires workarounds for perfectly valid code.  Also, GCC/clang
         # don't warn about it by default. So for consistency/sanity, we turn
@@ -1809,26 +1804,30 @@ ia64*-hpux*)
         # autoconf insists on passing $LDFLAGS to the compiler.
         if test -z "$CLANG_CL"; then
             LDFLAGS="$LDFLAGS -LARGEADDRESSAWARE -NXCOMPAT"
             if test -z "$DEVELOPER_OPTIONS"; then
                 LDFLAGS="$LDFLAGS -RELEASE"
             fi
         fi
         dnl For profile-guided optimization
-        PROFILE_GEN_CFLAGS="-GL"
+        PROFILE_GEN_CFLAGS="-GL -DMSVC_PGO_ENABLED"
         PROFILE_GEN_LDFLAGS="-LTCG:PGINSTRUMENT"
+        if test "$_CC_SUITE" -ge "12"; then
+            dnl Run PGO profiling in safe mode
+            PROFILE_GEN_LDFLAGS="$PROFILE_GEN_LDFLAGS -PogoSafeMode"
+        fi
         dnl XXX: PGO builds can fail with warnings treated as errors,
         dnl specifically "no profile data available" appears to be
         dnl treated as an error sometimes. This might be a consequence
         dnl of using WARNINGS_AS_ERRORS in some modules, combined
         dnl with the linker doing most of the work in the whole-program
         dnl optimization/PGO case. I think it's probably a compiler bug,
         dnl but we work around it here.
-        PROFILE_USE_CFLAGS="-GL -wd4624 -wd4952"
+        PROFILE_USE_CFLAGS="-GL -wd4624 -wd4952 -DMSVC_PGO_ENABLED"
         dnl XXX: should be -LTCG:PGOPTIMIZE, but that fails on libxul.
         dnl Probably also a compiler bug, but what can you do?
         PROFILE_USE_LDFLAGS="-LTCG:PGUPDATE"
         LDFLAGS="$LDFLAGS -DYNAMICBASE"
     fi
     AC_DEFINE(HAVE_SNPRINTF)
     AC_DEFINE(HAVE__MSIZE)
     AC_DEFINE(_WINDOWS)
diff --git a/js/src/jit/CodeGenerator.cpp b/js/src/jit/CodeGenerator.cpp
--- a/js/src/jit/CodeGenerator.cpp
+++ b/js/src/jit/CodeGenerator.cpp
@@ -5168,55 +5168,90 @@ CodeGenerator::visitRandom(LRandom* ins)
 
 void
 CodeGenerator::visitMathFunctionD(LMathFunctionD* ins)
 {
     Register temp = ToRegister(ins->temp());
     FloatRegister input = ToFloatRegister(ins->input());
     MOZ_ASSERT(ToFloatRegister(ins->output()) == ReturnDoubleReg);
 
+    bool vectorcall = false;
+#ifndef JS_NO_VECTORCALL
+    switch (ins->mir()->function()) {
+      case MMathFunction::Log:
+      case MMathFunction::Sin:
+      case MMathFunction::Cos:
+      case MMathFunction::Exp:
+      case MMathFunction::Tan:
+      case MMathFunction::ATan:
+      case MMathFunction::ASin:
+      case MMathFunction::ACos:
+      case MMathFunction::Log10:
+        vectorcall = true;
+        break;
+    }
+#endif
+
     const MathCache* mathCache = ins->mir()->cache();
 
-    masm.setupUnalignedABICall(mathCache ? 2 : 1, temp);
-    if (mathCache) {
-        masm.movePtr(ImmPtr(mathCache), temp);
-        masm.passABIArg(temp);
-    }
-    masm.passABIArg(input, MoveOp::DOUBLE);
+    if (!vectorcall) {
+        masm.setupUnalignedABICall(mathCache ? 2 : 1, temp);
+        if (mathCache) {
+            masm.movePtr(ImmPtr(mathCache), temp);
+            masm.passABIArg(temp);
+        }
+        masm.passABIArg(input, MoveOp::DOUBLE);
+    }
+#ifndef JS_NO_VECTORCALL
+    else {
+        masm.setupAlignedVecCall(mathCache ? 2 : 1);
+        if (mathCache) {
+            masm.movePtr(ImmPtr(mathCache), temp);
+            masm.passVecArg(temp);
+        }
+        masm.passVecArg(input, MoveOp::DOUBLE);
+    }
+#endif
 
 #   define MAYBE_CACHED(fcn) (mathCache ? (void*)fcn ## _impl : (void*)fcn ## _uncached)
+    typedef double (JS_VECTORCALL* VECFUNC_IMPL)(MathCache*, double);
+    typedef double (JS_VECTORCALL* VECFUNC_UNCACHED)(double);
+    VECFUNC_IMPL fnImpl = nullptr;
+    VECFUNC_UNCACHED fnUncached = nullptr;
+#   define MAYBE_CACHED_VEC(fcn) (mathCache ? (void*)(fnImpl = fcn ## _impl) : \
+                                              (void*)(fnUncached = fcn ## _uncached))
 
     void* funptr = nullptr;
     switch (ins->mir()->function()) {
       case MMathFunction::Log:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_log));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_log));
         break;
       case MMathFunction::Sin:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_sin));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_sin));
         break;
       case MMathFunction::Cos:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_cos));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_cos));
         break;
       case MMathFunction::Exp:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_exp));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_exp));
         break;
       case MMathFunction::Tan:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_tan));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_tan));
         break;
       case MMathFunction::ATan:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_atan));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_atan));
         break;
       case MMathFunction::ASin:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_asin));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_asin));
         break;
       case MMathFunction::ACos:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_acos));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_acos));
         break;
       case MMathFunction::Log10:
-        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_log10));
+        funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED_VEC(js::math_log10));
         break;
       case MMathFunction::Log2:
         funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_log2));
         break;
       case MMathFunction::Log1P:
         funptr = JS_FUNC_TO_DATA_PTR(void*, MAYBE_CACHED(js::math_log1p));
         break;
       case MMathFunction::ExpM1:
@@ -5259,17 +5294,22 @@ CodeGenerator::visitMathFunctionD(LMathF
         funptr = JS_FUNC_TO_DATA_PTR(void*, js::math_round_impl);
         break;
       default:
         MOZ_CRASH("Unknown math function");
     }
 
 #   undef MAYBE_CACHED
 
-    masm.callWithABI(funptr, MoveOp::DOUBLE);
+    if (!vectorcall)
+        masm.callWithABI(funptr, MoveOp::DOUBLE);
+#ifndef JS_NO_VECTORCALL
+    else
+        masm.callWithVec(funptr, MoveOp::DOUBLE);
+#endif
 }
 
 void
 CodeGenerator::visitMathFunctionF(LMathFunctionF* ins)
 {
     Register temp = ToRegister(ins->temp());
     FloatRegister input = ToFloatRegister(ins->input());
     MOZ_ASSERT(ToFloatRegister(ins->output()) == ReturnFloat32Reg);
diff --git a/js/src/jit/Lowering.cpp b/js/src/jit/Lowering.cpp
--- a/js/src/jit/Lowering.cpp
+++ b/js/src/jit/Lowering.cpp
@@ -1411,17 +1411,21 @@ LIRGenerator::visitMathFunction(MMathFun
 {
     MOZ_ASSERT(IsFloatingPointType(ins->type()));
     MOZ_ASSERT(ins->type() == ins->input()->type());
 
     LInstruction* lir;
     if (ins->type() == MIRType_Double) {
         // Note: useRegisterAtStart is safe here, the temp is not a FP register.
         lir = new(alloc()) LMathFunctionD(useRegisterAtStart(ins->input()),
+#ifdef JS_NO_VECTORCALL
                                           tempFixed(CallTempReg0));
+#else
+                                          tempFixed(VecIntArgReg0));
+#endif
     } else {
         lir = new(alloc()) LMathFunctionF(useRegisterAtStart(ins->input()),
                                           tempFixed(CallTempReg0));
     }
     defineReturn(lir, ins);
 }
 
 // Try to mark an add or sub instruction as able to recover its input when
diff --git a/js/src/jit/x86/Assembler-x86.h b/js/src/jit/x86/Assembler-x86.h
--- a/js/src/jit/x86/Assembler-x86.h
+++ b/js/src/jit/x86/Assembler-x86.h
@@ -61,16 +61,35 @@ static MOZ_CONSTEXPR_VAR Register CallTe
 static MOZ_CONSTEXPR_VAR Register CallTempReg4 = esi;
 static MOZ_CONSTEXPR_VAR Register CallTempReg5 = edx;
 
 // We have no arg regs, so our NonArgRegs are just our CallTempReg*
 static MOZ_CONSTEXPR_VAR Register CallTempNonArgRegs[] = { edi, eax, ebx, ecx, esi, edx };
 static const uint32_t NumCallTempNonArgRegs =
     mozilla::ArrayLength(CallTempNonArgRegs);
 
+// Different argument registers for MSVC __vectorcall
+#if !defined(JS_NO_VECTORCALL)
+static MOZ_CONSTEXPR_VAR Register VecIntArgReg0 = ecx;
+static MOZ_CONSTEXPR_VAR Register VecIntArgReg1 = edx;
+static MOZ_CONSTEXPR_VAR Register VecIntArgRegs[] = { ecx, edx };
+static const uint32_t NumVecIntArgRegs =
+    mozilla::ArrayLength(VecIntArgRegs);
+
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgReg0 = xmm0;
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgReg1 = xmm1;
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgReg2 = xmm2;
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgReg3 = xmm3;
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgReg4 = xmm4;
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgReg5 = xmm5;
+static MOZ_CONSTEXPR_VAR FloatRegister VecFloatArgRegs[] = { xmm0, xmm1, xmm2, xmm3, xmm4, xmm5 };
+static const uint32_t NumVecFloatArgRegs =
+    mozilla::ArrayLength(VecFloatArgRegs);
+#endif
+
 class ABIArgGenerator
 {
     uint32_t stackOffset_;
     ABIArg current_;
 
   public:
     ABIArgGenerator();
     ABIArg next(MIRType argType);
diff --git a/js/src/jit/x86/MacroAssembler-x86.cpp b/js/src/jit/x86/MacroAssembler-x86.cpp
--- a/js/src/jit/x86/MacroAssembler-x86.cpp
+++ b/js/src/jit/x86/MacroAssembler-x86.cpp
@@ -353,16 +353,200 @@ void
 MacroAssemblerX86::callWithABI(Register fun, MoveOp::Type result)
 {
     uint32_t stackAdjust;
     callWithABIPre(&stackAdjust);
     call(Operand(fun));
     callWithABIPost(stackAdjust, result);
 }
 
+#if !defined(JS_NO_VECTORCALL)
+
+void
+MacroAssemblerX86::setupVecCall(uint32_t args)
+{
+    MOZ_ASSERT(!inCall_);
+    inCall_ = true;
+
+    args_ = args;
+    passedIntArgs_ = 0;
+    passedFloatArgs_ = 0;
+    stackForCall_ = 0;
+}
+
+void
+MacroAssemblerX86::setupAlignedVecCall(uint32_t args)
+{
+    setupVecCall(args);
+    dynamicAlignment_ = false;
+}
+
+void
+MacroAssemblerX86::setupUnalignedVecCall(uint32_t args, Register scratch)
+{
+    setupVecCall(args);
+    dynamicAlignment_ = true;
+
+    movl(esp, scratch);
+    andl(Imm32(~(ABIStackAlignment - 1)), esp);
+    push(scratch);
+}
+
+void
+MacroAssemblerX86::passVecArg(const MoveOperand& from, MoveOp::Type type)
+{
+    MoveOperand to;
+    switch (type) {
+      case MoveOp::FLOAT32:
+      case MoveOp::DOUBLE: {
+        FloatRegister dest;
+        if (GetVecFloatArgReg(passedIntArgs_, passedFloatArgs_++, &dest)) {
+            /*
+            // Convert to the right type of register.
+            if (type == MoveOp::FLOAT32)
+               dest = dest.asSingle();
+            */
+            if (from.isFloatReg() && from.floatReg() == dest) {
+                // Nothing to do; the value is in the right register already
+                return;
+            }
+            to = MoveOperand(dest);
+        } else {
+            to = MoveOperand(StackPointer, stackForCall_);
+            switch (type) {
+              case MoveOp::FLOAT32: stackForCall_ += sizeof(float);  break;
+              case MoveOp::DOUBLE:  stackForCall_ += sizeof(double); break;
+              default: MOZ_CRASH("Unexpected float register class argument type");
+            }
+        }
+        break;
+      }
+      case MoveOp::GENERAL: {
+        Register dest;
+        if (GetVecIntArgReg(passedIntArgs_++, passedFloatArgs_, &dest)) {
+            if (from.isGeneralReg() && from.reg() == dest) {
+                // Nothing to do; the value is in the right register already
+                return;
+            }
+            to = MoveOperand(dest);
+        } else {
+            to = MoveOperand(StackPointer, stackForCall_);
+            stackForCall_ += sizeof(int32_t);
+        }
+        break;
+      }
+      default:
+        MOZ_CRASH("Unexpected argument type");
+    }
+
+    enoughMemory_ = moveResolver_.addMove(from, to, type);
+}
+
+void
+MacroAssemblerX86::passVecArg(Register reg)
+{
+    passVecArg(MoveOperand(reg), MoveOp::GENERAL);
+}
+
+void
+MacroAssemblerX86::passVecArg(FloatRegister reg, MoveOp::Type type)
+{
+    passVecArg(MoveOperand(reg), type);
+}
+
+void
+MacroAssemblerX86::callWithVecPre(uint32_t* stackAdjust)
+{
+    MOZ_ASSERT(inCall_);
+    MOZ_ASSERT(args_ == passedIntArgs_ + passedFloatArgs_);
+
+    if (dynamicAlignment_) {
+        *stackAdjust = stackForCall_
+                     + ComputeByteAlignment(stackForCall_ + sizeof(intptr_t),
+                                            ABIStackAlignment);
+    } else {
+        *stackAdjust = stackForCall_
+                     + ComputeByteAlignment(stackForCall_ + framePushed_,
+                                            ABIStackAlignment);
+    }
+
+    reserveStack(*stackAdjust);
+
+    // Position all arguments.
+    {
+        enoughMemory_ &= moveResolver_.resolve();
+        if (!enoughMemory_)
+            return;
+
+        MoveEmitter emitter(asMasm());
+        emitter.emit(moveResolver_);
+        emitter.finish();
+    }
+
+#ifdef DEBUG
+    {
+        // Check call alignment.
+        Label good;
+        test32(esp, Imm32(ABIStackAlignment - 1));
+        j(Equal, &good);
+        breakpoint();
+        bind(&good);
+    }
+#endif
+}
+
+void
+MacroAssemblerX86::callWithVecPost(uint32_t stackAdjust, MoveOp::Type result)
+{
+    freeStack(stackAdjust);
+    if (dynamicAlignment_)
+        pop(esp);
+
+    MOZ_ASSERT(inCall_);
+    inCall_ = false;
+}
+
+void
+MacroAssemblerX86::callWithVec(void* fun, MoveOp::Type result)
+{
+    uint32_t stackAdjust;
+    callWithVecPre(&stackAdjust);
+    call(ImmPtr(fun));
+    callWithVecPost(stackAdjust, result);
+}
+
+void
+MacroAssemblerX86::callWithVec(AsmJSImmPtr fun, MoveOp::Type result)
+{
+    uint32_t stackAdjust;
+    callWithVecPre(&stackAdjust);
+    call(fun);
+    callWithVecPost(stackAdjust, result);
+}
+
+void
+MacroAssemblerX86::callWithVec(const Address& fun, MoveOp::Type result)
+{
+    uint32_t stackAdjust;
+    callWithVecPre(&stackAdjust);
+    call(Operand(fun));
+    callWithVecPost(stackAdjust, result);
+}
+
+void
+MacroAssemblerX86::callWithVec(Register fun, MoveOp::Type result)
+{
+    uint32_t stackAdjust;
+    callWithVecPre(&stackAdjust);
+    call(Operand(fun));
+    callWithVecPost(stackAdjust, result);
+}
+
+#endif // !defined(JS_NO_VECTORCALL)
+
 void
 MacroAssemblerX86::handleFailureWithHandlerTail(void* handler)
 {
     // Reserve space for exception information.
     subl(Imm32(sizeof(ResumeFromException)), esp);
     movl(esp, eax);
 
     // Call the handler.
diff --git a/js/src/jit/x86/MacroAssembler-x86.h b/js/src/jit/x86/MacroAssembler-x86.h
--- a/js/src/jit/x86/MacroAssembler-x86.h
+++ b/js/src/jit/x86/MacroAssembler-x86.h
@@ -24,16 +24,20 @@ class MacroAssemblerX86 : public MacroAs
     const MacroAssembler& asMasm() const;
 
   private:
     // Number of bytes the stack is adjusted inside a call to C. Calls to C may
     // not be nested.
     bool inCall_;
     uint32_t args_;
     uint32_t passedArgs_;
+#if !defined(JS_NO_VECTORCALL)
+    uint32_t passedIntArgs_;
+    uint32_t passedFloatArgs_;
+#endif
     uint32_t stackForCall_;
     bool dynamicAlignment_;
 
     struct Double {
         double value;
         AbsoluteLabel uses;
         Double(double value) : value(value) {}
     };
@@ -76,16 +80,19 @@ class MacroAssemblerX86 : public MacroAs
     Operand tagOf(const Address& address) {
         return Operand(address.base, address.offset + 4);
     }
     Operand tagOf(const BaseIndex& address) {
         return Operand(address.base, address.index, address.scale, address.offset + 4);
     }
 
     void setupABICall(uint32_t args);
+#if !defined(JS_NO_VECTORCALL)
+    void setupVecCall(uint32_t args);
+#endif
 
   public:
     using MacroAssemblerX86Shared::callWithExitFrame;
     using MacroAssemblerX86Shared::branch32;
     using MacroAssemblerX86Shared::branchTest32;
     using MacroAssemblerX86Shared::load32;
     using MacroAssemblerX86Shared::store32;
     using MacroAssemblerX86Shared::call;
@@ -1168,41 +1175,62 @@ class MacroAssemblerX86 : public MacroAs
     // Setup a call to C/C++ code, given the number of general arguments it
     // takes. Note that this only supports cdecl.
     //
     // In order for alignment to work correctly, the MacroAssembler must have a
     // consistent view of the stack displacement. It is okay to call "push"
     // manually, however, if the stack alignment were to change, the macro
     // assembler should be notified before starting a call.
     void setupAlignedABICall(uint32_t args);
+#if !defined(JS_NO_VECTORCALL)
+    void setupAlignedVecCall(uint32_t args);
+#endif
 
     // Sets up an ABI call for when the alignment is not known. This may need a
     // scratch register.
     void setupUnalignedABICall(uint32_t args, Register scratch);
+#if !defined(JS_NO_VECTORCALL)
+    void setupUnalignedVecCall(uint32_t args, Register scratch);
+#endif
 
     // Arguments must be assigned to a C/C++ call in order. They are moved
     // in parallel immediately before performing the call. This process may
     // temporarily use more stack, in which case esp-relative addresses will be
     // automatically adjusted. It is extremely important that esp-relative
     // addresses are computed *after* setupABICall(). Furthermore, no
     // operations should be emitted while setting arguments.
     void passABIArg(const MoveOperand& from, MoveOp::Type type);
     void passABIArg(Register reg);
     void passABIArg(FloatRegister reg, MoveOp::Type type);
+#if !defined(JS_NO_VECTORCALL)
+    void passVecArg(const MoveOperand& from, MoveOp::Type type);
+    void passVecArg(Register reg);
+    void passVecArg(FloatRegister reg, MoveOp::Type type);
+#endif
 
   private:
     void callWithABIPre(uint32_t* stackAdjust);
     void callWithABIPost(uint32_t stackAdjust, MoveOp::Type result);
+#if !defined(JS_NO_VECTORCALL)
+    void callWithVecPre(uint32_t* stackAdjust);
+    void callWithVecPost(uint32_t stackAdjust, MoveOp::Type result);
+#endif
 
   public:
     // Emits a call to a C/C++ function, resolving all argument moves.
     void callWithABI(void* fun, MoveOp::Type result = MoveOp::GENERAL);
     void callWithABI(AsmJSImmPtr fun, MoveOp::Type result = MoveOp::GENERAL);
     void callWithABI(const Address& fun, MoveOp::Type result = MoveOp::GENERAL);
     void callWithABI(Register fun, MoveOp::Type result = MoveOp::GENERAL);
+#if !defined(JS_NO_VECTORCALL)
+    void callWithVec(void* fun, MoveOp::Type result = MoveOp::GENERAL);
+    void callWithVec(AsmJSImmPtr fun, MoveOp::Type result = MoveOp::GENERAL);
+    void callWithVec(const Address& fun, MoveOp::Type result = MoveOp::GENERAL);
+    void callWithVec(Register fun, MoveOp::Type result = MoveOp::GENERAL);
+#endif
 
     // Used from within an Exit frame to handle a pending exception.
     void handleFailureWithHandlerTail(void* handler);
 
     void makeFrameDescriptor(Register frameSizeReg, FrameType type) {
         shll(Imm32(FRAMESIZE_SHIFT), frameSizeReg);
         orl(Imm32(type), frameSizeReg);
     }
@@ -1214,12 +1242,36 @@ class MacroAssemblerX86 : public MacroAs
 
     // Instrumentation for entering and leaving the profiler.
     void profilerEnterFrame(Register framePtr, Register scratch);
     void profilerExitFrame();
 };
 
 typedef MacroAssemblerX86 MacroAssemblerSpecific;
 
+#if !defined(JS_NO_VECTORCALL)
+
+static inline bool
+GetVecIntArgReg(uint32_t intArg, uint32_t floatArg, Register* out)
+{
+    uint32_t arg = intArg;
+    if (arg >= NumVecIntArgRegs)
+        return false;
+    *out = VecIntArgRegs[arg];
+    return true;
+}
+
+static inline bool
+GetVecFloatArgReg(uint32_t intArg, uint32_t floatArg, FloatRegister* out)
+{
+    uint32_t arg = floatArg;
+    if (floatArg >= NumVecFloatArgRegs)
+        return false;
+    *out = VecFloatArgRegs[arg];
+    return true;
+}
+
+#endif // !defined(JS_NO_VECTORCALL)
+
 } // namespace jit
 } // namespace js
 
 #endif /* jit_x86_MacroAssembler_x86_h */
diff --git a/js/src/jsmath.cpp b/js/src/jsmath.cpp
--- a/js/src/jsmath.cpp
+++ b/js/src/jsmath.cpp
@@ -36,16 +36,26 @@
 #include "jsobjinlines.h"
 
 #if defined(ANDROID) || defined(XP_MACOSX) || defined(__DragonFly__) || \
     defined(__FreeBSD__) || defined(__NetBSD__) || defined(__OpenBSD__)
 # include <stdlib.h>
 # define HAVE_ARC4RANDOM
 #endif
 
+#include "mozilla/SSE.h"
+
+#ifdef MOZILLA_MAY_SUPPORT_SSE4_1
+#include <smmintrin.h>
+#endif
+
+#if _MSC_VER < 1600 && _M_IX86_FP >= 2
+#pragma function(floor)
+#endif
+
 using namespace js;
 
 using mozilla::Abs;
 using mozilla::NumberEqualsInt32;
 using mozilla::NumberIsInt32;
 using mozilla::ExponentComponent;
 using mozilla::FloatingPoint;
 using mozilla::IsFinite;
@@ -65,16 +75,32 @@ static const JSConstDoubleSpec math_cons
     {"LN2"    ,  M_LN2     },
     {"LN10"   ,  M_LN10    },
     {"PI"     ,  M_PI      },
     {"SQRT2"  ,  M_SQRT2   },
     {"SQRT1_2",  M_SQRT1_2 },
     {0,0}
 };
 
+#ifdef JS_NO_VECTORCALL
+# define MATHCACHE_MAYBE_VEC_LOOKUP(cache, func, x, id) (cache)->lookup(func, x, id);
+#else
+# define MATHCACHE_MAYBE_VEC_LOOKUP(cache, func, x, id) (cache)->lookup<UnaryVecFunType>(func##_vec, x, id);
+# define MATH_VEC_FUNC(func) MOZ_ALWAYS_INLINE double __vectorcall func##_vec(double d) { return (func)(d); }
+MATH_VEC_FUNC(log)
+MATH_VEC_FUNC(sin)
+MATH_VEC_FUNC(cos)
+MATH_VEC_FUNC(exp)
+MATH_VEC_FUNC(tan)
+MATH_VEC_FUNC(atan)
+MATH_VEC_FUNC(asin)
+MATH_VEC_FUNC(acos)
+MATH_VEC_FUNC(log10)
+#endif
+
 MathCache::MathCache() {
     memset(table, 0, sizeof(table));
 
     /* See comments in lookup(). */
     MOZ_ASSERT(IsNegativeZero(-0.0));
     MOZ_ASSERT(!IsNegativeZero(+0.0));
     MOZ_ASSERT(hash(-0.0, MathCache::Sin) != hash(+0.0, MathCache::Sin));
 }
@@ -117,24 +143,24 @@ js::math_abs(JSContext* cx, unsigned arg
 }
 
 #if defined(SOLARIS) && defined(__GNUC__)
 #define ACOS_IF_OUT_OF_RANGE(x) if (x < -1 || 1 < x) return GenericNaN();
 #else
 #define ACOS_IF_OUT_OF_RANGE(x)
 #endif
 
-double
+double JS_VECTORCALL
 js::math_acos_impl(MathCache* cache, double x)
 {
     ACOS_IF_OUT_OF_RANGE(x);
-    return cache->lookup(acos, x, MathCache::Acos);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, acos, x, MathCache::Acos);
 }
 
-double
+double JS_VECTORCALL
 js::math_acos_uncached(double x)
 {
     ACOS_IF_OUT_OF_RANGE(x);
     return acos(x);
 }
 
 #undef ACOS_IF_OUT_OF_RANGE
 
@@ -162,24 +188,24 @@ js::math_acos(JSContext* cx, unsigned ar
 }
 
 #if defined(SOLARIS) && defined(__GNUC__)
 #define ASIN_IF_OUT_OF_RANGE(x) if (x < -1 || 1 < x) return GenericNaN();
 #else
 #define ASIN_IF_OUT_OF_RANGE(x)
 #endif
 
-double
+double JS_VECTORCALL
 js::math_asin_impl(MathCache* cache, double x)
 {
     ASIN_IF_OUT_OF_RANGE(x);
-    return cache->lookup(asin, x, MathCache::Asin);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, asin, x, MathCache::Asin);
 }
 
-double
+double JS_VECTORCALL
 js::math_asin_uncached(double x)
 {
     ASIN_IF_OUT_OF_RANGE(x);
     return asin(x);
 }
 
 #undef ASIN_IF_OUT_OF_RANGE
 
@@ -201,23 +227,23 @@ js::math_asin(JSContext* cx, unsigned ar
     if (!mathCache)
         return false;
 
     double z = math_asin_impl(mathCache, x);
     args.rval().setDouble(z);
     return true;
 }
 
-double
+double JS_VECTORCALL
 js::math_atan_impl(MathCache* cache, double x)
 {
-    return cache->lookup(atan, x, MathCache::Atan);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, atan, x, MathCache::Atan);
 }
 
-double
+double JS_VECTORCALL
 js::math_atan_uncached(double x)
 {
     return atan(x);
 }
 
 bool
 js::math_atan(JSContext* cx, unsigned argc, Value* vp)
 {
@@ -290,23 +316,34 @@ js::math_atan2_handle(JSContext* cx, Han
 bool
 js::math_atan2(JSContext* cx, unsigned argc, Value* vp)
 {
     CallArgs args = CallArgsFromVp(argc, vp);
 
     return math_atan2_handle(cx, args.get(0), args.get(1), args.rval());
 }
 
-double
+MOZ_ALWAYS_INLINE double
 js::math_ceil_impl(double x)
 {
 #ifdef __APPLE__
     if (x < 0 && x > -1.0)
         return js_copysign(0, -1);
 #endif
+
+#ifdef MOZILLA_MAY_SUPPORT_SSE4_1
+    if (mozilla::supports_sse4_1()) {
+        __m128d xd = _mm_load_sd(&x);
+        xd = _mm_ceil_sd(xd, xd);
+
+        double d;
+        _mm_store_sd(&d, xd);
+        return d;
+    }
+#endif
     return ceil(x);
 }
 
 bool
 js::math_ceil_handle(JSContext* cx, HandleValue v, MutableHandleValue res)
 {
     double d;
     if(!ToNumber(cx, v, &d))
@@ -348,23 +385,23 @@ js::math_clz32(JSContext* cx, unsigned a
         args.rval().setInt32(32);
         return true;
     }
 
     args.rval().setInt32(mozilla::CountLeadingZeroes32(n));
     return true;
 }
 
-double
+double JS_VECTORCALL
 js::math_cos_impl(MathCache* cache, double x)
 {
-    return cache->lookup(cos, x, MathCache::Cos);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, cos, x, MathCache::Cos);
 }
 
-double
+double JS_VECTORCALL
 js::math_cos_uncached(double x)
 {
     return cos(x);
 }
 
 bool
 js::math_cos(JSContext* cx, unsigned argc, Value* vp)
 {
@@ -395,24 +432,24 @@ js::math_cos(JSContext* cx, unsigned arg
             return PositiveInfinity<double>();  \
         if (x == NegativeInfinity<double>())    \
             return 0.0;                         \
     }
 #else
 #define EXP_IF_OUT_OF_RANGE(x)
 #endif
 
-double
+double JS_VECTORCALL
 js::math_exp_impl(MathCache* cache, double x)
 {
     EXP_IF_OUT_OF_RANGE(x);
-    return cache->lookup(exp, x, MathCache::Exp);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, exp, x, MathCache::Exp);
 }
 
-double
+double JS_VECTORCALL
 js::math_exp_uncached(double x)
 {
     EXP_IF_OUT_OF_RANGE(x);
     return exp(x);
 }
 
 #undef EXP_IF_OUT_OF_RANGE
 
@@ -434,19 +471,29 @@ js::math_exp(JSContext* cx, unsigned arg
     if (!mathCache)
         return false;
 
     double z = math_exp_impl(mathCache, x);
     args.rval().setNumber(z);
     return true;
 }
 
-double
+MOZ_ALWAYS_INLINE double
 js::math_floor_impl(double x)
 {
+#ifdef MOZILLA_MAY_SUPPORT_SSE4_1
+    if (mozilla::supports_sse4_1()) {
+        __m128d xd = _mm_load_sd(&x);
+        xd = _mm_floor_sd(xd, xd);
+
+        double d;
+        _mm_store_sd(&d, xd);
+        return d;
+    }
+#endif
     return floor(x);
 }
 
 bool
 js::math_floor_handle(JSContext* cx, HandleValue v, MutableHandleValue r)
 {
     double d;
     if (!ToNumber(cx, v, &d))
@@ -524,28 +571,32 @@ js::math_fround(JSContext* cx, unsigned 
 }
 
 #if defined(SOLARIS) && defined(__GNUC__)
 #define LOG_IF_OUT_OF_RANGE(x) if (x < 0) return GenericNaN();
 #else
 #define LOG_IF_OUT_OF_RANGE(x)
 #endif
 
-double
+double JS_VECTORCALL
 js::math_log_impl(MathCache* cache, double x)
 {
     LOG_IF_OUT_OF_RANGE(x);
     return cache->lookup(math_log_uncached, x, MathCache::Log);
 }
 
-double
+double JS_VECTORCALL
 js::math_log_uncached(double x)
 {
     LOG_IF_OUT_OF_RANGE(x);
+#ifdef JS_NO_VECTORCALL
     return log(x);
+#else
+    return log_vec(x);
+#endif
 }
 
 #undef LOG_IF_OUT_OF_RANGE
 
 bool
 js::math_log_handle(JSContext* cx, HandleValue val, MutableHandleValue res)
 {
     double in;
@@ -767,26 +818,26 @@ random_generateSeed()
 
 static const uint64_t RNG_MULTIPLIER = 0x5DEECE66DLL;
 static const uint64_t RNG_ADDEND = 0xBLL;
 static const uint64_t RNG_MASK = (1LL << 48) - 1;
 
 /*
  * Math.random() support, lifted from java.util.Random.java.
  */
-void
+MOZ_NEVER_INLINE void
 js::random_initState(uint64_t* rngState)
 {
     /* Our PRNG only uses 48 bits, so squeeze our entropy into those bits. */
     uint64_t seed = random_generateSeed();
     seed ^= (seed >> 16);
     *rngState = (seed ^ RNG_MULTIPLIER) & RNG_MASK;
 }
 
-uint64_t
+MOZ_ALWAYS_INLINE uint64_t
 js::random_next(uint64_t* rngState, int bits)
 {
     MOZ_ASSERT((*rngState & 0xffff000000000000ULL) == 0, "Bad rngState");
     MOZ_ASSERT(bits > 0 && bits <= 48, "bits is out of range");
 
     if (*rngState == 0) {
         random_initState(rngState);
     }
@@ -836,29 +887,55 @@ js::GetBiggestNumberLessThan(T x)
     Bits bits = mozilla::BitwiseCast<Bits>(x);
     MOZ_ASSERT(bits > 0, "will underflow");
     return mozilla::BitwiseCast<T>(bits - 1);
 }
 
 template double js::GetBiggestNumberLessThan<>(double x);
 template float js::GetBiggestNumberLessThan<>(float x);
 
-double
+#ifdef MOZILLA_MAY_SUPPORT_SSE4_1
+static const MOZ_ALIGNED_DECL(int64_t mask_sign[2], 16) = { 0x8000000000000000 };
+#endif
+
+MOZ_ALWAYS_INLINE double
 js::math_round_impl(double x)
 {
     int32_t ignored;
     if (NumberIsInt32(x, &ignored))
         return x;
 
     /* Some numbers are so big that adding 0.5 would give the wrong number. */
     if (ExponentComponent(x) >= int_fast16_t(FloatingPoint<double>::kExponentShift))
         return x;
 
     double add = (x >= 0) ? GetBiggestNumberLessThan(0.5) : 0.5;
-    return js_copysign(floor(x + add), x);
+
+#ifdef MOZILLA_MAY_SUPPORT_SSE4_1
+    if (mozilla::supports_sse4_1()) {
+        __m128d xmm1d = _mm_load_sd(&x);
+        __m128d xmm0d = xmm1d;
+
+        xmm0d = _mm_add_sd(xmm0d, _mm_load_sd(&add));
+        xmm0d = _mm_floor_sd(xmm0d, xmm0d);
+
+        __m128i xmm2i = _mm_load_si128((__m128i *)mask_sign);
+        __m128i xmm1i = _mm_castpd_si128(xmm1d);
+
+        xmm1i = _mm_and_si128(xmm1i, xmm2i);
+        xmm2i = _mm_andnot_si128(xmm2i, _mm_castpd_si128(xmm0d));
+        xmm1i = _mm_or_si128(xmm1i, xmm2i);
+
+        double d;
+        _mm_store_sd(&d, _mm_castsi128_pd(xmm1i));
+        return d;
+    }
+#endif
+
+    return js_copysign(math_floor_impl(x + add), x);
 }
 
 float
 js::math_roundf_impl(float x)
 {
     int32_t ignored;
     if (NumberIsInt32(x, &ignored))
         return x;
@@ -879,32 +956,36 @@ js::math_round(JSContext* cx, unsigned a
     if (args.length() == 0) {
         args.rval().setNaN();
         return true;
     }
 
     return math_round_handle(cx, args[0], args.rval());
 }
 
-double
+double JS_VECTORCALL
 js::math_sin_impl(MathCache* cache, double x)
 {
     return cache->lookup(math_sin_uncached, x, MathCache::Sin);
 }
 
-double
+double JS_VECTORCALL
 js::math_sin_uncached(double x)
 {
 #ifdef _WIN64
     // Workaround MSVC bug where sin(-0) is +0 instead of -0 on x64 on
     // CPUs without FMA3 (pre-Haswell). See bug 1076670.
     if (IsNegativeZero(x))
         return -0.0;
 #endif
+#ifdef JS_NO_VECTORCALL
     return sin(x);
+#else
+    return sin_vec(x);
+#endif
 }
 
 bool
 js::math_sin_handle(JSContext* cx, HandleValue val, MutableHandleValue res)
 {
     double in;
     if (!ToNumber(cx, val, &in))
         return false;
@@ -955,23 +1036,23 @@ js::math_sqrt(JSContext* cx, unsigned ar
     if (args.length() == 0) {
         args.rval().setNaN();
         return true;
     }
 
     return math_sqrt_handle(cx, args[0], args.rval());
 }
 
-double
+double JS_VECTORCALL
 js::math_tan_impl(MathCache* cache, double x)
 {
-    return cache->lookup(tan, x, MathCache::Tan);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, tan, x, MathCache::Tan);
 }
 
-double
+double JS_VECTORCALL
 js::math_tan_uncached(double x)
 {
     return tan(x);
 }
 
 bool
 js::math_tan(JSContext* cx, unsigned argc, Value* vp)
 {
@@ -991,55 +1072,61 @@ js::math_tan(JSContext* cx, unsigned arg
         return false;
 
     double z = math_tan_impl(mathCache, x);
     args.rval().setDouble(z);
     return true;
 }
 
 typedef double (*UnaryMathFunctionType)(MathCache* cache, double);
+typedef double (JS_VECTORCALL *UnaryVecMathFunctionType)(MathCache* cache, double);
 
 template <UnaryMathFunctionType F>
-static bool math_function(JSContext* cx, unsigned argc, Value* vp)
+static bool math_function(JSContext* cx, unsigned argc, Value* vp, bool vectorcall = false)
 {
     CallArgs args = CallArgsFromVp(argc, vp);
     if (args.length() == 0) {
         args.rval().setNumber(GenericNaN());
         return true;
     }
 
     double x;
     if (!ToNumber(cx, args[0], &x))
         return false;
 
     MathCache* mathCache = cx->runtime()->getMathCache(cx);
     if (!mathCache)
         return false;
-    double z = F(mathCache, x);
+
+    double z;
+    if (!vectorcall)
+        z = F(mathCache, x);
+    else
+        z = ((UnaryVecMathFunctionType)F)(mathCache, x);
     args.rval().setNumber(z);
 
     return true;
 }
 
-double
+double JS_VECTORCALL
 js::math_log10_impl(MathCache* cache, double x)
 {
-    return cache->lookup(log10, x, MathCache::Log10);
+    return MATHCACHE_MAYBE_VEC_LOOKUP(cache, log10, x, MathCache::Log10);
 }
 
-double
+double JS_VECTORCALL
 js::math_log10_uncached(double x)
 {
     return log10(x);
 }
 
 bool
 js::math_log10(JSContext* cx, unsigned argc, Value* vp)
 {
-    return math_function<math_log10_impl>(cx, argc, vp);
+    return math_function<(UnaryMathFunctionType)math_log10_impl>(cx, argc, vp, true);
 }
 
 #if !HAVE_LOG2
 double log2(double x)
 {
     return log(x) / M_LN2;
 }
 #endif
diff --git a/js/src/jsmath.h b/js/src/jsmath.h
--- a/js/src/jsmath.h
+++ b/js/src/jsmath.h
@@ -34,16 +34,17 @@
 #endif
 #ifndef M_SQRT1_2
 # define M_SQRT1_2       0.70710678118654752440
 #endif
 
 namespace js {
 
 typedef double (*UnaryFunType)(double);
+typedef double (JS_VECTORCALL *UnaryVecFunType)(double);
 
 class MathCache
 {
   public:
     enum MathFuncId {
         Zero,
         Sin, Cos, Tan, Sinh, Cosh, Tanh, Asin, Acos, Atan, Asinh, Acosh, Atanh,
         Sqrt, Log, Log10, Log2, Log1p, Exp, Expm1, Cbrt, Trunc, Sign
@@ -65,17 +66,18 @@ class MathCache
         uint16_t hash16 = uint16_t(hash32 ^ (hash32 >> 16));
         return (hash16 & (Size - 1)) ^ (hash16 >> (16 - SizeLog2));
     }
 
     /*
      * N.B. lookup uses double-equality. This is only safe if hash() maps +0
      * and -0 to different table entries, which is asserted in MathCache().
      */
-    double lookup(UnaryFunType f, double x, MathFuncId id) {
+    template<class T = UnaryFunType>
+    double lookup(T f, double x, MathFuncId id) {
         unsigned index = hash(x, id);
         Entry& e = table[index];
         if (e.in == x && e.id == id)
             return e.out;
         e.in = x;
         e.id = id;
         return e.out = f(x);
     }
@@ -155,62 +157,62 @@ extern bool
 RoundFloat32(JSContext* cx, HandleValue arg, MutableHandleValue res);
 
 extern bool
 math_fround(JSContext* cx, unsigned argc, js::Value* vp);
 
 extern bool
 math_log(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_log_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_log_uncached(double x);
 
 extern bool
 math_log_handle(JSContext* cx, HandleValue val, MutableHandleValue res);
 
 extern bool
 math_sin(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_sin_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_sin_uncached(double x);
 
 extern bool
 math_sin_handle(JSContext* cx, HandleValue val, MutableHandleValue res);
 
 extern bool
 math_cos(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_cos_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_cos_uncached(double x);
 
 extern bool
 math_exp(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_exp_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_exp_uncached(double x);
 
 extern bool
 math_tan(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_tan_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_tan_uncached(double x);
 
 extern bool
 math_log10(JSContext* cx, unsigned argc, js::Value* vp);
 
 extern bool
 math_log2(JSContext* cx, unsigned argc, js::Value* vp);
 
@@ -275,38 +277,38 @@ extern bool
 math_atan2_handle(JSContext* cx, HandleValue y, HandleValue x, MutableHandleValue res);
 
 extern bool
 math_atan2(JSContext* cx, unsigned argc, Value* vp);
 
 extern double
 ecmaAtan2(double x, double y);
 
-extern double
+extern double JS_VECTORCALL
 math_atan_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_atan_uncached(double x);
 
 extern bool
 math_atan(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_asin_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_asin_uncached(double x);
 
 extern bool
 math_asin(JSContext* cx, unsigned argc, js::Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_acos_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_acos_uncached(double x);
 
 extern bool
 math_acos(JSContext* cx, unsigned argc, js::Value* vp);
 
 extern bool
 math_ceil_handle(JSContext* cx, HandleValue value, MutableHandleValue res);
 
@@ -347,20 +349,20 @@ extern double
 powi(double x, int y);
 
 extern double
 ecmaPow(double x, double y);
 
 extern bool
 math_imul(JSContext* cx, unsigned argc, Value* vp);
 
-extern double
+extern double JS_VECTORCALL
 math_log10_impl(MathCache* cache, double x);
 
-extern double
+extern double JS_VECTORCALL
 math_log10_uncached(double x);
 
 extern double
 math_log2_impl(MathCache* cache, double x);
 
 extern double
 math_log2_uncached(double x);
 
diff --git a/js/src/jstypes.h b/js/src/jstypes.h
--- a/js/src/jstypes.h
+++ b/js/src/jstypes.h
@@ -90,16 +90,24 @@
 #define JS_FASTCALL __fastcall
 #elif defined(__GNUC__) && defined(__i386__)
 #define JS_FASTCALL __attribute__((fastcall))
 #else
 #define JS_FASTCALL
 #define JS_NO_FASTCALL
 #endif
 
+#if defined(_MSC_VER) && _MSC_VER >= 1800 && \
+    defined(_M_IX86_FP) && _M_IX86_FP >= 2
+#define JS_VECTORCALL __vectorcall
+#else
+#define JS_VECTORCALL
+#define JS_NO_VECTORCALL
+#endif
+
 /***********************************************************************
 ** MACROS:      JS_BEGIN_MACRO
 **              JS_END_MACRO
 ** DESCRIPTION:
 **      Macro body brackets so that macros with compound statement definitions
 **      behave syntactically more like functions when called.
 ***********************************************************************/
 #define JS_BEGIN_MACRO  do {
diff --git a/layout/base/FrameLayerBuilder.cpp b/layout/base/FrameLayerBuilder.cpp
--- a/layout/base/FrameLayerBuilder.cpp
+++ b/layout/base/FrameLayerBuilder.cpp
@@ -937,37 +937,55 @@ public:
 
   nscoord GetAppUnitsPerDevPixel() { return mAppUnitsPerDevPixel; }
 
   nsIntRect ScaleToNearestPixels(const nsRect& aRect) const
   {
     return aRect.ScaleToNearestPixels(mParameters.mXScale, mParameters.mYScale,
                                       mAppUnitsPerDevPixel);
   }
+  nsIntRect ToNearestPixels(const nsRect& aRect)
+  {
+    return aRect.ToNearestPixels(mAppUnitsPerDevPixel);
+  }
   nsIntRegion ScaleRegionToNearestPixels(const nsRegion& aRegion) const
   {
     return aRegion.ScaleToNearestPixels(mParameters.mXScale, mParameters.mYScale,
                                         mAppUnitsPerDevPixel);
   }
   nsIntRect ScaleToOutsidePixels(const nsRect& aRect, bool aSnap = false) const
   {
     if (aSnap && mSnappingEnabled) {
       return ScaleToNearestPixels(aRect);
     }
     return aRect.ScaleToOutsidePixels(mParameters.mXScale, mParameters.mYScale,
                                       mAppUnitsPerDevPixel);
   }
+  nsIntRect ToOutsidePixels(const nsRect& aRect, bool aSnap = false)
+  {
+    if (aSnap && mSnappingEnabled) {
+      return ToNearestPixels(aRect);
+    }
+    return aRect.ToOutsidePixels(mAppUnitsPerDevPixel);
+  }
   nsIntRect ScaleToInsidePixels(const nsRect& aRect, bool aSnap = false) const
   {
     if (aSnap && mSnappingEnabled) {
       return ScaleToNearestPixels(aRect);
     }
     return aRect.ScaleToInsidePixels(mParameters.mXScale, mParameters.mYScale,
                                      mAppUnitsPerDevPixel);
   }
+  nsIntRect ToInsidePixels(const nsRect& aRect, bool aSnap = false)
+  {
+    if (aSnap && mSnappingEnabled) {
+      return ToNearestPixels(aRect);
+    }
+    return aRect.ToInsidePixels(mAppUnitsPerDevPixel);
+  }
 
   nsIntRegion ScaleRegionToInsidePixels(const nsRegion& aRegion, bool aSnap = false) const
   {
     if (aSnap && mSnappingEnabled) {
       return ScaleRegionToNearestPixels(aRegion);
     }
     return aRegion.ScaleToInsidePixels(mParameters.mXScale, mParameters.mYScale,
                                         mAppUnitsPerDevPixel);
@@ -3405,16 +3423,17 @@ ContainerState::ComputeOpaqueRect(nsDisp
 void
 ContainerState::ProcessDisplayItems(nsDisplayList* aList)
 {
   PROFILER_LABEL("ContainerState", "ProcessDisplayItems",
     js::ProfileEntry::Category::GRAPHICS);
 
   const nsIFrame* lastAnimatedGeometryRoot = mContainerReferenceFrame;
   nsPoint topLeft(0,0);
+  const bool scaled = mParameters.Scaled();
 
   // When NO_COMPONENT_ALPHA is set, items will be flattened into a single
   // layer, so we need to choose which active scrolled root to use for all
   // items.
   if (mFlattenToSingleLayer) {
     if (ChooseAnimatedGeometryRoot(*aList, &lastAnimatedGeometryRoot)) {
       topLeft = lastAnimatedGeometryRoot->GetOffsetToCrossDoc(mContainerReferenceFrame);
     }
@@ -3459,24 +3478,24 @@ ContainerState::ProcessDisplayItems(nsDi
     bool snap;
     nsRect itemContent = item->GetBounds(mBuilder, &snap);
     nsDisplayItem::Type itemType = item->GetType();
     if (itemType == nsDisplayItem::TYPE_LAYER_EVENT_REGIONS) {
       nsDisplayLayerEventRegions* eventRegions =
         static_cast<nsDisplayLayerEventRegions*>(item);
       itemContent = eventRegions->GetHitRegionBounds(mBuilder, &snap);
     }
-    nsIntRect itemDrawRect = ScaleToOutsidePixels(itemContent, snap);
+    nsIntRect itemDrawRect = scaled ? ScaleToOutsidePixels(itemContent, snap) : ToOutsidePixels(itemContent, snap);
     bool prerenderedTransform = itemType == nsDisplayItem::TYPE_TRANSFORM &&
         static_cast<nsDisplayTransform*>(item)->ShouldPrerender(mBuilder);
     ParentLayerIntRect clipRect;
     const DisplayItemClip& itemClip = item->GetClip();
     if (itemClip.HasClip()) {
       itemContent.IntersectRect(itemContent, itemClip.GetClipRect());
-      clipRect = ViewAs<ParentLayerPixel>(ScaleToNearestPixels(itemClip.GetClipRect()));
+      clipRect = ViewAs<ParentLayerPixel>(scaled ? ScaleToNearestPixels(itemClip.GetClipRect()) : ToNearestPixels(itemClip.GetClipRect()));
       if (!prerenderedTransform) {
         itemDrawRect.IntersectRect(itemDrawRect, ParentLayerIntRect::ToUntyped(clipRect));
       }
       clipRect.MoveBy(ViewAs<ParentLayerPixel>(mParameters.mOffset));
     }
 #ifdef DEBUG
     nsRect bounds = itemContent;
     bool dummy;
@@ -3487,17 +3506,17 @@ ContainerState::ProcessDisplayItems(nsDi
       }
     }
     ((nsRect&)mAccumulatedChildBounds).UnionRect(mAccumulatedChildBounds, bounds);
 #endif
     // We haven't computed visibility at this point, so item->GetVisibleRect()
     // is just the dirty rect that item was initialized with. We intersect it
     // with the clipped item bounds to get a tighter visible rect.
     nsIntRect itemVisibleRect = itemDrawRect.Intersect(
-      ScaleToOutsidePixels(item->GetVisibleRect(), false));
+      scaled ? ScaleToOutsidePixels(item->GetVisibleRect(), false) : ToOutsidePixels(item->GetVisibleRect(), false));
 
     LayerState layerState = item->GetLayerState(mBuilder, mManager, mParameters);
     if (layerState == LAYER_INACTIVE &&
         nsDisplayItem::ForceActiveLayers()) {
       layerState = LAYER_ACTIVE;
     }
 
     bool forceInactive;
diff --git a/layout/base/FrameLayerBuilder.h b/layout/base/FrameLayerBuilder.h
--- a/layout/base/FrameLayerBuilder.h
+++ b/layout/base/FrameLayerBuilder.h
@@ -79,16 +79,21 @@ struct ContainerLayerParameters {
     , mLayerContentsVisibleRect(nullptr)
     , mOffset(aOffset)
     , mBackgroundColor(aParent.mBackgroundColor)
     , mInTransformedSubtree(aParent.mInTransformedSubtree)
     , mInActiveTransformedSubtree(aParent.mInActiveTransformedSubtree)
     , mDisableSubpixelAntialiasingInDescendants(aParent.mDisableSubpixelAntialiasingInDescendants)
     , mInLowPrecisionDisplayPort(aParent.mInLowPrecisionDisplayPort)
   {}
+  bool Scaled()
+  {
+    return (0x3f800000 != *(uint32_t *)&mXScale) ||
+           (0x3f800000 != *(uint32_t *)&mYScale);
+  }
 
   float mXScale, mYScale;
 
   LayoutDeviceToLayerScale2D Scale() const {
     return LayoutDeviceToLayerScale2D(mXScale, mYScale);
   }
 
   /**
diff --git a/layout/generic/nsBlockFrame.cpp b/layout/generic/nsBlockFrame.cpp
--- a/layout/generic/nsBlockFrame.cpp
+++ b/layout/generic/nsBlockFrame.cpp
@@ -4,16 +4,20 @@
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 /*
  * rendering object for CSS display:block, inline-block, and list-item
  * boxes, also used for various anonymous boxes
  */
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include "nsBlockFrame.h"
 
 #include "mozilla/DebugOnly.h"
 
 #include "nsCOMPtr.h"
 #include "nsAbsoluteContainingBlock.h"
 #include "nsBlockReflowContext.h"
 #include "nsBlockReflowState.h"
@@ -2074,16 +2078,22 @@ nsBlockFrame::ReflowDirtyLines(nsBlockRe
   bool lastLineMovedUp = false;
   // We save up information about BR-clearance here
   uint8_t inlineFloatBreakType = aState.mFloatBreakType;
 
   line_iterator line = begin_lines(), line_end = end_lines();
 
   // Reflow the lines that are already ours
   for ( ; line != line_end; ++line, aState.AdvanceToNextLine()) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    if (line.next() != line_end) {
+      _mm_prefetch((char *)line.peekNext()->mFirstChild, _MM_HINT_T0);
+    }
+#endif
+
     DumpLine(aState, line, deltaBCoord, 0);
 #ifdef DEBUG
     AutoNoisyIndenter indent2(gNoisyReflow);
 #endif
 
     if (selfDirty)
       line->MarkDirty();
 
@@ -6328,16 +6338,19 @@ DisplayLine(nsDisplayListBuilder* aBuild
   nsDisplayListSet childLists(collection,
     lineInline ? collection.Content() : collection.BlockBorderBackgrounds());
 
   uint32_t flags = lineInline ? nsIFrame::DISPLAY_CHILD_INLINE : 0;
 
   nsIFrame* kid = aLine->mFirstChild;
   int32_t n = aLine->GetChildCount();
   while (--n >= 0) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)kid->GetNextSibling(), _MM_HINT_T0);
+#endif
     aFrame->BuildDisplayListForChild(aBuilder, kid, aDirtyRect,
                                      childLists, flags);
     kid = kid->GetNextSibling();
   }
   
   if (lineMayHaveTextOverflow) {
     aTextOverflow->ProcessLine(collection, aLine.get());
   }
@@ -6371,18 +6384,22 @@ nsBlockFrame::BuildDisplayList(nsDisplay
   }
 #endif
 
   DisplayBorderBackgroundOutline(aBuilder, aLists);
 
   if (GetPrevInFlow()) {
     DisplayOverflowContainers(aBuilder, aDirtyRect, aLists);
     for (nsIFrame* f = mFloats.FirstChild(); f; f = f->GetNextSibling()) {
-      if (f->GetStateBits() & NS_FRAME_IS_PUSHED_FLOAT)
-         BuildDisplayListForChild(aBuilder, f, aDirtyRect, aLists);
+      if (f->GetStateBits() & NS_FRAME_IS_PUSHED_FLOAT) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+        _mm_prefetch((char *)f->GetNextSibling(), _MM_HINT_T0);
+#endif
+        BuildDisplayListForChild(aBuilder, f, aDirtyRect, aLists);
+      }
     }
   }
 
   aBuilder->MarkFramesForDisplayList(this, mFloats, aDirtyRect);
 
   // Prepare for text-overflow processing.
   nsAutoPtr<TextOverflow> textOverflow(
     TextOverflow::WillProcessLines(aBuilder, this));
@@ -6419,16 +6436,19 @@ nsBlockFrame::BuildDisplayList(nsDisplay
   } else {
     bool nonDecreasingYs = true;
     int32_t lineCount = 0;
     nscoord lastY = INT32_MIN;
     nscoord lastYMost = INT32_MIN;
     for (line_iterator line = begin_lines();
          line != line_end;
          ++line) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+      _mm_prefetch((char *)line.peekNext(), _MM_HINT_T0);
+#endif
       nsRect lineArea = line->GetVisualOverflowArea();
       DisplayLine(aBuilder, lineArea, aDirtyRect, line, depth, drawnLines,
                   linesDisplayListCollection, this, textOverflow);
       if (!lineArea.IsEmpty()) {
         if (lineArea.y < lastY
             || lineArea.YMost() < lastYMost) {
           nonDecreasingYs = false;
         }
diff --git a/layout/generic/nsContainerFrame.cpp b/layout/generic/nsContainerFrame.cpp
--- a/layout/generic/nsContainerFrame.cpp
+++ b/layout/generic/nsContainerFrame.cpp
@@ -1,15 +1,19 @@
 /* -*- Mode: C++; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- */
 /* This Source Code Form is subject to the terms of the Mozilla Public
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 /* base class #1 for rendering objects that have child lists */
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include "nsContainerFrame.h"
 
 #include "nsAbsoluteContainingBlock.h"
 #include "nsIDocument.h"
 #include "nsPresContext.h"
 #include "nsStyleContext.h"
 #include "nsRect.h"
 #include "nsPoint.h"
@@ -297,16 +301,19 @@ nsContainerFrame::BuildDisplayListForNon
                                                       const nsDisplayListSet& aLists,
                                                       uint32_t                aFlags)
 {
   nsIFrame* kid = mFrames.FirstChild();
   // Put each child's background directly onto the content list
   nsDisplayListSet set(aLists, aLists.Content());
   // The children should be in content order
   while (kid) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)kid->GetNextSibling(), _MM_HINT_T0);
+#endif
     BuildDisplayListForChild(aBuilder, kid, aDirtyRect, set, aFlags);
     kid = kid->GetNextSibling();
   }
 }
 
 /* virtual */ void
 nsContainerFrame::ChildIsDirty(nsIFrame* aChild)
 {
@@ -1314,16 +1321,19 @@ void
 nsContainerFrame::DisplayOverflowContainers(nsDisplayListBuilder*   aBuilder,
                                             const nsRect&           aDirtyRect,
                                             const nsDisplayListSet& aLists)
 {
   nsFrameList* overflowconts = GetPropTableFrames(OverflowContainersProperty());
   if (overflowconts) {
     for (nsIFrame* frame = overflowconts->FirstChild(); frame;
          frame = frame->GetNextSibling()) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+      _mm_prefetch((char *)frame->GetNextSibling(), _MM_HINT_T0);
+#endif
       BuildDisplayListForChild(aBuilder, frame, aDirtyRect, aLists);
     }
   }
 }
 
 static bool
 TryRemoveFrame(nsIFrame* aFrame, FramePropertyTable* aPropTable,
                const FramePropertyDescriptor* aProp, nsIFrame* aChildToRemove)
diff --git a/layout/generic/nsFrame.cpp b/layout/generic/nsFrame.cpp
--- a/layout/generic/nsFrame.cpp
+++ b/layout/generic/nsFrame.cpp
@@ -1,16 +1,20 @@
 /* -*- Mode: C++; tab-width: 2; indent-tabs-mode: nil; c-basic-offset: 2 -*- */
 // vim:cindent:ts=2:et:sw=2:
 /* This Source Code Form is subject to the terms of the Mozilla Public
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 /* base class of all rendering objects */
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include "nsFrame.h"
 
 #include <stdarg.h>
 #include <algorithm>
 
 #include "gfxUtils.h"
 #include "mozilla/Attributes.h"
 #include "mozilla/DebugOnly.h"
@@ -1072,73 +1076,102 @@ nsIFrame::GetMarginRectRelativeToSelf() 
   nsRect r(0, 0, mRect.width, mRect.height);
   r.Inflate(m);
   return r;
 }
 
 bool
 nsIFrame::IsTransformed() const
 {
+  return IsTransformed(StyleDisplay());
+}
+
+bool
+nsIFrame::IsTransformed(const nsStyleDisplay* aDisp) const
+{
   return ((mState & NS_FRAME_MAY_BE_TRANSFORMED) &&
           (StyleDisplay()->HasTransform(this) ||
            IsSVGTransformed() ||
            (mContent &&
             nsLayoutUtils::HasAnimationsForCompositor(mContent,
                                                       eCSSProperty_transform) &&
             IsFrameOfType(eSupportsCSSTransforms) &&
             mContent->GetPrimaryFrame() == this)));
 }
 
 bool
 nsIFrame::HasOpacityInternal(float aThreshold) const
 {
+  return HasOpacityInternal(StyleDisplay(), aThreshold);
+}
+
+bool
+nsIFrame::HasOpacityInternal(const nsStyleDisplay* aDisp, float aThreshold) const
+{
   MOZ_ASSERT(0.0 <= aThreshold && aThreshold <= 1.0, "Invalid argument");
-  const nsStyleDisplay* displayStyle = StyleDisplay();
-  return StyleDisplay()->mOpacity < aThreshold ||
-         (displayStyle->mWillChangeBitField & NS_STYLE_WILL_CHANGE_OPACITY) ||
+  return aDisp->mOpacity < aThreshold ||
+         (aDisp->mWillChangeBitField & NS_STYLE_WILL_CHANGE_OPACITY) ||
          (mContent &&
            nsLayoutUtils::HasAnimationsForCompositor(mContent,
                                                      eCSSProperty_opacity) &&
            mContent->GetPrimaryFrame() == this);
 }
 
 bool
 nsIFrame::IsSVGTransformed(gfx::Matrix *aOwnTransforms,
                            gfx::Matrix *aFromParentTransforms) const
 {
   return false;
 }
 
+
 bool
 nsIFrame::Preserves3DChildren() const
 {
-  const nsStyleDisplay* disp = StyleDisplay();
-  if (disp->mTransformStyle != NS_STYLE_TRANSFORM_STYLE_PRESERVE_3D ||
+  return Preserves3DChildren(StyleDisplay());
+}
+
+bool
+nsIFrame::Preserves3DChildren(const nsStyleDisplay* aDisp) const
+{
+  if (aDisp->mTransformStyle != NS_STYLE_TRANSFORM_STYLE_PRESERVE_3D ||
       !IsFrameOfType(nsIFrame::eSupportsCSSTransforms)) {
     return false;
   }
 
   // If we're all scroll frame, then all descendants will be clipped, so we can't preserve 3d.
   if (GetType() == nsGkAtoms::scrollFrame) {
     return false;
   }
 
   nsRect temp;
-  return !nsFrame::ShouldApplyOverflowClipping(this, disp) &&
-         !GetClipPropClipRect(disp, &temp, GetSize()) &&
+  return !nsFrame::ShouldApplyOverflowClipping(this, aDisp) &&
+         !GetClipPropClipRect(aDisp, &temp, GetSize()) &&
          !nsSVGIntegrationUtils::UsingEffectsForFrame(this);
 }
 
 bool
 nsIFrame::Preserves3D() const
 {
   if (!GetParent() || !GetParent()->Preserves3DChildren()) {
     return false;
   }
-  return StyleDisplay()->HasTransform(this) || StyleDisplay()->BackfaceIsHidden();
+  const nsStyleDisplay *disp = StyleDisplay();
+  return disp->HasTransform(this) || disp->BackfaceIsHidden();
+}
+
+bool
+nsIFrame::Preserves3D(const nsIFrame* aParent,
+                      const nsStyleDisplay* aParentDisp) const
+{
+  if (!aParent || !aParent->Preserves3DChildren(aParentDisp)) {
+    return false;
+  }
+  const nsStyleDisplay *disp = StyleDisplay();
+  return disp->HasTransform(this) || disp->BackfaceIsHidden();
 }
 
 bool
 nsIFrame::HasPerspective() const
 {
   if (!IsTransformed()) {
     return false;
   }
@@ -1604,16 +1637,20 @@ nsFrame::DisplayBorderBackgroundOutline(
                                         bool                    aForceBackground)
 {
   // The visibility check belongs here since child elements have the
   // opportunity to override the visibility property and display even if
   // their parent is hidden.
   if (!IsVisibleForPainting(aBuilder))
     return;
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  _mm_prefetch((char *)&StyleBorder()->GetComputedBorder(), _MM_HINT_NTA);
+#endif
+
   nsCSSShadowArray* shadows = StyleBorder()->mBoxShadow;
   if (shadows && shadows->HasShadowWithInset(false)) {
     aLists.BorderBackground()->AppendNewToTop(new (aBuilder)
       nsDisplayBoxShadowOuter(aBuilder, this));
   }
 
   bool bgIsThemed = DisplayBackgroundUnconditional(aBuilder, aLists,
                                                    aForceBackground);
@@ -1716,17 +1753,17 @@ ApplyOverflowClipping(nsDisplayListBuild
   // is required by comboboxes which make their display text (an inline frame)
   // have clipping.
   if (!nsFrame::ShouldApplyOverflowClipping(aFrame, aDisp)) {
     return;
   }
   nsRect clipRect;
   bool haveRadii = false;
   nscoord radii[8];
-  if (aFrame->StyleDisplay()->mOverflowClipBox ==
+  if (aDisp->mOverflowClipBox ==
         NS_STYLE_OVERFLOW_CLIP_BOX_PADDING_BOX) {
     clipRect = aFrame->GetPaddingRectRelativeToSelf() +
       aBuilder->ToReferenceFrame(aFrame);
     haveRadii = aFrame->GetPaddingBoxBorderRadii(radii);
   } else {
     clipRect = aFrame->GetContentRectRelativeToSelf() +
       aBuilder->ToReferenceFrame(aFrame);
     // XXX border-radius
@@ -1992,17 +2029,17 @@ nsIFrame::BuildDisplayListForStackingCon
   nsRect dirtyRectOutsideSVGEffects = dirtyRect;
   nsDisplayList hoistedScrollInfoItemsStorage;
   if (usingSVGEffects) {
     dirtyRect =
       nsSVGIntegrationUtils::GetRequiredSourceForInvalidArea(this, dirtyRect);
     aBuilder->EnterSVGEffectsContents(&hoistedScrollInfoItemsStorage);
   }
 
-  bool useOpacity = HasVisualOpacity() && !nsSVGUtils::CanOptimizeOpacity(this);
+  bool useOpacity = HasVisualOpacity(disp) && !nsSVGUtils::CanOptimizeOpacity(this);
   bool useBlendMode = disp->mMixBlendMode != NS_STYLE_BLEND_NORMAL;
   bool useStickyPosition = disp->mPosition == NS_STYLE_POSITION_STICKY &&
     IsScrollFrameActive(aBuilder,
                         nsLayoutUtils::GetNearestScrollableFrame(GetParent(),
                         nsLayoutUtils::SCROLLABLE_SAME_DOC |
                         nsLayoutUtils::SCROLLABLE_INCLUDE_HIDDEN));
 
   nsDisplayListBuilder::AutoBuildingDisplayList
@@ -2240,17 +2277,22 @@ nsIFrame::BuildDisplayListForChild(nsDis
   // If painting is restricted to just the background of the top level frame,
   // then we have nothing to do here.
   if (aBuilder->IsBackgroundOnly())
     return;
 
   nsIFrame* child = aChild;
   if (child->GetStateBits() & NS_FRAME_TOO_DEEP_IN_FRAME_TREE)
     return;
-  
+
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  nsStyleContext *childStyleContext = child->StyleContext();
+  _mm_prefetch((char *)childStyleContext, _MM_HINT_NTA);
+#endif
+
   bool isSVG = (child->GetStateBits() & NS_FRAME_SVG_LAYOUT);
 
   // true if this is a real or pseudo stacking context
   bool pseudoStackingContext =
     (aFlags & DISPLAY_CHILD_FORCE_PSEUDO_STACKING_CONTEXT) != 0;
   if (!isSVG &&
       (aFlags & DISPLAY_CHILD_INLINE) &&
       !child->IsFrameOfType(eLineParticipant)) {
@@ -2270,16 +2312,22 @@ nsIFrame::BuildDisplayListForChild(nsDis
     child = placeholder->GetOutOfFlowFrame();
     NS_ASSERTION(child, "No out of flow frame?");
     // If 'child' is a pushed float then it's owned by a block that's not an
     // ancestor of the placeholder, and it will be painted by that block and
     // should not be painted through the placeholder.
     if (!child || nsLayoutUtils::IsPopup(child) ||
         (child->GetStateBits() & NS_FRAME_IS_PUSHED_FLOAT))
       return;
+
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    childStyleContext = child->StyleContext();
+    _mm_prefetch((char *)childStyleContext, _MM_HINT_NTA);
+#endif
+
     // Make sure that any attempt to use childType below is disappointed. We
     // could call GetType again but since we don't currently need it, let's
     // avoid the virtual call.
     childType = nullptr;
     // Recheck NS_FRAME_TOO_DEEP_IN_FRAME_TREE
     if (child->GetStateBits() & NS_FRAME_TOO_DEEP_IN_FRAME_TREE)
       return;
     savedOutOfFlowData = static_cast<nsDisplayListBuilder::OutOfFlowDisplayData*>
@@ -2289,17 +2337,24 @@ nsIFrame::BuildDisplayListForChild(nsDis
     } else {
       // The out-of-flow frame did not intersect the dirty area. We may still
       // need to traverse into it, since it may contain placeholders we need
       // to enter to reach other out-of-flow frames that are visible.
       dirty.SetEmpty();
     }
     pseudoStackingContext = true;
   }
-  if (child->Preserves3D()) {
+
+  const nsStyleDisplay* ourDisp = StyleDisplay();
+
+  nsIFrame* parent = child->GetParent();
+  const nsStyleDisplay* parentDisp =
+    parent == this ? ourDisp : parent->StyleDisplay();
+
+  if (child->Preserves3D(parent, parentDisp)) {
     nsRect* savedDirty = static_cast<nsRect*>
       (child->Properties().Get(nsDisplayListBuilder::Preserve3DDirtyRectProperty()));
     if (savedDirty) {
       dirty = *savedDirty;
     } else {
       dirty.SetEmpty();
     }
   }
@@ -2307,16 +2362,20 @@ nsIFrame::BuildDisplayListForChild(nsDis
   NS_ASSERTION(childType != nsGkAtoms::placeholderFrame,
                "Should have dealt with placeholders already");
   if (aBuilder->GetSelectedFramesOnly() &&
       child->IsLeaf() &&
       !aChild->IsSelected()) {
     return;
   }
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  childStyleContext->PrefetchCachedResetData();
+#endif
+
   if (aBuilder->GetIncludeAllOutOfFlows() &&
       (child->GetStateBits() & NS_FRAME_OUT_OF_FLOW)) {
     dirty = child->GetVisualOverflowRect();
   } else if (!(child->GetStateBits() & NS_FRAME_FORCE_DISPLAY_LIST_DESCEND_INTO)) {
     // No need to descend into child to catch placeholders for visible
     // positioned stuff. So see if we can short-circuit frame traversal here.
 
     // We can stop if child's frame subtree's intersection with the
@@ -2337,46 +2396,60 @@ nsIFrame::BuildDisplayListForChild(nsDis
       // Usually we could set dirty to childDirty now but there's no
       // benefit, and it can be confusing. It can especially confuse
       // situations where we're going to ignore a scrollframe's clipping;
       // we wouldn't want to clip the dirty area to the scrollframe's
       // bounds in that case.
     }
   }
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  nsIContent* childContent = child->GetContent();
+  if (childContent) {
+    _mm_prefetch((char *)childContent, _MM_HINT_NTA);
+  }
+#endif
+
   // XXX need to have inline-block and inline-table set pseudoStackingContext
   
-  const nsStyleDisplay* ourDisp = StyleDisplay();
   // REVIEW: Taken from nsBoxFrame::Paint
   // Don't paint our children if the theme object is a leaf.
   if (IsThemed(ourDisp) &&
       !PresContext()->GetTheme()->WidgetIsContainer(ourDisp->mAppearance))
     return;
 
   // Child is composited if it's transformed, partially transparent, or has
   // SVG effects or a blend mode..
   const nsStyleDisplay* disp = child->StyleDisplay();
   const nsStylePosition* pos = child->StylePosition();
-  bool isVisuallyAtomic = child->HasOpacity()
-    || child->IsTransformed()
+  bool isVisuallyAtomic = child->HasOpacity(disp)
+    || child->IsTransformed(disp)
     // strictly speaking, 'perspective' doesn't require visual atomicity,
     // but the spec says it acts like the rest of these
     || disp->mChildPerspective.GetUnit() == eStyleUnit_Coord
     || disp->mMixBlendMode != NS_STYLE_BLEND_NORMAL
     || nsSVGIntegrationUtils::UsingEffectsForFrame(child)
     || (child->GetStateBits() & NS_FRAME_HAS_VR_CONTENT);
 
   bool isPositioned = disp->IsAbsPosContainingBlock(child);
   bool isStackingContext =
     (isPositioned && (disp->mPosition == NS_STYLE_POSITION_STICKY ||
                       pos->mZIndex.GetUnit() == eStyleUnit_Integer)) ||
      (disp->mWillChangeBitField & NS_STYLE_WILL_CHANGE_STACKING_CONTEXT) ||
      disp->mIsolation != NS_STYLE_ISOLATION_AUTO ||
      isVisuallyAtomic || (aFlags & DISPLAY_CHILD_FORCE_STACKING_CONTEXT);
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  Element *childElement = nullptr;
+  if (childContent && childContent->IsElement()) {
+    childElement = childContent->AsElement();
+    childElement->PrefetchAttrsAndChildren();
+  }
+#endif
+
   if (isVisuallyAtomic || isPositioned || (!isSVG && disp->IsFloating(child)) ||
       ((disp->mClipFlags & NS_STYLE_CLIP_RECT) &&
        IsSVGContentWithCSSClip(child)) ||
        disp->mIsolation != NS_STYLE_ISOLATION_AUTO ||
        (disp->mWillChangeBitField & NS_STYLE_WILL_CHANGE_STACKING_CONTEXT) ||
       (aFlags & DISPLAY_CHILD_FORCE_STACKING_CONTEXT)) {
     // If you change this, also change IsPseudoStackingContextFromStyle()
     pseudoStackingContext = true;
@@ -2389,27 +2462,30 @@ nsIFrame::BuildDisplayListForChild(nsDis
   DisplayListClipState::AutoClipMultiple clipState(aBuilder);
   CheckForApzAwareEventHandlers(aBuilder, child);
 
   if (savedOutOfFlowData) {
     clipState.SetClipForContainingBlockDescendants(
       &savedOutOfFlowData->mContainingBlockClip);
   }
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  if (childElement) {
+    childElement->PrefetchAttrAndChildArrayImpl();
+  }
+#endif
+
   // Setup clipping for the parent's overflow:-moz-hidden-unscrollable,
   // or overflow:hidden on elements that don't support scrolling (and therefore
   // don't create nsHTML/XULScrollFrame). This clipping needs to not clip
   // anything directly rendered by the parent, only the rendering of its
   // children.
   // Don't use overflowClip to restrict the dirty rect, since some of the
   // descendants may not be clipped by it. Even if we end up with unnecessary
   // display items, they'll be pruned during ComputeVisibility.
-  nsIFrame* parent = child->GetParent();
-  const nsStyleDisplay* parentDisp =
-    parent == this ? ourDisp : parent->StyleDisplay();
   ApplyOverflowClipping(aBuilder, parent, parentDisp, clipState);
 
   nsDisplayList list;
   nsDisplayList extraPositionedDescendants;
   if (isStackingContext) {
     if (disp->mMixBlendMode != NS_STYLE_BLEND_NORMAL) {
       aBuilder->SetContainsBlendMode(disp->mMixBlendMode);
     }
diff --git a/layout/generic/nsHTMLReflowState.cpp b/layout/generic/nsHTMLReflowState.cpp
--- a/layout/generic/nsHTMLReflowState.cpp
+++ b/layout/generic/nsHTMLReflowState.cpp
@@ -25,16 +25,17 @@
 #include "nsLayoutUtils.h"
 #include "mozilla/Preferences.h"
 #include "nsFontInflationData.h"
 #include "StickyScrollContainer.h"
 #include "nsIFrameInlines.h"
 #include "CounterStyleManager.h"
 #include <algorithm>
 #include "mozilla/dom/HTMLInputElement.h"
+#include "mozilla/Attributes.h"
 
 #ifdef DEBUG
 #undef NOISY_VERTICAL_ALIGN
 #else
 #undef NOISY_VERTICAL_ALIGN
 #endif
 
 using namespace mozilla;
@@ -1113,16 +1114,17 @@ nsHTMLReflowState::CalculateHorizBorderP
   *aOutsideBoxSizing = outside;
   return;
 }
 
 /**
  * Returns true iff a pre-order traversal of the normal child
  * frames rooted at aFrame finds no non-empty frame before aDescendant.
  */
+MOZ_ALWAYS_INLINE
 static bool AreAllEarlierInFlowFramesEmpty(nsIFrame* aFrame,
   nsIFrame* aDescendant, bool* aFound) {
   if (aFrame == aDescendant) {
     *aFound = true;
     return true;
   }
   if (!aFrame->IsSelfEmpty()) {
     *aFound = false;
diff --git a/layout/generic/nsIFrame.h b/layout/generic/nsIFrame.h
--- a/layout/generic/nsIFrame.h
+++ b/layout/generic/nsIFrame.h
@@ -1172,35 +1172,47 @@ public:
   virtual bool NeedsView() { return false; }
 
   /**
    * Returns true if this frame is transformed (e.g. has CSS or SVG transforms)
    * or if its parent is an SVG frame that has children-only transforms (e.g.
    * an SVG viewBox attribute).
    */
   bool IsTransformed() const;
+  bool IsTransformed(const nsStyleDisplay* aDisp) const;
 
   /**
    * Returns true if the frame is translucent for the purposes of creating a
    * stacking context.
    */
   bool HasOpacity() const
   {
     return HasOpacityInternal(1.0f);
   }
+  bool HasOpacity(const nsStyleDisplay* aDisp) const
+  {
+    return HasOpacityInternal(aDisp, 1.0f);
+  }
   /**
    * Returns true if the frame is translucent for display purposes.
    */
   bool HasVisualOpacity() const
   {
     // Treat an opacity value of 0.99 and above as opaque.  This is an
     // optimization aimed at Web content which use opacity:0.99 as a hint for
     // creating a stacking context only.
     return HasOpacityInternal(0.99f);
   }
+  bool HasVisualOpacity(const nsStyleDisplay* aDisp) const
+  {
+    // Treat an opacity value of 0.99 and above as opaque.  This is an
+    // optimization aimed at Web content which use opacity:0.99 as a hint for
+    // creating a stacking context only.
+    return HasOpacityInternal(aDisp, 0.99f);
+  }
 
    /**
    * Return true if this frame might be using a transform getter.
    */
   virtual bool HasTransformGetter() const { return false; }
 
   /**
    * Returns true if this frame is an SVG frame that has SVG transforms applied
@@ -1215,23 +1227,26 @@ public:
                                 Matrix *aFromParentTransforms = nullptr) const;
 
   /**
    * Returns whether this frame will attempt to preserve the 3d transforms of its
    * children. This requires transform-style: preserve-3d, as well as no clipping
    * or svg effects.
    */
   bool Preserves3DChildren() const;
+  bool Preserves3DChildren(const nsStyleDisplay* aDisp) const;
 
   /**
    * Returns whether this frame has a parent that Preserves3DChildren() and has
    * its own transform (or hidden backface) to be combined with the parent's
    * transform.
    */
   bool Preserves3D() const;
+  bool Preserves3D(const nsIFrame* aParent,
+                   const nsStyleDisplay* aParentDisp) const;
 
   bool HasPerspective() const;
 
   bool ChildrenHavePerspective() const;
 
   // Calculate the overflow size of all child frames, taking preserve-3d into account
   void ComputePreserve3DChildrenOverflow(nsOverflowAreas& aOverflowAreas, const nsRect& aBounds);
 
@@ -3175,16 +3190,17 @@ private:
   // Helper-functions for SortFrameList():
   template<bool IsLessThanOrEqual(nsIFrame*, nsIFrame*)>
   static nsIFrame* SortedMerge(nsIFrame *aLeft, nsIFrame *aRight);
 
   template<bool IsLessThanOrEqual(nsIFrame*, nsIFrame*)>
   static nsIFrame* MergeSort(nsIFrame *aSource);
 
   bool HasOpacityInternal(float aThreshold) const;
+  bool HasOpacityInternal(const nsStyleDisplay* aDisp, float aThreshold) const;
 
 #ifdef DEBUG_FRAME_DUMP
 public:
   static void IndentBy(FILE* out, int32_t aIndent) {
     while (--aIndent >= 0) fputs("  ", out);
   }
   void ListTag(FILE* out) const {
     ListTag(out, this);
diff --git a/layout/generic/nsLineBox.h b/layout/generic/nsLineBox.h
--- a/layout/generic/nsLineBox.h
+++ b/layout/generic/nsLineBox.h
@@ -756,16 +756,21 @@ class nsLineList_iterator {
 
     iterator_self_type operator++(int)
     {
       iterator_self_type rv(*this);
       mCurrent = mCurrent->_mNext;
       return rv;
     }
 
+    pointer peekNext()
+    {
+      return static_cast<pointer>(mCurrent->_mNext);
+    }
+
     iterator_self_type& operator--()
     {
       mCurrent = mCurrent->_mPrev;
       return *this;
     }
 
     iterator_self_type operator--(int)
     {
diff --git a/layout/style/nsCSSRuleProcessor.cpp b/layout/style/nsCSSRuleProcessor.cpp
--- a/layout/style/nsCSSRuleProcessor.cpp
+++ b/layout/style/nsCSSRuleProcessor.cpp
@@ -4,16 +4,20 @@
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 /*
  * style rule processor for CSS style sheets, responsible for selector
  * matching and cascading
  */
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #define PL_ARENA_CONST_ALIGN_MASK 7
 // We want page-sized arenas so there's no fragmentation involved.
 // Including plarena.h must come first to avoid it being included by some
 // header file thereby making PL_ARENA_CONST_ALIGN_MASK ineffective.
 #define NS_CASCADEENUMDATA_ARENA_BLOCK_SIZE (4096)
 #include "plarena.h"
 
 #include "nsCSSRuleProcessor.h"
@@ -1791,16 +1795,19 @@ static bool SelectorMatches(Element* aEl
   NS_ASSERTION(aNodeMatchContext.mStateMask.IsEmpty() ||
                !aTreeMatchContext.mForStyling,
                "mForStyling must be false if we're just testing for "
                "state-dependence");
 
   // test for pseudo class match
   for (nsPseudoClassList* pseudoClass = aSelector->mPseudoClassList;
        pseudoClass; pseudoClass = pseudoClass->mNext) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)pseudoClass->mNext, _MM_HINT_NTA);
+#endif
     EventStates statesToCheck = sPseudoClassStates[pseudoClass->mType];
     if (statesToCheck.IsEmpty()) {
       // keep the cases here in the same order as the list in
       // nsCSSPseudoClassList.h
       switch (pseudoClass->mType) {
       case nsCSSPseudoClasses::ePseudoClass_empty:
         if (!checkGenericEmptyMatches(aElement, aTreeMatchContext, true)) {
           return false;
@@ -2620,16 +2627,22 @@ nsCSSRuleProcessor::HasStateDependentSty
       if (isPseudoElement) {
         if (selector->PseudoType() != aPseudoType) {
           continue;
         }
         selectorForPseudo = selector;
         selector = selector->mNext;
       }
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+      if (iter + 1 != end) {
+        _mm_prefetch((char *)(iter + 1)->mSelector, _MM_HINT_NTA);
+      }
+#endif
+
       nsRestyleHint possibleChange = RestyleHintForOp(selector->mOperator);
       SelectorMatchesFlags selectorFlags = SelectorMatchesFlags::UNKNOWN;
 
       // If hint already includes all the bits of possibleChange,
       // don't bother calling SelectorMatches, since even if it returns false
       // hint won't change.
       // Also don't bother calling SelectorMatches if none of the
       // states passed in are relevant here.
diff --git a/layout/style/nsStyleContext.h b/layout/style/nsStyleContext.h
--- a/layout/style/nsStyleContext.h
+++ b/layout/style/nsStyleContext.h
@@ -3,16 +3,20 @@
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 /* the interface (to internal code) for retrieving computed style data */
 
 #ifndef _nsStyleContext_h_
 #define _nsStyleContext_h_
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include "mozilla/RestyleLogging.h"
 #include "mozilla/Assertions.h"
 #include "nsRuleNode.h"
 #include "nsCSSPseudoElements.h"
 
 class nsIAtom;
 class nsPresContext;
 
@@ -423,16 +427,22 @@ public:
   void SwapStyleData(nsStyleContext* aNewContext, uint32_t aStructs);
 
   /**
    * On each descendant of this style context, clears out any cached inherited
    * structs indicated in aStructs.
    */
   void ClearCachedInheritedStyleDataOnDescendants(uint32_t aStructs);
 
+  void PrefetchCachedResetData() {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)mCachedResetData, _MM_HINT_NTA);
+#endif
+  }
+
   /**
    * Sets the NS_STYLE_INELIGIBLE_FOR_SHARING bit on this style context
    * and its descendants.  If it finds a descendant that has the bit
    * already set, assumes that it can skip that subtree.
    */
   void SetIneligibleForSharing();
 
 #ifdef DEBUG
@@ -542,16 +552,18 @@ private:
   // This only gets called under call trees where we've already checked
   // that PresContext()->RestyleManager()->ShouldLogRestyle() returned true.
   // It exists here just to satisfy LOG_RESTYLE's expectations.
   bool ShouldLogRestyle() { return true; }
 #endif
 
   nsStyleContext* mParent; // STRONG
 
+  nsResetStyleData*       mCachedResetData; // Cached reset style data.
+
   // Children are kept in two circularly-linked lists.  The list anchor
   // is not part of the list (null for empty), and we point to the first
   // child.
   // mEmptyChild for children whose rule node is the root rule node, and
   // mChild for other children.  The order of children is not
   // meaningful.
   nsStyleContext* mChild;
   nsStyleContext* mEmptyChild;
@@ -579,17 +591,16 @@ private:
   // are owned by this style context and structs that are owned by one of
   // this style context's ancestors (which are indirectly owned since this
   // style context owns a reference to its parent).  If the bit in |mBits|
   // is set for a struct, that means that the pointer for that struct is
   // owned by an ancestor or by mRuleNode rather than by this style context.
   // Since style contexts typically have some inherited data but only sometimes
   // have reset data, we always allocate the mCachedInheritedData, but only
   // sometimes allocate the mCachedResetData.
-  nsResetStyleData*       mCachedResetData; // Cached reset style data.
   nsInheritedStyleData    mCachedInheritedData; // Cached inherited style data
   uint64_t                mBits; // Which structs are inherited from the
                                  // parent context or owned by mRuleNode.
   uint32_t                mRefCnt;
 
 #ifdef DEBUG
   uint32_t                mFrameRefCnt; // number of frames that use this
                                         // as their style context
diff --git a/layout/style/nsStyleStruct.cpp b/layout/style/nsStyleStruct.cpp
--- a/layout/style/nsStyleStruct.cpp
+++ b/layout/style/nsStyleStruct.cpp
@@ -2266,19 +2266,19 @@ bool nsStyleBackground::HasFixedBackgrou
       return true;
     }
   }
   return false;
 }
 
 bool nsStyleBackground::IsTransparent() const
 {
-  return BottomLayer().mImage.IsEmpty() &&
-         mImageCount == 1 &&
-         NS_GET_A(mBackgroundColor) == 0;
+  return mImageCount == 1 &&
+         NS_GET_A(mBackgroundColor) == 0 &&
+         BottomLayer().mImage.IsEmpty();
 }
 
 void
 nsStyleBackground::Position::SetInitialPercentValues(float aPercentVal)
 {
   mXPosition.mPercent = aPercentVal;
   mXPosition.mLength = 0;
   mXPosition.mHasPercent = true;
diff --git a/layout/style/nsStyleStruct.h b/layout/style/nsStyleStruct.h
--- a/layout/style/nsStyleStruct.h
+++ b/layout/style/nsStyleStruct.h
@@ -538,19 +538,22 @@ struct nsStyleBackground {
 
   // The (positive) number of computed values of each property, since
   // the lengths of the lists are independent.
   uint32_t mAttachmentCount,
            mClipCount,
            mOriginCount,
            mRepeatCount,
            mPositionCount,
-           mImageCount,
            mSizeCount,
-           mBlendModeCount;
+           mBlendModeCount,
+           mImageCount;
+
+  nscolor mBackgroundColor;       // [reset]
+
   // Layers are stored in an array, matching the top-to-bottom order in
   // which they are specified in CSS.  The number of layers to be used
   // should come from the background-image property.  We create
   // additional |Layer| objects for *any* property, not just
   // background-image.  This means that the bottommost layer that
   // callers in layout care about (which is also the one whose
   // background-clip applies to the background-color) may not be last
   // layer.  In layers below the bottom layer, properties will be
@@ -562,18 +565,16 @@ struct nsStyleBackground {
 
   #define NS_FOR_VISIBLE_BACKGROUND_LAYERS_BACK_TO_FRONT(var_, stylebg_) \
     for (uint32_t var_ = (stylebg_) ? (stylebg_)->mImageCount : 1; var_-- != 0; )
   #define NS_FOR_VISIBLE_BACKGROUND_LAYERS_BACK_TO_FRONT_WITH_RANGE(var_, stylebg_, start_, count_) \
     NS_ASSERTION((int32_t)(start_) >= 0 && (uint32_t)(start_) < ((stylebg_) ? (stylebg_)->mImageCount : 1), "Invalid layer start!"); \
     NS_ASSERTION((count_) > 0 && (count_) <= (start_) + 1, "Invalid layer range!"); \
     for (uint32_t var_ = (start_) + 1; var_-- != (uint32_t)((start_) + 1 - (count_)); )
 
-  nscolor mBackgroundColor;       // [reset]
-
   // True if this background is completely transparent.
   bool IsTransparent() const;
 
   // We have to take slower codepaths for fixed background attachment,
   // but we don't want to do that when there's no image.
   // Not inline because it uses an nsCOMPtr<imgIRequest>
   // FIXME: Should be in nsStyleStructInlines.h.
   bool HasFixedBackground() const;
diff --git a/layout/xul/nsBoxFrame.cpp b/layout/xul/nsBoxFrame.cpp
--- a/layout/xul/nsBoxFrame.cpp
+++ b/layout/xul/nsBoxFrame.cpp
@@ -26,16 +26,20 @@
 
 // Boxes and Incremental Reflow
 // ----------------------------
 // Boxes layout out top down by adding up their children's min, max, and preferred sizes. Only problem is if a incremental
 // reflow occurs. The preferred size of a child deep in the hierarchy could change. And this could change
 // any number of syblings around the box. Basically any children in the reflow chain must have their caches cleared
 // so when asked for there current size they can relayout themselves. 
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include "nsBoxFrame.h"
 
 #include "gfxUtils.h"
 #include "mozilla/gfx/2D.h"
 #include "nsBoxLayoutState.h"
 #include "mozilla/dom/Touch.h"
 #include "mozilla/Move.h"
 #include "nsStyleContext.h"
@@ -1304,16 +1308,20 @@ PaintXULDebugBackground(nsIFrame* aFrame
 }
 #endif
 
 void
 nsBoxFrame::BuildDisplayList(nsDisplayListBuilder*   aBuilder,
                              const nsRect&           aDirtyRect,
                              const nsDisplayListSet& aLists)
 {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  _mm_prefetch((char *)StyleVisibility(), _MM_HINT_NTA);
+#endif
+
   bool forceLayer = false;
 
   if (GetContent()->IsXULElement()) {
     // forcelayer is only supported on XUL elements with box layout
     if (GetContent()->HasAttr(kNameSpaceID_None, nsGkAtoms::layer)) {
       forceLayer = true;
     }
     // Check for frames that are marked as a part of the region used
@@ -1323,16 +1331,20 @@ nsBoxFrame::BuildDisplayList(nsDisplayLi
       aBuilder->AddWindowExcludeGlassRegion(
           nsRect(aBuilder->ToReferenceFrame(this), GetSize()));
     }
   }
 
   nsDisplayListCollection tempLists;
   const nsDisplayListSet& destination = forceLayer ? tempLists : aLists;
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+  _mm_prefetch((char *)mFrames.FirstChild(), _MM_HINT_NTA);
+#endif
+
   DisplayBorderBackgroundOutline(aBuilder, destination);
 
 #ifdef DEBUG_LAYOUT
   if (mState & NS_STATE_CURRENTLY_IN_DEBUG) {
     destination.BorderBackground()->AppendNewToTop(new (aBuilder)
       nsDisplayGeneric(aBuilder, this, PaintXULDebugBackground,
                        "XULDebugBackground"));
     destination.Outlines()->AppendNewToTop(new (aBuilder)
@@ -1370,16 +1382,19 @@ nsBoxFrame::BuildDisplayListForChildren(
                                         const nsDisplayListSet& aLists)
 {
   nsIFrame* kid = mFrames.FirstChild();
   // Put each child's background onto the BlockBorderBackgrounds list
   // to emulate the existing two-layer XUL painting scheme.
   nsDisplayListSet set(aLists, aLists.BlockBorderBackgrounds());
   // The children should be in the right order
   while (kid) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+    _mm_prefetch((char *)kid->GetNextSibling(), _MM_HINT_T0);
+#endif
     BuildDisplayListForChild(aBuilder, kid, aDirtyRect, set);
     kid = kid->GetNextSibling();
   }
 }
 
 // REVIEW: PaintChildren did a few things none of which are a big deal
 // anymore:
 // * Paint some debugging rects for this frame.
diff --git a/memory/mozjemalloc/jemalloc.c b/memory/mozjemalloc/jemalloc.c
--- a/memory/mozjemalloc/jemalloc.c
+++ b/memory/mozjemalloc/jemalloc.c
@@ -95,16 +95,20 @@
  *           in the associated arena chunk header maps.
  *
  *   Huge : Each allocation is backed by a dedicated contiguous set of chunks.
  *          Metadata are stored in a separate red-black tree.
  *
  *******************************************************************************
  */
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #ifdef MOZ_MEMORY_ANDROID
 #define NO_TLS
 #define _pthread_self() pthread_self()
 #endif
 
 /*
  * On Linux, we use madvise(MADV_DONTNEED) to release memory back to the
  * operating system.  If we release 1MB of live pages with MADV_DONTNEED, our
@@ -219,32 +223,44 @@
 #ifdef MOZ_MEMORY_WINDOWS
 
 /* Some defines from the CRT internal headers that we need here. */
 #define _CRT_SPINCOUNT 5000
 #define __crtInitCritSecAndSpinCount InitializeCriticalSectionAndSpinCount
 #include <io.h>
 #include <windows.h>
 #include <intrin.h>
+#if defined _M_IX86 || defined _M_AMD64
+#include <smmintrin.h>
+#endif
 
 #pragma warning( disable: 4267 4996 4146 )
 
 #define	bool BOOL
 #define	false FALSE
 #define	true TRUE
 #define	inline __inline
 #define	SIZE_T_MAX SIZE_MAX
 #define	STDERR_FILENO 2
 #define	PATH_MAX MAX_PATH
 #define	vsnprintf _vsnprintf
 
 #ifndef NO_TLS
 static unsigned long tlsIndex = 0xffffffff;
 #endif 
 
+static BOOL sse4_1_supported = FALSE;
+typedef struct
+{
+  int EAX;
+  int EBX;
+  int ECX;
+  int EDX;
+} CPU_INFO;
+
 #define	__thread
 #define	_pthread_self() __threadid()
 
 /* use MSVC intrinsics */
 #pragma intrinsic(_BitScanForward)
 static __forceinline int
 ffs(int x)
 {
@@ -4197,31 +4213,40 @@ arena_malloc_small(arena_t *arena, size_
 	} else {
 		/* Sub-page. */
 		size = pow2_ceil(size);
 		bin = &arena->bins[ntbins + nqbins
 		    + (ffs((int)(size >> opt_small_max_2pow)) - 2)];
 	}
 	RELEASE_ASSERT(size == bin->reg_size);
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+	_mm_prefetch((char *)bin, _MM_HINT_NTA);
+#endif
+
 #ifdef MALLOC_BALANCE
 	arena_lock_balance(arena);
 #else
 	malloc_spin_lock(&arena->lock);
 #endif
 	if ((run = bin->runcur) != NULL && run->nfree > 0)
 		ret = arena_bin_malloc_easy(arena, bin, run);
 	else
 		ret = arena_bin_malloc_hard(arena, bin);
 
 	if (ret == NULL) {
 		malloc_spin_unlock(&arena->lock);
 		return (NULL);
 	}
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+	_mm_prefetch((char *)ret, _MM_HINT_NTA);
+	_mm_prefetch((char *)ret + 64, _MM_HINT_NTA);
+#endif
+
 #ifdef MALLOC_STATS
 	bin->stats.nrequests++;
 	arena->stats.nmalloc_small++;
 	arena->stats.allocated_small += size;
 #endif
 	malloc_spin_unlock(&arena->lock);
 
 	if (zero == false) {
@@ -4249,16 +4274,20 @@ arena_malloc_large(arena_t *arena, size_
 #else
 	malloc_spin_lock(&arena->lock);
 #endif
 	ret = (void *)arena_run_alloc(arena, NULL, size, true, zero);
 	if (ret == NULL) {
 		malloc_spin_unlock(&arena->lock);
 		return (NULL);
 	}
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+	_mm_prefetch((char *)ret, _MM_HINT_NTA);
+	_mm_prefetch((char *)ret + 64, _MM_HINT_NTA);
+#endif
 #ifdef MALLOC_STATS
 	arena->stats.nmalloc_large++;
 	arena->stats.allocated_large += size;
 #endif
 	malloc_spin_unlock(&arena->lock);
 
 	if (zero == false) {
 #ifdef MALLOC_FILL
@@ -4709,16 +4738,20 @@ arena_dalloc(void *ptr, size_t offset)
 	arena = chunk->arena;
 	assert(arena != NULL);
 	RELEASE_ASSERT(arena->magic == ARENA_MAGIC);
 
 	pageind = offset >> pagesize_2pow;
 	mapelm = &chunk->map[pageind];
 	RELEASE_ASSERT((mapelm->bits & CHUNK_MAP_ALLOCATED) != 0);
 	if ((mapelm->bits & CHUNK_MAP_LARGE) == 0) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+		arena_run_t *run = (arena_run_t *)(mapelm->bits & ~pagesize_mask);
+		_mm_prefetch((char *)run, _MM_HINT_NTA);
+#endif
 		/* Small allocation. */
 		malloc_spin_lock(&arena->lock);
 		arena_dalloc_small(arena, chunk, ptr, mapelm);
 		malloc_spin_unlock(&arena->lock);
 	} else
 		arena_dalloc_large(arena, chunk, ptr);
 }
 
@@ -5561,16 +5594,30 @@ malloc_init_hard(void)
 		malloc_mutex_unlock(&init_lock);
 #endif
 		return (false);
 	}
 
 #ifdef MOZ_MEMORY_WINDOWS
 	/* get a thread local storage index */
 	tlsIndex = TlsAlloc();
+
+	{
+		CPU_INFO CPUInfo;
+
+		__cpuid((int*)&CPUInfo, 0);
+		if (CPUInfo.EAX >= 1)
+		{
+			__cpuid((int*)&CPUInfo, 1);
+			if (CPUInfo.ECX & (1 << 19))
+			{
+				sse4_1_supported = TRUE;
+			}
+		}
+	}
 #endif
 
 	/* Get page size and number of CPUs */
 #ifdef MOZ_MEMORY_WINDOWS
 	{
 		SYSTEM_INFO info;
 
 		GetSystemInfo(&info);
@@ -7179,8 +7226,45 @@ BOOL APIENTRY DllMain(HINSTANCE hModule,
     case DLL_PROCESS_DETACH:
       break;
 
   }
 
   return TRUE;
 }
 #endif
+
+#ifdef MOZ_MEMORY_WINDOWS
+#include <math.h>
+
+double __cdecl floor_tt(double x)
+{
+#if defined _M_IX86 || defined _M_AMD64
+  if (sse4_1_supported)
+  {
+    __m128d xd = _mm_load_sd(&x);
+    double d;
+
+    xd = _mm_floor_sd(xd, xd);
+    _mm_store_sd(&d, xd);
+    return d;
+  }
+#endif
+  return floor(x);
+}
+
+double __cdecl ceil_tt(double x)
+{
+#if defined _M_IX86 || defined _M_AMD64
+  if (sse4_1_supported)
+  {
+    __m128d xd = _mm_load_sd(&x);
+    double d;
+
+    xd = _mm_ceil_sd(xd, xd);
+    _mm_store_sd(&d, xd);
+    return d;
+  }
+#endif
+  return ceil(x);
+}
+
+#endif
diff --git a/mfbt/Attributes.h b/mfbt/Attributes.h
--- a/mfbt/Attributes.h
+++ b/mfbt/Attributes.h
@@ -6,16 +6,22 @@
 
 /* Implementations of various class and method modifier attributes. */
 
 #ifndef mozilla_Attributes_h
 #define mozilla_Attributes_h
 
 #include "mozilla/Compiler.h"
 
+#if defined(WIN32) || defined(__SYMBIAN32__)
+#  define TT_RESTRICTED_PTR     __restrict
+#else
+#  define TT_RESTRICTED_PTR     __restrict__
+#endif
+
 /*
  * MOZ_ALWAYS_INLINE is a macro which expands to tell the compiler that the
  * method decorated with it must be inlined, even if the compiler thinks
  * otherwise.  This is only a (much) stronger version of the inline hint:
  * compilers are not guaranteed to respect it (although they're much more likely
  * to do so).
  *
  * The MOZ_ALWAYS_INLINE_EVEN_DEBUG macro is yet stronger. It tells the
diff --git a/mozglue/build/moz.build b/mozglue/build/moz.build
--- a/mozglue/build/moz.build
+++ b/mozglue/build/moz.build
@@ -96,8 +96,23 @@ if CONFIG['OS_TARGET'] == 'Darwin':
     # On OSX 10.10.3, a dead lock happens in some cases involving dynamic
     # symbol resolution for symbols that jemalloc itself uses. While it
     # might be possible to find a way to avoid all such symbol resolutions,
     # it's currently not possible because at the very least there's a call
     # to pthread_self from tsd_init_check_recursion, which is necessary
     # because somehow clang doesn't want to accept the __thread keyword
     # for TLS.
     LDFLAGS += ['-Wl,-bind_at_load']
+
+EXPORTS.mozilla += [
+    'parallel_invoke.h',
+]
+
+SOURCES += [
+    'parallel_invoke.cpp',
+]
+
+if CONFIG['_MSC_VER']:
+    if '-DTT_MEMUTIL' in CONFIG['MOZ_OPTIMIZE_FLAGS']:
+        SOURCES['parallel_invoke.cpp'].flags += [
+            '-GL-',
+            '-openmp',
+        ]
diff --git a/mozglue/build/mozglue.def.in b/mozglue/build/mozglue.def.in
--- a/mozglue/build/mozglue.def.in
+++ b/mozglue/build/mozglue.def.in
@@ -31,9 +31,11 @@ EXPORTS
   strdup=wrap_strdup
   _strdup=wrap_strdup
   wcsdup=wrap_wcsdup
   _wcsdup=wrap_wcsdup
   jemalloc_stats
   jemalloc_free_dirty_pages
   ; A hack to work around the CRT (see giant comment in Makefile.in)
   frex=dumb_free_thunk
+  floor=floor_tt
+  ceil=ceil_tt
 #endif
diff --git a/mozglue/build/parallel_invoke.cpp b/mozglue/build/parallel_invoke.cpp
new file mode 100644
--- /dev/null
+++ b/mozglue/build/parallel_invoke.cpp
@@ -0,0 +1,44 @@
+#ifdef _OPENMP
+#include <omp.h>
+#endif
+
+#include "parallel_invoke.h"
+
+void parallel_invoke(PARALLEL_INVOKE_FUNC *functions,
+                     int count,
+                     void *param,
+                     int num_threads)
+{
+#ifdef _OPENMP
+
+  if (num_threads == PARALLEL_INVOKE_MAX_THREADS)
+    num_threads = omp_get_max_threads();
+
+  if (num_threads <= 0)
+    num_threads = 1;
+
+  if (num_threads == 1 || count <= 1) {
+    for (int i = 0; i < count; i++) {
+      functions[i](param);
+    }
+  } else {
+#pragma omp parallel num_threads(num_threads)
+    {
+#pragma omp master
+      functions[0](param);
+
+#pragma omp for schedule(dynamic)
+      for (int i = 1; i < count; i++) {
+        functions[i](param);
+      }
+    }
+  }
+
+#else  // _OPENMP
+
+  for (int i = 0; i < count; i++) {
+    functions[i](param);
+  }
+
+#endif // _OPENMP
+}
diff --git a/mozglue/build/parallel_invoke.h b/mozglue/build/parallel_invoke.h
new file mode 100644
--- /dev/null
+++ b/mozglue/build/parallel_invoke.h
@@ -0,0 +1,18 @@
+#ifndef parallel_invoke_h_
+#define parallel_invoke_h_
+
+#include "mozilla/Types.h"
+
+MOZ_BEGIN_EXTERN_C
+
+#define PARALLEL_INVOKE_MAX_THREADS (-1)
+typedef void (*PARALLEL_INVOKE_FUNC)(void *param);
+
+MFBT_API void parallel_invoke(PARALLEL_INVOKE_FUNC *functions,
+                              int count,
+                              void *param = nullptr,
+                              int num_threads = PARALLEL_INVOKE_MAX_THREADS);
+
+MOZ_END_EXTERN_C
+
+#endif /* !defined(parallel_invoke_h_) */
diff --git a/netwerk/protocol/http/nsHttpConnectionMgr.cpp b/netwerk/protocol/http/nsHttpConnectionMgr.cpp
--- a/netwerk/protocol/http/nsHttpConnectionMgr.cpp
+++ b/netwerk/protocol/http/nsHttpConnectionMgr.cpp
@@ -1,13 +1,17 @@
 /* vim:set ts=4 sw=4 sts=4 et cin: */
 /* This Source Code Form is subject to the terms of the Mozilla Public
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 // HttpLog.h should generally be included first
 #include "HttpLog.h"
 
 // Log on level :5, instead of default :4.
 #undef LOG
 #define LOG(args) LOG5(args)
 #undef LOG_ENABLED
 #define LOG_ENABLED() LOG5_ENABLED()
@@ -1184,16 +1188,21 @@ nsHttpConnectionMgr::ProcessPendingQForE
     nsHttpTransaction *trans;
     nsresult rv;
     bool dispatchedSuccessfully = false;
 
     // if !considerAll iterate the pending list until one is dispatched successfully.
     // Keep iterating afterwards only until a transaction fails to dispatch.
     // if considerAll == true then try and dispatch all items.
     for (uint32_t i = 0; i < ent->mPendingQ.Length(); ) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+        if (i + 1 < ent->mPendingQ.Length()) {
+          _mm_prefetch((char *)ent->mPendingQ[i + 1]->LoadGroupConnectionInfo(), _MM_HINT_NTA);
+        }
+#endif
         trans = ent->mPendingQ[i];
 
         // When this transaction has already established a half-open
         // connection, we want to prevent any duplicate half-open
         // connections from being established and bound to this
         // transaction. Allow only use of an idle persistent connection
         // (if found) for transactions referred by a half-open connection.
         bool alreadyHalfOpen = false;
diff --git a/nsprpub/configure b/nsprpub/configure
--- a/nsprpub/configure
+++ b/nsprpub/configure
@@ -7250,19 +7250,16 @@ tools are selected during the Xcode/Deve
     case "$target_cpu" in
     i*86)
 	if test -n "$USE_64"; then
 	    $as_echo "#define _AMD64_ 1" >>confdefs.h
 
 	else
 	    $as_echo "#define _X86_ 1" >>confdefs.h
 
-            if test -z "$GNU_CC" -a "$MSC_VER" -ge "1700"; then
-                                                CFLAGS="$CFLAGS -arch:IA32"
-            fi
 	fi
         ;;
     x86_64)
 	    $as_echo "#define _AMD64_ 1" >>confdefs.h
 
 	    USE_64=1
 	    ;;
     ia64)
diff --git a/nsprpub/configure.in b/nsprpub/configure.in
--- a/nsprpub/configure.in
+++ b/nsprpub/configure.in
@@ -1950,19 +1950,23 @@ tools are selected during the Xcode/Deve
             fi
         fi
         
         CFLAGS="$CFLAGS -W3 -nologo -GF -Gy"
         DLLFLAGS="$DLLFLAGS -OUT:\"\$@\""
         _DEBUG_FLAGS=-Zi
         _OPTIMIZE_FLAGS=-O2
 
-        PROFILE_GEN_CFLAGS="-GL"
+        PROFILE_GEN_CFLAGS="-GL -DMSVC_PGO_ENABLED"
         PROFILE_GEN_LDFLAGS="-LTCG:PGINSTRUMENT"
-        PROFILE_USE_CFLAGS="-GL -wd4624 -wd4952"
+        if test $_CC_MAJOR_VERSION -ge 18; then
+            dnl Run PGO profiling in safe mode
+            PROFILE_GEN_LDFLAGS="$PROFILE_GEN_LDFLAGS -PogoSafeMode"
+        fi
+        PROFILE_USE_CFLAGS="-GL -wd4624 -wd4952 -DMSVC_PGO_ENABLED"
         PROFILE_USE_LDFLAGS="-LTCG:PGUPDATE"
 
         if test "$MSC_VER" -ge "1800"; then
             dnl Visual C++ 2013 requires -FS when parallel building with
             dnl make -jN. If not specified, compiler sometimes emits C1041
             dnl error.
             CFLAGS="$CFLAGS -FS"
             dnl -Gw can benefit when using linker optimization on PGO.
@@ -2056,21 +2060,16 @@ tools are selected during the Xcode/Deve
     esac
 
     case "$target_cpu" in
     i*86)
 	if test -n "$USE_64"; then
 	    AC_DEFINE(_AMD64_)
 	else		
 	    AC_DEFINE(_X86_)
-            if test -z "$GNU_CC" -a "$MSC_VER" -ge "1700"; then
-                dnl Visual C++ 2012 defaults to -arch:SSE2. Use -arch:IA32
-                dnl to avoid requiring SSE2.
-                CFLAGS="$CFLAGS -arch:IA32"
-            fi
 	fi
         ;;
     x86_64)
 	    AC_DEFINE(_AMD64_)
 	    USE_64=1
 	    ;;
     ia64)
 	    AC_DEFINE(_IA64_)
diff --git a/security/nss/coreconf/WIN32.mk b/security/nss/coreconf/WIN32.mk
--- a/security/nss/coreconf/WIN32.mk
+++ b/security/nss/coreconf/WIN32.mk
@@ -211,21 +211,18 @@ ifeq (,$(filter-out x386 x86_64,$(CPU_AR
 ifdef USE_64
 	DEFINES += -D_AMD64_
 	# Use subsystem 5.02 to allow running on Windows XP.
 	ifeq ($(_MSC_VER_GE_11),1)
 		LDFLAGS += -SUBSYSTEM:CONSOLE,5.02
 	endif
 else
 	DEFINES += -D_X86_
-	# VS2012 defaults to -arch:SSE2. Use -arch:IA32 to avoid requiring
-	# SSE2.
 	# Use subsystem 5.01 to allow running on Windows XP.
 	ifeq ($(_MSC_VER_GE_11),1)
-		OS_CFLAGS += -arch:IA32
 		LDFLAGS += -SUBSYSTEM:CONSOLE,5.01
 	endif
 endif
 endif
 ifeq ($(CPU_ARCH), ALPHA)
 	DEFINES += -D_ALPHA_=1
 endif
 
diff --git a/security/nss/lib/freebl/Makefile b/security/nss/lib/freebl/Makefile
--- a/security/nss/lib/freebl/Makefile
+++ b/security/nss/lib/freebl/Makefile
@@ -124,21 +124,20 @@ ifdef NS_USE_GCC
 #     DEFINES += -DMP_ASSEMBLY_MULTIPLY -DMP_ASSEMBLY_SQUARE \
 #                -DMP_ASSEMBLY_DIV_2DX1D
 # but we haven't figured out how to make it work, so we are not
 # using assembler right now.
     ASFILES  =
     DEFINES += -DMP_NO_MP_WORD -DMP_USE_UINT_DIGIT
 else
 # MSVC
-    MPI_SRCS += mpi_x86_asm.c
     DEFINES += -DMP_ASSEMBLY_MULTIPLY -DMP_ASSEMBLY_SQUARE 
     DEFINES += -DMP_ASSEMBLY_DIV_2DX1D -DMP_USE_UINT_DIGIT -DMP_NO_MP_WORD
     ifdef BUILD_OPT
-	OPTIMIZER += -Ox  # maximum optimization for freebl
+	OPTIMIZER += -O2  # maximum optimization for freebl
     endif
     # The Intel AES assembly code requires Visual C++ 2010.
     # if $(_MSC_VER) >= 1600 (Visual C++ 2010)
     ifeq ($(firstword $(sort $(_MSC_VER) 1600)),1600)
 	DEFINES += -DUSE_HW_AES -DINTEL_GCM
 	ASFILES += intel-aes-x86-masm.asm intel-gcm-x86-masm.asm
 	EXTRA_SRCS += intel-gcm-wrap.c
 	ifeq ($(CLANG_CL),1)
diff --git a/security/nss/lib/freebl/manifest.mn b/security/nss/lib/freebl/manifest.mn
--- a/security/nss/lib/freebl/manifest.mn
+++ b/security/nss/lib/freebl/manifest.mn
@@ -60,17 +60,21 @@ PRIVATE_EXPORTS = \
 	secmpi.h \
 	secrng.h \
 	ec.h \
 	ecl.h \
 	ecl-curve.h \
 	$(NULL)
 
 MPI_HDRS = mpi-config.h mpi.h mpi-priv.h mplogic.h mpprime.h logtab.h mp_gf2m.h
+ifdef USE_64
 MPI_SRCS = mpprime.c mpmontg.c mplogic.c mpi.c mp_gf2m.c
+else
+MPI_SRCS = mpprime.c mpmontg.c mplogic.c mpi.c mp_gf2m.c mpi_x86_asm.c
+endif
 
 
 ECL_HDRS = ecl-exp.h ecl.h ec2.h ecp.h ecl-priv.h
 ifndef NSS_DISABLE_ECC
 ECL_SRCS = ecl.c ecl_curve.c ecl_mult.c ecl_gf.c \
 	ecp_aff.c ecp_jac.c ecp_mont.c \
 	ec_naf.c ecp_jm.c ecp_256.c ecp_384.c ecp_521.c \
 	ecp_256_32.c
diff --git a/toolkit/modules/debug.js b/toolkit/modules/debug.js
--- a/toolkit/modules/debug.js
+++ b/toolkit/modules/debug.js
@@ -37,17 +37,17 @@ this.NS_ASSERT = function NS_ASSERT(cond
   var defB = Components.classes["@mozilla.org/preferences-service;1"]
                        .getService(Components.interfaces.nsIPrefService)
                        .getDefaultBranch(null);
   try {
     switch (defB.getCharPref("app.update.channel")) {
       case "nightly":
       case "aurora":
       case "beta":
-      case "default":
+      // case "default":
         releaseBuild = false;
     }
   } catch(ex) {}
 
   var caller = arguments.callee.caller;
   var assertionText = "ASSERT: " + message + "\n";
 
   // Report the error to the console
diff --git a/toolkit/xre/nsWindowsWMain.cpp b/toolkit/xre/nsWindowsWMain.cpp
--- a/toolkit/xre/nsWindowsWMain.cpp
+++ b/toolkit/xre/nsWindowsWMain.cpp
@@ -5,16 +5,25 @@
 // This file is a .cpp file meant to be included in nsBrowserApp.cpp and other
 // similar bootstrap code. It converts wide-character windows wmain into UTF-8
 // narrow-character strings.
 
 #ifndef XP_WIN
 #error This file only makes sense on Windows.
 #endif
 
+// Force link tmemutil.dll
+#if defined(TT_MEMUTIL)
+#if defined(_M_IX86)
+#pragma comment(linker, "/include:_GetCpuFeature_tt")
+#elif defined(_M_AMD64)
+#pragma comment(linker, "/include:GetCpuFeature_tt")
+#endif
+#endif /* TT_MEMUTIL */
+
 #include "nsUTF8Utils.h"
 #include <intrin.h>
 #include <math.h>
 #include "mozilla/WindowsVersion.h"
 
 #ifndef XRE_DONT_PROTECT_DLL_LOAD
 #include "nsSetDllDirectory.h"
 #endif
diff --git a/widget/windows/WinUtils.cpp b/widget/windows/WinUtils.cpp
--- a/widget/windows/WinUtils.cpp
+++ b/widget/windows/WinUtils.cpp
@@ -724,26 +724,36 @@ WinUtils::GetTopLevelHWND(HWND aWnd,
       upWnd = ::GetWindow(curWnd, GW_OWNER);
     }
     curWnd = upWnd;
   }
 
   return topWnd;
 }
 
+class CAtom_NSWindowPropName {
+public:
+  CAtom_NSWindowPropName() {
+    wchar_t sPropName[40] = L"";
+    _snwprintf(sPropName, 39, L"MozillansIWidgetPtr%u",
+               ::GetCurrentProcessId());
+    sPropName[39] = '\0';
+    atom = ::GlobalAddAtomW(sPropName);
+  }
+  ~CAtom_NSWindowPropName() {
+    ::GlobalDeleteAtom(atom);
+  }
+  ATOM atom;
+};
+
 static const wchar_t*
 GetNSWindowPropName()
 {
-  static wchar_t sPropName[40] = L"";
-  if (!*sPropName) {
-    _snwprintf(sPropName, 39, L"MozillansIWidgetPtr%u",
-               ::GetCurrentProcessId());
-    sPropName[39] = '\0';
-  }
-  return sPropName;
+  static CAtom_NSWindowPropName gaNswpn;
+  return (const wchar_t*)(UINT_PTR)gaNswpn.atom;
 }
 
 /* static */
 bool
 WinUtils::SetNSWindowBasePtr(HWND aWnd, nsWindowBase* aWidget)
 {
   if (!aWidget) {
     ::RemovePropW(aWnd, GetNSWindowPropName());
diff --git a/widget/windows/nsWindow.cpp b/widget/windows/nsWindow.cpp
--- a/widget/windows/nsWindow.cpp
+++ b/widget/windows/nsWindow.cpp
@@ -2055,17 +2055,28 @@ nsWindow::ResetLayout()
 
   // Invalidate and update
   Invalidate();
 }
 
 // Internally track the caption status via a window property. Required
 // due to our internal handling of WM_NCACTIVATE when custom client
 // margins are set.
-static const wchar_t kManageWindowInfoProperty[] = L"ManageWindowInfoProperty";
+class CAtom_ManageWindowInfoProperty {
+public:
+  CAtom_ManageWindowInfoProperty() {
+    atom = ::GlobalAddAtomW(L"ManageWindowInfoProperty");
+  }
+  ~CAtom_ManageWindowInfoProperty() {
+    ::GlobalDeleteAtom(atom);
+  }
+  ATOM atom;
+};
+static CAtom_ManageWindowInfoProperty gaMwip;
+#define kManageWindowInfoProperty ((LPCWSTR)(UINT_PTR)gaMwip.atom)
 typedef BOOL (WINAPI *GetWindowInfoPtr)(HWND hwnd, PWINDOWINFO pwi);
 static GetWindowInfoPtr sGetWindowInfoPtrStub = nullptr;
 
 BOOL WINAPI
 GetWindowInfoHook(HWND hWnd, PWINDOWINFO pwi)
 {
   if (!sGetWindowInfoPtrStub) {
     NS_ASSERTION(FALSE, "Something is horribly wrong in GetWindowInfoHook!");
diff --git a/xpcom/base/nsCycleCollector.cpp b/xpcom/base/nsCycleCollector.cpp
--- a/xpcom/base/nsCycleCollector.cpp
+++ b/xpcom/base/nsCycleCollector.cpp
@@ -138,16 +138,20 @@
 // there should be no objects released from the scan-safe set during
 // the scan.
 //
 // We *do* call |Root| and |Unroot| on every white object, on
 // either side of the calls to |Unlink|. This keeps the set of white
 // objects alive during the unlinking.
 //
 
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #if !defined(__MINGW32__)
 #ifdef WIN32
 #include <crtdbg.h>
 #include <errno.h>
 #endif
 #endif
 
 #include "base/process_util.h"
@@ -993,16 +997,22 @@ private:
 
     template<class PurpleVisitor>
     void VisitEntries(nsPurpleBuffer& aBuffer, PurpleVisitor& aVisitor)
     {
       nsPurpleBufferEntry* eEnd = ArrayEnd(mEntries);
       for (nsPurpleBufferEntry* e = mEntries; e != eEnd; ++e) {
         MOZ_ASSERT(e->mObject, "There should be no null mObject when we iterate over the purple buffer");
         if (!(uintptr_t(e->mObject) & uintptr_t(1)) && e->mObject) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+          nsPurpleBufferEntry* ePref = e + 8;
+          if (ePref < eEnd) {
+            _mm_prefetch((char *)ePref->mRefCnt, _MM_HINT_NTA);
+          }
+#endif
           aVisitor.Visit(aBuffer, e);
         }
       }
     }
   };
   // This class wraps a linked list of the elements in the purple
   // buffer.
 
diff --git a/xpcom/glue/nsDeque.cpp b/xpcom/glue/nsDeque.cpp
--- a/xpcom/glue/nsDeque.cpp
+++ b/xpcom/glue/nsDeque.cpp
@@ -130,17 +130,32 @@ nsDeque::SetDeallocator(nsDequeFunctor* 
 
 /**
  * Remove all items from container without destroying them.
  */
 void
 nsDeque::Empty()
 {
   if (mSize && mData) {
+#ifdef TT_MEMUTIL
+    static const uint32_t dwNonTemporalDataSizeMin = GetNonTemporalDataSizeMin_tt();
+    const uint32_t dwDataSize = mCapacity * sizeof(*mData);
+
+    if (dwDataSize < dwNonTemporalDataSizeMin ||
+        NON_TEMPORAL_STORES_NOT_SUPPORTED == dwNonTemporalDataSizeMin)
+    {
+        memset(mData, 0, mCapacity * sizeof(*mData));
+    }
+    else
+    {
+        memset_nontemporal_tt(mData, 0, mCapacity * sizeof(*mData));
+    }
+#else
     memset(mData, 0, mCapacity * sizeof(*mData));
+#endif
   }
   mSize = 0;
   mOrigin = 0;
 }
 
 /**
  * Remove and delete all items from container
  */
diff --git a/xpcom/glue/pldhash.cpp b/xpcom/glue/pldhash.cpp
--- a/xpcom/glue/pldhash.cpp
+++ b/xpcom/glue/pldhash.cpp
@@ -2,16 +2,23 @@
 /* vim: set ts=8 sts=2 et sw=2 tw=80: */
 /* This Source Code Form is subject to the terms of the Mozilla Public
  * License, v. 2.0. If a copy of the MPL was not distributed with this
  * file, You can obtain one at http://mozilla.org/MPL/2.0/. */
 
 /*
  * Double hashing implementation.
  */
+#if _MSC_VER >= 1400
+#include <intrin.h>
+#endif
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+#include <xmmintrin.h>
+#endif
+
 #include <stdio.h>
 #include <stdlib.h>
 #include <string.h>
 #include "pldhash.h"
 #include "mozilla/HashFunctions.h"
 #include "mozilla/MathAlgorithms.h"
 #include "nsDebug.h"     /* for PR_ASSERT */
 #include "nsAlgorithm.h"
@@ -104,31 +111,47 @@ PL_DHashMatchStringKey(PLDHashTable* aTa
          (stub->key && aKey &&
           strcmp((const char*)stub->key, (const char*)aKey) == 0);
 }
 
 MOZ_ALWAYS_INLINE void
 PLDHashTable::MoveEntryStub(const PLDHashEntryHdr* aFrom,
                             PLDHashEntryHdr* aTo)
 {
+#if _MSC_VER >= 1400
+  if ((mEntrySize & 3) == 0) {
+    __movsd((unsigned long*)aTo, (unsigned long*)aFrom, mEntrySize >> 2);
+  } else {
+    memcpy(aTo, aFrom, mEntrySize);
+  }
+#else
   memcpy(aTo, aFrom, mEntrySize);
+#endif
 }
 
 void
 PL_DHashMoveEntryStub(PLDHashTable* aTable,
                       const PLDHashEntryHdr* aFrom,
                       PLDHashEntryHdr* aTo)
 {
   aTable->MoveEntryStub(aFrom, aTo);
 }
 
 MOZ_ALWAYS_INLINE void
 PLDHashTable::ClearEntryStub(PLDHashEntryHdr* aEntry)
 {
+#if _MSC_VER >= 1400
+  if ((mEntrySize & 3) == 0) {
+    __stosd((unsigned long*)aEntry, 0, mEntrySize >> 2);
+  } else {
+    memset(aEntry, 0, mEntrySize);
+  }
+#else
   memset(aEntry, 0, mEntrySize);
+#endif
 }
 
 void
 PL_DHashClearEntryStub(PLDHashTable* aTable, PLDHashEntryHdr* aEntry)
 {
   aTable->ClearEntryStub(aEntry);
 }
 
@@ -545,17 +568,36 @@ PLDHashTable::ChangeTable(int aDeltaLog2
   }
 
   /* We can't fail from here on, so update table parameters. */
   mHashShift = PL_DHASH_BITS - newLog2;
   mRemovedCount = 0;
   mGeneration++;
 
   /* Assign the new entry store to table. */
+#ifdef TT_MEMUTIL
+  {
+    static bool initialized = false;
+    static uint32_t dwNonTemporalDataSizeMin = NON_TEMPORAL_STORES_NOT_SUPPORTED;
+
+    if (!initialized) {
+      dwNonTemporalDataSizeMin = GetNonTemporalDataSizeMin_tt();
+      initialized = true;
+    }
+
+    if (nbytes < dwNonTemporalDataSizeMin ||
+        NON_TEMPORAL_STORES_NOT_SUPPORTED == dwNonTemporalDataSizeMin) {
+      memset(newEntryStore, 0, nbytes);
+    } else {
+      memset_nontemporal_tt(newEntryStore, 0, nbytes);
+    }
+  }
+#else
   memset(newEntryStore, 0, nbytes);
+#endif
   char* oldEntryStore;
   char* oldEntryAddr;
   oldEntryAddr = oldEntryStore = mEntryStore;
   mEntryStore = newEntryStore;
   PLDHashMoveEntry moveEntry = mOps->moveEntry;
 
   /* Copy only live entries, leaving removed ones behind. */
   uint32_t oldCapacity = 1u << oldLog2;
@@ -828,16 +870,19 @@ PLDHashTable::Enumerate(PLDHashEnumerato
     if (entryAddr >= entryLimit) {
       entryAddr -= tableSize;
     }
   }
 
   for (uint32_t e = 0; e < capacity; ++e) {
     PLDHashEntryHdr* entry = (PLDHashEntryHdr*)entryAddr;
     if (ENTRY_IS_LIVE(entry)) {
+#if (_M_IX86_FP >= 1) || defined(__SSE__) || defined(_M_AMD64) || defined(__amd64__)
+      _mm_prefetch((char *)(entryAddr + mEntrySize), _MM_HINT_NTA);
+#endif
       PLDHashOperator op = aEtor(this, entry, i++, aArg);
       if (op & PL_DHASH_REMOVE) {
         METER(mStats.mRemoveEnums++);
         PL_DHashTableRawRemove(this, entry);
         didRemove = true;
       }
       if (op & PL_DHASH_STOP) {
         break;
diff --git a/xpcom/string/nsCharTraits.h b/xpcom/string/nsCharTraits.h
--- a/xpcom/string/nsCharTraits.h
+++ b/xpcom/string/nsCharTraits.h
@@ -148,16 +148,20 @@ struct nsCharTraits<char16_t>
   {
     return static_cast<char_type*>(memmove(aStr1, aStr2,
                                            aN * sizeof(char_type)));
   }
 
   static char_type*
   copy(char_type* aStr1, const char_type* aStr2, size_t aN)
   {
+    if (1 == aN) {
+      *aStr1 = *aStr2;
+      return aStr1;
+    }
     return static_cast<char_type*>(memcpy(aStr1, aStr2,
                                           aN * sizeof(char_type)));
   }
 
   static char_type*
   copyASCII(char_type* aStr1, const char* aStr2, size_t aN)
   {
     for (char_type* s = aStr1; aN--; ++s, ++aStr2) {
